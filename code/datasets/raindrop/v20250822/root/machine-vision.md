<div class="nav">

⟵ [Up](index.html)  \|  [Index](index.html)

</div>

# machine-vision

<div class="cards">

<div class="card">

<div class="card-title">

[What happened to pathology AI
companies?](https://open.substack.com/pub/abhishaike/p/what-happened-to-pathology-ai-companies?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/$s_!Euh6!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F815a7c7c-b724-4863-9055-306dd94b110e_2912x1632.png)](https://open.substack.com/pub/abhishaike/p/what-happened-to-pathology-ai-companies?r=oc5d&utm_medium=ios)

</div>

4k words, 19 minutes reading time

</div>

<div class="card">

<div class="card-title">

[How to think with
images](https://www.lesswrong.com/posts/r6gpBgs98gnArCEty/how-to-think-with-images)

</div>

<div class="card-image">

[![](https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/r6gpBgs98gnArCEty/ndlhybz8pgjed78bat6c)](https://www.lesswrong.com/posts/r6gpBgs98gnArCEty/how-to-think-with-images)

</div>

\* Introduction \* Understanding vs. Generation in Vision \* Unifying
Vision – Are We There Yet? \* Vision Without Words: Do Models Need
Language? \*…

</div>

<div class="card">

<div class="card-title">

[A Code Implementation for Advanced Human Pose Estimation Using
MediaPipe, OpenCV and
Matplotlib](https://www.marktechpost.com/2025/03/25/a-code-implementation-for-advanced-human-pose-estimation-using-mediapipe-opencv-and-matplotlib/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/03/Screenshot-2025-03-25-at-1.46.40%E2%80%AFPM.png)](https://www.marktechpost.com/2025/03/25/a-code-implementation-for-advanced-human-pose-estimation-using-mediapipe-opencv-and-matplotlib/)

</div>

A Code Implementation Guide to Advanced Human Pose Estimation using
MediaPipe, OpenCV and Matplotlib

</div>

<div class="card">

<div class="card-title">

[On-Device, Real-Time Hand Tracking with
MediaPipe](https://research.google/blog/on-device-real-time-hand-tracking-with-mediapipe/)

</div>

<div class="card-image">

[![](https://storage.googleapis.com/gweb-research2023-media/images/e3ef09568fe6b09d0b93772d3f02dbf3-i.width-800.format-jpeg.jpg)](https://research.google/blog/on-device-real-time-hand-tracking-with-mediapipe/)

</div>

Posted by Valentin Bazarevsky and Fan Zhang, Research Engineers, Google
Research The ability to perceive the shape and motion of hands can be a
v...

</div>

<div class="card">

<div class="card-title">

[From Iron Man to Reality: Hand Gesture Recognition Reshapes Tech
Interaction -
Dataconomy](https://dataconomy.com/2025/03/28/iron-man-reality-hand-gesture-recognition/)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png)](https://dataconomy.com/2025/03/28/iron-man-reality-hand-gesture-recognition/)

</div>

The surge in hand gesture recognition is not merely a novelty; it's a
fundamental shift in how humans interact with machines.

</div>

<div class="card">

<div class="card-title">

[Improving Uniformity And Linearity For All
Masks](https://semiengineering.com/improving-uniformity-and-linearity-for-all-masks/)

</div>

<div class="card-image">

[![](https://semiengineering.com/wp-content/uploads/eBeam_Uniformity-Linearity-for-All-Masks-fig2.webp?fit=272%2C344&ssl=1)](https://semiengineering.com/improving-uniformity-and-linearity-for-all-masks/)

</div>

Pixel-level dose correction improves the quality of masks written by
multi-beam.

</div>

<div class="card">

<div class="card-title">

[Book](https://github.com/udlbook/cvbook/raw/main/book.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[5 Free Books on Computer Vision -
MachineLearningMastery.com](https://machinelearningmastery.com/5-free-books-on-computer-vision/)

</div>

<div class="card-image">

[![](https://machinelearningmastery.com/wp-content/uploads/2024/10/mlm-5-free-books-computer-vision-1.jpeg)](https://machinelearningmastery.com/5-free-books-on-computer-vision/)

</div>

\[caption align=

</div>

<div class="card">

<div class="card-title">

[10 GitHub Repositories to Master Computer
Vision](https://www.kdnuggets.com/10-github-repositories-to-master-computer-vision)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/awan_10_github_repositories_master_computer_vision_1.png)](https://www.kdnuggets.com/10-github-repositories-to-master-computer-vision)

</div>

The GitHub repository includes up-to-date learning resources, research
papers, guides, popular tools, tutorials, projects, and datasets.

</div>

<div class="card">

<div class="card-title">

[Satellites Spotting
Ships](https://tech.marksblogg.com/yolo-umbra-sar-satellites-ship-detection.html)

</div>

Benchmarks & Tips for Big Data, Hadoop, AWS, Google Cloud, PostgreSQL,
Spark, Python & More...

</div>

<div class="card">

<div class="card-title">

[Image Data Preprocessing Techniques You Should
Know](https://thecleverprogrammer.com/2024/06/05/image-data-preprocessing-techniques-you-should-know)

</div>

<div class="card-image">

[![](https://thecleverprogrammer.com/wp-content/uploads/2024/06/Essential-Image-Data-Preprocessing-Techniques.png)](https://thecleverprogrammer.com/2024/06/05/image-data-preprocessing-techniques-you-should-know)

</div>

In this article, I'll take you through the essential image data
preprocessing techniques you should know with implementation using
Python.

</div>

<div class="card">

<div class="card-title">

[x.com](https://x.com/DimitrisPapail/status/1779945981314027608)

</div>

— Dimitris Papailiopoulos (@DimitrisPapail)

</div>

<div class="card">

<div class="card-title">

[Optical Illusions Can Fool AI Chatbots,
Too](https://www.scientificamerican.com/article/optical-illusions-can-fool-ai-chatbots-too)

</div>

<div class="card-image">

[![](https://static.scientificamerican.com/dam/m/4e1975f68a5f0b19/original/2AP2RJ0-web.jpg?w=1200)](https://www.scientificamerican.com/article/optical-illusions-can-fool-ai-chatbots-too)

</div>

Experiments with optical illusions have revealed surprising similarities
between human and AI perception

</div>

<div class="card">

<div class="card-title">

[Demystifying Vision-Language Models: An In-Depth
Exploration](https://www.marktechpost.com/2024/05/23/demystifying-vision-language-models-an-in-depth-exploration)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-16-at-12.00.13-AM.png)](https://www.marktechpost.com/2024/05/23/demystifying-vision-language-models-an-in-depth-exploration)

</div>

Vision-language models (VLMs), capable of processing both images and
text, have gained immense popularity due to their versatility in solving
a wide range of tasks, from information retrieval in scanned documents
to code generation from screenshots. However, the development of these
powerful models has been hindered by a lack of understanding regarding
the critical design choices that truly impact their performance. This
knowledge gap makes it challenging for researchers to make meaningful
progress in this field. To address this issue, a team of researchers
from Hugging Face and Sorbonne Université conducted extensive
experiments to unravel the factors that matter the

</div>

<div class="card">

<div class="card-title">

[How to Estimate Depth from a Single
Image](https://dev.to/voxel51/how-to-estimate-depth-from-a-single-image-o3a)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F93gnab40i2hb8pfybza1.png)](https://dev.to/voxel51/how-to-estimate-depth-from-a-single-image-o3a)

</div>

Author: Jacob Marks (Machine Learning Engineer at Voxel51) Run and
Evaluate Monocular Depth...

</div>

<div class="card">

<div class="card-title">

[Monocular Depth
Estimation](https://paperswithcode.com/task/monocular-depth-estimation)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/monodepth_teaser_eB0Qogq.gif)](https://paperswithcode.com/task/monocular-depth-estimation)

</div>

\*\*Monocular Depth Estimation\*\* is the task of estimating the depth
value (distance relative to the camera) of each pixel given a single
(monocular) RGB image. This challenging task is a key prerequisite for
determining scene understanding for applications such as 3D scene
reconstruction, autonomous driving, and AR. State-of-the-art methods
usually fall into one of two categories: designing a complex network
that is powerful enough to directly regress the depth map, or splitting
the input into bins or windows to reduce computational complexity. The
most popular benchmarks are the KITTI and NYUv2 datasets. Models are
typically evaluated using RMSE or absolute relative error. Source:
\[Defocus Deblurring Using Dual-Pixel Data
\](https://arxiv.org/abs/2005.00305)

</div>

<div class="card">

<div class="card-title">

[YOLO8 The basic functions for
beginner!](https://dev.to/sachadee/yolo8-the-basic-functions-for-beginner-1k9)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fzas31oisldyaulcast9z.gif)](https://dev.to/sachadee/yolo8-the-basic-functions-for-beginner-1k9)

</div>

When you start using YOLO8 you loose a lot of time to find the basics
codes to get the bounding...

</div>

<div class="card">

<div class="card-title">

[‘The machine did it coldly’: Israel used AI to identify 37,000 Hamas
target](https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes)

</div>

<div class="card-image">

[![](https://i.guim.co.uk/img/media/5e2b277c72ab2d1978b8a795b09cd8b3215d93f6/0_285_5151_3091/master/5151.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=80a6607fe59176c3d1673e18aea5a264)](https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes)

</div>

Israeli intelligence sources reveal use of ‘Lavender’ system in Gaza war
and claim permission given to kill civilians in pursuit of low-ranking
militants

</div>

<div class="card">

<div class="card-title">

[Object Detection Basics — A Comprehensive Beginner’s Guide (Part
1)](https://towardsdatascience.com/object-detection-basics-a-comprehensive-beginners-guide-part-1-f57380c89b78?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*4Vq2m6HJ1OMOW77g)](https://towardsdatascience.com/object-detection-basics-a-comprehensive-beginners-guide-part-1-f57380c89b78?source=rss----7f60cf5620c9---4)

</div>

Learn the basics of this advanced computer vision task of object
detection in an easy to understand multi-part beginner’s guide

</div>

<div class="card">

<div class="card-title">

[Binary image convex hull – algorithm notes » Steve on Image Processing
with](https://blogs.mathworks.com/steve/2011/10/04/binary-image-convex-hull-algorithm-notes)

</div>

<div class="card-image">

[![](https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_01.png)](https://blogs.mathworks.com/steve/2011/10/04/binary-image-convex-hull-algorithm-notes)

</div>

Today I want to tell a little image processing algorithm story related
to my post last week about the new bwconvhull function in the Image
Processing Toolbox. The developer (Brendan) who worked on this function
came to see me sometime last year to find out how the 'ConvexImage'
measurement offered by regionprops

</div>

<div class="card">

<div class="card-title">

[‘Let’s Go Shopping (LGS)’ Dataset: A Large-Scale Public Dataset with
15M
Im](https://www.marktechpost.com/2024/01/14/lets-go-shopping-lgs-dataset-a-large-scale-public-dataset-with-15m-image-caption-pairs-from-publicly-available-e-commerce-websites)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-14-at-4.05.26-AM.png)](https://www.marktechpost.com/2024/01/14/lets-go-shopping-lgs-dataset-a-large-scale-public-dataset-with-15m-image-caption-pairs-from-publicly-available-e-commerce-websites)

</div>

Developing large-scale datasets has been critical in computer vision and
natural language processing. These datasets, rich in visual and textual
information, are fundamental to developing algorithms capable of
understanding and interpreting images. They serve as the backbone for
enhancing machine learning models, particularly those tasked with
deciphering the complex interplay between visual elements in images and
their corresponding textual descriptions. A significant challenge in
this field is the need for large-scale, accurately annotated datasets.
These are essential for training models but are often not publicly
accessible, limiting the scope of research and development. The ImageNet
and OpenImages datasets, containing human-annotated

</div>

<div class="card">

<div class="card-title">

[Low Quality Image Detection—Part
1](https://towardsdatascience.com/low-quality-image-detection-machine-learning-fdc2c1ba86e1)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*pZemXsaM8pOj8Uc5)](https://towardsdatascience.com/low-quality-image-detection-machine-learning-fdc2c1ba86e1)

</div>

How to perform low quality images detection using Machine Learning and
Deep Learning.

</div>

<div class="card">

<div class="card-title">

[Image Segmentation: An In-Depth
Guide](https://towardsdatascience.com/image-segmentation-an-in-depth-guide-5e56512eea2e)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:512/1*YZoz7tIHda8sIJYegHMO8w.png)](https://towardsdatascience.com/image-segmentation-an-in-depth-guide-5e56512eea2e)

</div>

How can you get a computer to distinguish between different types of
objects in an image? A step-by-step guide.

</div>

<div class="card">

<div class="card-title">

[ChatGPT Vision is insanely good, here is what it can and can’t
do](https://dataconomy.com/2023/10/04/chatgpt-vision-is-insanely-good-here-is-what-it-can-and-cant-do)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2023/10/jonathan-kemper-UF3vfhV04SA-unsplash.jpg)](https://dataconomy.com/2023/10/04/chatgpt-vision-is-insanely-good-here-is-what-it-can-and-cant-do)

</div>

OpenAI's ChatGPT Vision is making waves in the world of artificial
intelligence, but what exactly is it, and how can

</div>

<div class="card">

<div class="card-title">

[Break-A-Scene](https://omriavrahami.com/break-a-scene)

</div>

<div class="card-image">

[![](https://omriavrahami.com/break-a-scene/static/images/teaser_1200_630.jpg)](https://omriavrahami.com/break-a-scene)

</div>

A method for extracting multiple concepts from a single image.

</div>

<div class="card">

<div class="card-title">

[MIT Researchers Created a New Annotated Synthetic Dataset of Images
that
De](https://www.marktechpost.com/2023/09/16/mit-researchers-created-a-new-annotated-synthetic-dataset-of-images-that-depict-a-wide-range-of-scenarios-to-help-machine-learning-models-understand-the-concepts-in-a-scene)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-16-at-4.25.14-AM.png)](https://www.marktechpost.com/2023/09/16/mit-researchers-created-a-new-annotated-synthetic-dataset-of-images-that-depict-a-wide-range-of-scenarios-to-help-machine-learning-models-understand-the-concepts-in-a-scene)

</div>

Large-scale pre-trained Vision and language models have demonstrated
remarkable performance in numerous applications, allowing for the
replacement of a fixed set of supported classes with zero-shot open
vocabulary reasoning over (nearly arbitrary) natural language queries.
However, recent research has revealed a fundamental flaw in these
models. For instance, their inability to comprehend Visual Language
Concepts (VLC) that extend 'beyond nouns,' such as the meaning of
non-object words (e.g., attributes, actions, relations, states, etc.),
or their difficulty with compositional reasoning, such as comprehending
the significance of the word order in a sentence. Vision and language
models, powerful machine-learning algorithms that learn

</div>

<div class="card">

<div class="card-title">

[eBay rolls out a tool that generates product listings from
photos](https://techcrunch.com/2023/09/07/ebay-rolls-out-a-tool-that-generates-product-listings-from-photos)

</div>

<div class="card-image">

[![](https://techcrunch.com/wp-content/uploads/2019/09/GettyImages-632621434.jpg)](https://techcrunch.com/2023/09/07/ebay-rolls-out-a-tool-that-generates-product-listings-from-photos)

</div>

eBay's new generative AI tool, rolling out on iOS first, can write a
product listing from a single photo -- or so the company claims.

</div>

<div class="card">

<div class="card-title">

[MIT CSAIL unveils PhotoGuard, an AI defense against unauthorized image
mani](https://venturebeat.com/ai/mit-csail-unveils-photoguard-an-ai-defense-against-unauthorized-image-manipulation)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_a_humanoid_robot_stands_in_a_red-lit_darkroom_looking_a_4a22ff40-1e9b-417d-812a-03c074a20ddb.png?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/mit-csail-unveils-photoguard-an-ai-defense-against-unauthorized-image-manipulation)

</div>

MIT CSAIL researchers claim PhotoGuard can detect image irregularities
invisible to the human eye through its AI's architectural prowess.

</div>

<div class="card">

<div class="card-title">

[This AI Research Introduces a Novel Two-Stage Pose Distillation for
Whole-B](https://www.marktechpost.com/2023/08/05/this-ai-research-introduces-a-novel-two-stage-pose-distillation-for-whole-body-pose-estimation)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-05-at-6.35.24-PM.png)](https://www.marktechpost.com/2023/08/05/this-ai-research-introduces-a-novel-two-stage-pose-distillation-for-whole-body-pose-estimation)

</div>

Numerous human-centric perception, comprehension, and creation tasks
depend on whole-body pose estimation, including 3D whole-body mesh
recovery, human-object interaction, and posture-conditioned human image
and motion production. Furthermore, using user-friendly algorithms like
OpenPose and MediaPipe, recording human postures for virtual content
development and VR/AR has significantly increased in popularity.
Although these tools are convenient, their performance still needs to
improve, which limits their potential. Therefore, more developments in
human pose assessment technologies are essential to realizing the
promise of user-driven content production.  Comparatively speaking,
whole-body pose estimation presents more difficulties than human pose
estimation with body-only key points detection due to

</div>

<div class="card">

<div class="card-title">

[How to make photos confusing to
AI](https://thehustle.co/how-to-make-photos-confusing-to-ai)

</div>

<div class="card-image">

[![](https://20627419.fs1.hubspotusercontent-na1.net/hubfs/20627419/The%20Hustle/Assets/Images/911911672-httpsthdaily.s3.us-west-1.amazonaws.comfinal_size-confused-robot_20230730235528.webp)](https://thehustle.co/how-to-make-photos-confusing-to-ai)

</div>

A new tool out of MIT makes it so AI cannot edit your photos.

</div>

<div class="card">

<div class="card-title">

[What is an Image Processor? Turns Out the Answer is
Hazy](https://www.allaboutcircuits.com/technical-articles/what-is-an-image-processor-turns-out-the-answer-is-hazy)

</div>

<div class="card-image">

[![](https://www.allaboutcircuits.com/uploads/thumbnails/intro_image_signal_processing_thumbnail.jpg)](https://www.allaboutcircuits.com/technical-articles/what-is-an-image-processor-turns-out-the-answer-is-hazy)

</div>

Real-time image processing is a resource-intensive task that often
requires specialized hardware. With that in mind, let's explore
processors that are designed specifically for photo and video
applications.

</div>

<div class="card">

<div class="card-title">

[Ahead of AI \#10: State of Computer Vision
2023](https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6090e66d-32e4-45e4-b1c3-d739135aa94c_1074x1108.png)](https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer)

</div>

Large language model development (LLM) development is still happening at
a rapid pace.

</div>

<div class="card">

<div class="card-title">

[Introducing Segment Anything: Working toward the first foundation model
for](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation)

</div>

</div>

<div class="card">

<div class="card-title">

[Hands-on Generative AI with GANs using Python: Image
Generation](https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-image-generation-9a62e591c7c6)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*h07aDSTfNQuoPk1a1WhxlQ.png)](https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-image-generation-9a62e591c7c6)

</div>

Learn how to implement GANs with PyTorch to generate synthetic images

</div>

<div class="card">

<div class="card-title">

[Nvidia Tackles Chipmaking Process, Claims 40X Speed Up with
cuLitho](https://www.tomshardware.com/news/nvidia-tackles-chipmaking-process-claims-40x-speed-up-with-culitho)

</div>

<div class="card-image">

[![](https://cdn.mos.cms.futurecdn.net/Vu6N9RDjut8Yy6FiGKNSCB-1200-80.png)](https://www.tomshardware.com/news/nvidia-tackles-chipmaking-process-claims-40x-speed-up-with-culitho)

</div>

Faster masks, less power.

</div>

<div class="card">

<div class="card-title">

[Image Filters with
Python](https://towardsdatascience.com/image-filters-with-python-3dc223a12624?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*h0_6ad6JsubZus2v)](https://towardsdatascience.com/image-filters-with-python-3dc223a12624?source=rss----7f60cf5620c9---4)

</div>

A concise computer vision project for building image filters using
Python

</div>

<div class="card">

<div class="card-title">

[Shopping for Apparel in an Online World: UI/UX Design for Virtual
Clothing](https://www.toptal.com/designers/ux/virtual-clothing-try-on)

</div>

<div class="card-image">

[![](https://bs-uploads.toptal.io/blackfish-uploads/components/open_graph_image/9409265/og_image/optimized/UI-UX-Design-for-Virtual-Clothing-Try-On_Technology_Social__1_-bca6c6bfca76c09aeaca1d62696dbc61.png)](https://www.toptal.com/designers/ux/virtual-clothing-try-on)

</div>

How AR and VR are reshaping apparel e-commerce.

</div>

<div class="card">

<div class="card-title">

[Multi-camera real-time object detection with WebRTC and
YOLO](https://softwarescalability.com/editorial/real-time-object-detection-with-webrtc-and-yolo)

</div>

<div class="card-image">

[![](https://softwarescalability.com/assets/blog/real-time-object-detection-with-webrtc-and-yolo/cover.jpg)](https://softwarescalability.com/editorial/real-time-object-detection-with-webrtc-and-yolo)

</div>

Learn how to build a surveillance system using WebRTC for low-latency
and YOLO for object detection. This tutorial will guide you through the
process of using computer vision and machine learning techniques to
detect and track objects in real-time video streams. With this
knowledge, you can create a surveillance system for security or other
applications. However, there are challenges to consider when using
cameras for object detection, including data privacy and security
concerns, as well as technical limitations such as low image quality and
lighting conditions. This article will teach you how to overcome some of
these challenges and build a reliable surveillance system.

</div>

<div class="card">

<div class="card-title">

[MIT's newest computer vision algorithm identifies images down to the
pixel](https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html)

</div>

<div class="card-image">

[![](https://s.yimg.com/ny/api/res/1.2/mO_NA2J03vyvD4oyvb4xkw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDM-/https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141)](https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html)

</div>

A team of researchers at MIT CSAIL, in collaboration with Cornell
University and Microsoft, have developed STEGO, an algorithm able to
identify images down to the individual pixel.

</div>

<div class="card">

<div class="card-title">

[lucidrains/vit-pytorch: Implementation of Vision Transformer, a simple
way to achieve SOTA in vision classification with only a single
transformer encoder, in
Pytorch](https://github.com/lucidrains/vit-pytorch)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/9edc731f2a99d5a99777494dd7aaa43716ebad2f0f59b90b9e38e48aaecebb2c/lucidrains/vit-pytorch)](https://github.com/lucidrains/vit-pytorch)

</div>

Implementation of Vision Transformer, a simple way to achieve SOTA in
vision classification with only a single transformer encoder, in
Pytorch - lucidrains/vit-pytorch

</div>

<div class="card">

<div class="card-title">

[YOLOv7: A deep dive into the current state-of-the-art for object
detection](https://towardsdatascience.com/yolov7-a-deep-dive-into-the-current-state-of-the-art-for-object-detection-ce3ffedeeaeb?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*wMUHb5UizMu6QSWRfw8SKw.png)](https://towardsdatascience.com/yolov7-a-deep-dive-into-the-current-state-of-the-art-for-object-detection-ce3ffedeeaeb?source=rss----7f60cf5620c9---4)

</div>

Everything you need to know to use YOLOv7 in custom training scripts

</div>

<div class="card">

<div class="card-title">

[A search engine for
shapes](https://www.technologyreview.com/2022/10/25/1060426/a-search-engine-for-shapes)

</div>

<div class="card-image">

[![](https://wp.technologyreview.com/wp-content/uploads/2022/09/ND22_MIT_notes-Tan-thumb.jpg?resize=1200,600)](https://www.technologyreview.com/2022/10/25/1060426/a-search-engine-for-shapes)

</div>

Jianmin “Jamie” Tan, PhD ’90

</div>

<div class="card">

<div class="card-title">

[What is ‘Image Super Resolution’, and why do we need
it?](https://towardsdatascience.com/what-is-image-super-resolution-and-why-do-we-need-it-9c3bd9dc233e)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*7SRhVaFlkEvFfO4AAxqQFw.jpeg)](https://towardsdatascience.com/what-is-image-super-resolution-and-why-do-we-need-it-9c3bd9dc233e)

</div>

An introduction to the field, its applications, and current issues

</div>

<div class="card">

<div class="card-title">

[Image Super-Resolution: An Overview of the Current State of
Research](https://towardsdatascience.com/image-super-resolution-an-overview-of-the-current-state-of-research-94294a77ed5a?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*bSgPxqGzylm7QZGPlPuUpg.png)](https://towardsdatascience.com/image-super-resolution-an-overview-of-the-current-state-of-research-94294a77ed5a?source=rss----7f60cf5620c9---4)

</div>

A review of popular techniques and remaining challenges

</div>

<div class="card">

<div class="card-title">

[The Basics of Object Detection: YOLO, SSD,
R-CNN](https://towardsdatascience.com/the-basics-of-object-detection-yolo-ssd-r-cnn-6def60f51c0b?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*8LMlzkU35e7S31yh)](https://towardsdatascience.com/the-basics-of-object-detection-yolo-ssd-r-cnn-6def60f51c0b?source=rss----7f60cf5620c9---4)

</div>

Overview of how object detection works, and where to get started

</div>

<div class="card">

<div class="card-title">

[A Comprehensive Tutorial on Stereo Geometry and Stereo Rectification
with
P](https://towardsdatascience.com/a-comprehensive-tutorial-on-stereo-geometry-and-stereo-rectification-with-python-7f368b09924a)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*bq7TY8eW7Q6dlwHh2LwQVA.jpeg)](https://towardsdatascience.com/a-comprehensive-tutorial-on-stereo-geometry-and-stereo-rectification-with-python-7f368b09924a)

</div>

Everything you need to know about Stereo Geometry

</div>

<div class="card">

<div class="card-title">

[The New Normal: The Coming Tsunami of
Fakery](https://grandy.substack.com/p/the-new-normal-the-coming-tsunami)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2c9ecb5-eb24-449c-974a-014606a87d9a_680x383.jpeg)](https://grandy.substack.com/p/the-new-normal-the-coming-tsunami)

</div>

How the Dead Internet Theory is fast becoming reality thanks to zero,
marginal-cost content generated at infinite scale

</div>

<div class="card">

<div class="card-title">

[How to Perform Motion Detection Using Python -
KDnuggets](https://www.kdnuggets.com/2022/08/perform-motion-detection-python.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/yada_perform_motion_detection_python_2.gif)](https://www.kdnuggets.com/2022/08/perform-motion-detection-python.html)

</div>

In this article, we will specifically take a look at motion detection
using a webcam of a laptop or computer and will create a code script to
work on our computer and see its real-time example.

</div>

<div class="card">

<div class="card-title">

[What is YOLOv7? A Complete
Guide.](https://blog.roboflow.com/yolov7-breakdown)

</div>

<div class="card-image">

[![](https://blog.roboflow.com/content/images/size/w1200/2022/07/YOLOv7_explained.webp)](https://blog.roboflow.com/yolov7-breakdown)

</div>

In this guide, we discuss what YOLOv7 is, how the model works, and the
novel model architecture changes in YOLOv7.

</div>

<div class="card">

<div class="card-title">

[YOLOv7: Trainable bag-of-freebies sets new state-of-the-art
for...](https://arxiv.org/abs/2207.02696)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2207.02696)

</div>

YOLOv7 surpasses all known object detectors in both speed and accuracy
in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8% AP
among all known real-time object detectors with 30...

</div>

<div class="card">

<div class="card-title">

[YOLOv6: next-generation object detection — review and
comparison](https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*ntuxZniu-76-7ODdQmaemA.jpeg)](https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f?source=rss----7f60cf5620c9---4)

</div>

eview and comparison of the next generation object detection

</div>

<div class="card">

<div class="card-title">

[NVIDIA NeRF AI Renders Amazingly Realistic 3D Scenes From 2D Photos In
Just](https://hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds)

</div>

<div class="card-image">

[![](https://images.hothardware.com/contentimages/newsitem/58082/content/small_nvidia_nerf_thumbnail.jpg)](https://hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds)

</div>

It takes a human being around 0.1 to 0.4 seconds to blink. In even less
time, an AI-based inverse rendering process developed by NVIDIA can
generate a 3D scene from 2D photos.

</div>

<div class="card">

<div class="card-title">

[Are You Better Than a Machine at Spotting a
Deepfake?](https://www.scientificamerican.com/podcast/episode/are-you-better-than-a-machine-at-spotting-a-deepfake)

</div>

<div class="card-image">

[![](https://static.scientificamerican.com/sciam/cache/file/FF9411E3-6975-4B44-BD7E6544E9363865_source.jpg?w=1200)](https://www.scientificamerican.com/podcast/episode/are-you-better-than-a-machine-at-spotting-a-deepfake)

</div>

New research shows that detecting digital fakes generated by machine
learning might be a job best done with humans still in the loop.

</div>

<div class="card">

<div class="card-title">

[Asset2Vec: Turning 3D Objects into Vectors and
Back](https://towardsdatascience.com/asset2vec-turning-3d-objects-into-vectors-and-back-8335496b756d)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:963/1*EKdPweq5B-8w7dnkYKXQ2g.png)](https://towardsdatascience.com/asset2vec-turning-3d-objects-into-vectors-and-back-8335496b756d)

</div>

How we used NeRF to embed our entire 3D object catalogue to a shared
latent space, and what it means for the future of graphics

</div>

<div class="card">

<div class="card-title">

[Curating a Dataset from Raw Images and
Videos](https://link.medium.com/PdMh44o0Fmb)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*xNDajhqQHMydCUrB)](https://link.medium.com/PdMh44o0Fmb)

</div>

Best-practices to follow when building datasets from large pools of
image and video data and tools that make it straightforward.

</div>

<div class="card">

<div class="card-title">

[How to stop AI from recognizing your face in selfies \| MIT Technology
Revie](https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview)

</div>

<div class="card-image">

[![](https://wp.technologyreview.com/wp-content/uploads/2021/05/james-barr-L_f7x_Uv5Qs-unsplash.jpg?resize=1200,600)](https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview)

</div>

A growing number of tools now let you stop facial recognition systems
from training on your personal photos

</div>

<div class="card">

<div class="card-title">

[Detecting Twenty-thousand Classes using Image-level
Supervision](https://arxiv.org/abs/2201.02605v2)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2201.02605v2)

</div>

Current object detectors are limited in vocabulary size due to the small
scale of detection datasets. Image classifiers, on the other hand,
reason about much larger vocabularies, as their datasets...

</div>

<div class="card">

<div class="card-title">

[HRNet explained: Human Pose Estimation, Semantic Segmentation and
Object
De](https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg)](https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4)

</div>

Revealing whats behind the state-of-the art algorithm HRNet

</div>

<div class="card">

<div class="card-title">

[Essential Linux Command-Line Tricks for Computer Vision
Researchers](https://towardsdatascience.com/essential-linux-command-line-tricks-for-computer-vision-researchers-27d4f013d9a?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*Ybu9fEJ8EG4SY9JGpycwmA.jpeg)](https://towardsdatascience.com/essential-linux-command-line-tricks-for-computer-vision-researchers-27d4f013d9a?source=rss----7f60cf5620c9---4)

</div>

In this post, you will learn some cool command line tricks which can
help you to speed up your day-to-day R&D.

</div>

<div class="card">

<div class="card-title">

[Object Detection Algorithms and Libraries -
neptune.ai](https://neptune.ai/blog/object-detection-algorithms-and-libraries)

</div>

<div class="card-image">

[![](https://neptune.ai/wp-content/uploads/2022/07/blog_feature_image_015601_7_0_1_8.jpg)](https://neptune.ai/blog/object-detection-algorithms-and-libraries)

</div>

A guide on object detection algorithms and libraries that covers use
cases, technical details, and offers a look into modern applications.

</div>

<div class="card">

<div class="card-title">

[10 Computer Vision Terms Everyone Must Know
About!](https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*LFhMuFB1_hyYnoE2)](https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8?source=rss----7f60cf5620c9---4)

</div>

The ten essential computer vision terminologies that everyone should
learn to become more proficient at computer vision with sample codes

</div>

<div class="card">

<div class="card-title">

[Researchers Create 'Master Faces' to Bypass Facial
Recognition](https://www.vice.com/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition)

</div>

<div class="card-image">

[![](https://www.vice.com/wp-content/uploads/sites/2/2021/08/1628529155600-gettyimages-607358443.jpeg?resize=2000,1331)](https://www.vice.com/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition)

</div>

According to the paper, their findings imply that facial recognition
systems are “extremely vulnerable.”

</div>

<div class="card">

<div class="card-title">

[5 Ultimate Python Libraries for Image
Processing](https://towardsdatascience.com/5-ultimate-python-libraries-for-image-processing-13f89d32769e?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*7SF7Ai0xkGVZ5i-Xi5ABxg.jpeg)](https://towardsdatascience.com/5-ultimate-python-libraries-for-image-processing-13f89d32769e?source=rss----7f60cf5620c9---4)

</div>

OpenCV is not the only one

</div>

<div class="card">

<div class="card-title">

[Same or Different? The Question Flummoxes Neural Networks. \| Quanta
Magazine](https://www.quantamagazine.org/same-or-different-ai-cant-tell-20210623?fbclid=IwAR0tGsjpYIg0UnsKf7ZN_qDqfU0-KFWFKTEUbGxNhzy7scUzixyn8HJDG6s)

</div>

<div class="card-image">

[![](https://www.quantamagazine.org/wp-content/uploads/2021/06/Same_different_520x292.jpg)](https://www.quantamagazine.org/same-or-different-ai-cant-tell-20210623?fbclid=IwAR0tGsjpYIg0UnsKf7ZN_qDqfU0-KFWFKTEUbGxNhzy7scUzixyn8HJDG6s)

</div>

For all their triumphs, AI systems can’t seem to generalize the concepts
of “same” and “different.” Without that, researchers worry, the quest to
create truly intelligent machines may be hopeless.

</div>

<div class="card">

<div class="card-title">

[Complete Guide to Data Augmentation for Computer
Vision](https://towardsdatascience.com/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*I9uwq0r1x_4Gs1x9)](https://towardsdatascience.com/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07?source=rss----7f60cf5620c9---4)

</div>

Data Augmentation is one of the most important topics in Deep Computer
Vision. When you train your neural network, you should do data
augmentation like… ALWAYS. Otherwise, you are not using your…

</div>

<div class="card">

<div class="card-title">

[Surviving an In-Flight Anomaly: What Happened on Ingenuity’s Sixth
Flight
-](https://mars.nasa.gov/technology/helicopter/status/305/surviving-an-in-flight-anomaly-what-happened-on-ingenuitys-sixth-flight)

</div>

<div class="card-image">

[![](https://science.nasa.gov/wp-content/uploads/2024/03/PIA24600-16x9-1.jpg?w=1024)](https://mars.nasa.gov/technology/helicopter/status/305/surviving-an-in-flight-anomaly-what-happened-on-ingenuitys-sixth-flight)

</div>

On the 91st Martian day, or sol, of NASA’s Mars 2020 Perseverance rover
mission, the Ingenuity Mars Helicopter performed its sixth flight. The
flight was designed to expand the flight envelope and demonstrate
aerial-imaging capabilities by taking stereo images of a region of
interest to the west. Ingenuity was commanded to climb to an altitude of
33 feet (10 meters) before translating 492 feet (150 meters) to the
southwest at a ground speed of 9 mph (4 meters per second). At that
point, it was to translate 49 feet (15 meters) to the south while taking
images toward the west, then fly another 164 feet (50 meters) northeast
and land.

</div>

<div class="card">

<div class="card-title">

[Essential Linear Algebra for Data Science and Machine Learning -
KDnuggets](https://www.kdnuggets.com/2021/05/essential-linear-algebra-data-science-machine-learning.html)

</div>

Linear algebra is foundational in data science and machine learning.
Beginners starting out along their learning journey in data science--as
well as established practitioners--must develop a strong familiarity
with the essential concepts in linear algebra.

</div>

<div class="card">

<div class="card-title">

[How image search works at Dropbox -
Dropbox](https://dropbox.tech/machine-learning/how-image-search-works-at-dropbox)

</div>

<div class="card-image">

[![](https://aem.dropbox.com/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/Techblog-ImageSearch-Social2.png)](https://dropbox.tech/machine-learning/how-image-search-works-at-dropbox)

</div>

</div>

<div class="card">

<div class="card-title">

[Top 5 Python libraries for Computer
vision](https://dev.to/stokry/top-5-python-libraries-for-computer-vision-47ga)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F0qrkw79dpm95yxooymed.gif)](https://dev.to/stokry/top-5-python-libraries-for-computer-vision-47ga)

</div>

Computer vision is the field of computer science that focuses on
replicating parts of the complexity...

</div>

<div class="card">

<div class="card-title">

[jsbroks/coco-annotator: :pencil2: Web-based image segmentation tool for
object detection, localization, and
keypoints](https://github.com/jsbroks/coco-annotator)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/f01ecb12313062fed4e67e6dff3962623e45766c631ad1db3fc6432ec852aeb2/jsbroks/coco-annotator)](https://github.com/jsbroks/coco-annotator)

</div>

:pencil2: Web-based image segmentation tool for object detection,
localization, and keypoints - jsbroks/coco-annotator

</div>

<div class="card">

<div class="card-title">

[Gentle introduction to 2D Hand Pose Estimation: Approach
Explained](https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*CvYL8OI0js7MWUlM)](https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11?source=rss----7f60cf5620c9---4)

</div>

Detailed tutorial on where to find a dataset, how to preprocess data,
what model architecture and loss to use, and, finally, how to…

</div>

<div class="card">

<div class="card-title">

[A Beginner’s Guide to Image Augmentations in Machine
Learning](https://towardsdatascience.com/a-beginners-guide-to-image-augmentations-in-machine-learning-22c48a2fbd99?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*9A-t8pz7YSCMwJRo)](https://towardsdatascience.com/a-beginners-guide-to-image-augmentations-in-machine-learning-22c48a2fbd99?source=rss----7f60cf5620c9---4)

</div>

Data Augmentation is one of the most important yet underrated aspects of
a machine learning system …

</div>

<div class="card">

<div class="card-title">

[Breaking Through the Uncanny
Valley](https://theness.com/neurologicablog/index.php/breaking-through-the-uncanny-valley)

</div>

<div class="card-image">

[![](https://theness.com/neurologicablog/wp-content/uploads/sites/3/2021/03/creepy-girl-uncanny-valley.jpg)](https://theness.com/neurologicablog/index.php/breaking-through-the-uncanny-valley)

</div>

In 1970 robotics professor Masahiro Mori observed, "Bbukimi no tani
genshō," which was later translated into "uncanny valley". This refers
to an observed phenomenon (first in robots, but also applies to digital
recreations) that the more human-like the robot the greater the
emotional affinity of people. However, as imitation approaches complete
imitation it takes a

</div>

<div class="card">

<div class="card-title">

[Image Feature Extraction Using
PyTorch](https://towardsdatascience.com/image-feature-extraction-using-pytorch-e3b327c3607a?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*P69zpl--JsVRSIVXL0hUzw.jpeg)](https://towardsdatascience.com/image-feature-extraction-using-pytorch-e3b327c3607a?source=rss----7f60cf5620c9---4)

</div>

Case Study: Image Clustering using K-Means Algorithm

</div>

<div class="card">

<div class="card-title">

[New AI tool detects Deepfakes by analyzing light reflections in the
eyes](https://thenextweb.com/neural/2021/03/11/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist)

</div>

<div class="card-image">

[![](https://img-cdn.tnwcdn.com/image/tnw-blurple?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F03%2Fimage-2-1.jpg&signature=6421c014d99170a1da5339281bea3e7a)](https://thenextweb.com/neural/2021/03/11/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist)

</div>

Computer scientists from the University at Buffalo used the method to
successfully detect Deepfakes taken from This Person Does Not Exist.

</div>

<div class="card">

<div class="card-title">

[Deep Nostalgia AI brings your photos to life just like in the ‘Harry
Potter](https://www.fastcompany.com/90611504/deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies?partner=feedburner)

</div>

<div class="card-image">

[![](https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2021/03/p-1-deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies.gif)](https://www.fastcompany.com/90611504/deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies?partner=feedburner)

</div>

Deep Nostalgia AI brings your photos to life just like in the Harry
Potter movies.

</div>

<div class="card">

<div class="card-title">

[State-of-the-Art Image Generation
Models](https://arankomatsuzaki.wordpress.com/2021/03/04/state-of-the-art-image-generative-models)

</div>

<div class="card-image">

[![](https://arankomatsuzaki.wordpress.com/wp-content/uploads/2021/03/fig1.jpg?w=1200)](https://arankomatsuzaki.wordpress.com/2021/03/04/state-of-the-art-image-generative-models)

</div>

I have aggregated some of the SotA image generative models released
recently, with short summaries, visualizations and comments. The overall
development is summarized, and the future trends are spe…

</div>

<div class="card">

<div class="card-title">

[How to Use Roboflow and Streamlit to Visualize Object Detection
Output](https://link.medium.com/MBOlUwEWaeb)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*asY-S_5_Nf5x__Mc.gif)](https://link.medium.com/MBOlUwEWaeb)

</div>

Building an app for blood cell count detection.

</div>

<div class="card">

<div class="card-title">

[Image Processing with Python — Using RG
Chromaticity](https://towardsdatascience.com/image-processing-with-python-using-rg-chromaticity-c585e7905818?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:712/1*yVaiKs01yoCxSo2CfhUQ0A.png)](https://towardsdatascience.com/image-processing-with-python-using-rg-chromaticity-c585e7905818?source=rss----7f60cf5620c9---4)

</div>

How to use the Gaussian Distribution for Image Segmentation

</div>

<div class="card">

<div class="card-title">

[Object Tracking \| Papers With
Code](https://paperswithcode.com/task/object-tracking)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-27_at_20.19.02_be6jLVT_XnabzXC.png)](https://paperswithcode.com/task/object-tracking)

</div>

\*\*Object tracking\*\* is the task of taking an initial set of object
detections, creating a unique ID for each of the initial detections, and
then tracking each of the objects as they move around frames in a video,
maintaining the ID assignment. State-of-the-art methods involve fusing
data from RGB and event-based cameras to produce more reliable object
tracking. CNN-based models using only RGB images as input are also
effective. The most popular benchmark is OTB. There are several
evaluation metrics specific to object tracking, including HOTA, MOTA,
IDF1, and Track-mAP. ( Image credit: \[Towards-Realtime-MOT
\](https://github.com/Zhongdao/Towards-Realtime-MOT) )

</div>

<div class="card">

<div class="card-title">

[Computer Vision \| Papers With
Code](https://paperswithcode.com/task/denoising)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-28_at_22.38.38_yCcs3qr.png)](https://paperswithcode.com/task/denoising)

</div>

\*\*Denoising\*\* is a task in image processing and computer vision that
aims to remove or reduce noise from an image. Noise can be introduced
into an image due to various reasons, such as camera sensor limitations,
lighting conditions, and compression artifacts. The goal of denoising is
to recover the original image, which is considered to be noise-free,
from a noisy observation. ( Image credit: \[Beyond a Gaussian
Denoiser\](https://arxiv.org/pdf/1608.03981v1.pdf) )

</div>

<div class="card">

<div class="card-title">

[The Child Affective Facial Expression (CAFE) set: validity and
reliability](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285011)

</div>

<div class="card-image">

[![](https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285011)

</div>

Emotional development is one of the largest and most productive areas of
psychological research. For decades, researchers have been fascinated by
how humans respond to, detect, and interpret emotional facial
expressions. Much of the research in this area ...

</div>

</div>
