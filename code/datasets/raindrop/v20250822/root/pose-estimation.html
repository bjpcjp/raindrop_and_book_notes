<html><head><meta charset="utf-8"><title>pose-estimation</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">⟵ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>pose-estimation</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/03/25/a-code-implementation-for-advanced-human-pose-estimation-using-mediapipe-opencv-and-matplotlib/">A Code Implementation for Advanced Human Pose Estimation Using MediaPipe, OpenCV and Matplotlib</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/03/25/a-code-implementation-for-advanced-human-pose-estimation-using-mediapipe-opencv-and-matplotlib/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/03/Screenshot-2025-03-25-at-1.46.40 PM.png" alt=""></a></div>
    <p class="card-excerpt">A Code Implementation Guide to Advanced Human Pose Estimation using MediaPipe, OpenCV and Matplotlib</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://research.google/blog/on-device-real-time-hand-tracking-with-mediapipe/">On-Device, Real-Time Hand Tracking with MediaPipe</a></div>
    <div class="card-image"><a href="https://research.google/blog/on-device-real-time-hand-tracking-with-mediapipe/"><img src="https://storage.googleapis.com/gweb-research2023-media/images/e3ef09568fe6b09d0b93772d3f02dbf3-i.width-800.format-jpeg.jpg" alt=""></a></div>
    <p class="card-excerpt">Posted by Valentin Bazarevsky and Fan Zhang, Research Engineers, Google Research   The ability to perceive the shape and motion of hands can be a v...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/10/20/meet-swimxyz-a-synthetic-dataset-of-swimming-motions-and-videos-containing-3-4m-frames-annotated-with-ground-truth-2d-and-3d-joints">Meet SwimXYZ: A Synthetic Dataset of Swimming Motions and Videos Containing</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/10/20/meet-swimxyz-a-synthetic-dataset-of-swimming-motions-and-videos-containing-3-4m-frames-annotated-with-ground-truth-2d-and-3d-joints"><img src="https://www.marktechpost.com/wp-content/uploads/2023/10/ezgif-5-b8f61baff5.gif" alt=""></a></div>
    <p class="card-excerpt">Human motion capture has emerged as a key tool in various industries, including sports, medical, and character animation for the entertainment sector. Motion capture is utilized in sports for multiple purposes, including injury prevention, injury analysis, video game industry animations, and even generating informative visualization for TV broadcasters. Traditional motion capture systems provide solid results in the majority of circumstances. Still, they are expensive and time-consuming to set up, calibrate, and post-process, making them difficult to utilize on a broad scale. These concerns are made worse for aquatic activities like swimming, which bring up unique problems such as marker reflections</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4">HRNet explained: Human Pose Estimation, Semantic Segmentation and Object De</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg" alt=""></a></div>
    <p class="card-excerpt">Revealing whats behind the state-of-the art algorithm HRNet</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11?source=rss----7f60cf5620c9---4">Gentle introduction to 2D Hand Pose Estimation: Approach Explained</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*CvYL8OI0js7MWUlM" alt=""></a></div>
    <p class="card-excerpt">Detailed tutorial on where to find a dataset, how to preprocess data, what model architecture and loss to use, and, finally, how to…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/task/pose-estimation">Browse the State-of-the-Art in Machine Learning | Papers With Code</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/task/pose-estimation"><img src="https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-28_at_22.28.25_6MeKR2X.png" alt=""></a></div>
    <p class="card-excerpt">**Pose Estimation** is a computer vision task where the goal is to detect the position and orientation of a person or an object. Usually, this is done by predicting the location of specific keypoints like hands, head, elbows, etc. in case of Human Pose Estimation.  A common benchmark for this task is [MPII Human Pose](https://paperswithcode.com/sota/pose-estimation-on-mpii-human-pose)  ( Image credit: [Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose](https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch) )</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/FORTH-ModelBasedTracker/MocapNET">FORTH-ModelBasedTracker/MocapNET: We present MocapNET, an ensemble of SNN e</a></div>
    <div class="card-image"><a href="https://github.com/FORTH-ModelBasedTracker/MocapNET"><img src="https://opengraph.githubassets.com/5fc82e472ef74401676aaf90bb8448c9b11e4e9205f2799ad38005c1bca39190/FORTH-ModelBasedTracker/MocapNET" alt=""></a></div>
    <p class="card-excerpt">We present MocapNET, a real-time method that estimates the 3D human pose directly in the popular Bio Vision Hierarchy (BVH) format, given estimations of the 2D body joints originating from monocula...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="http://ieeexplore.ieee.org/document/8621059">Feature Boosting Network For 3D Pose Estimation</a></div>
    <div class="card-image"><a href="http://ieeexplore.ieee.org/document/8621059"><img src="https://ieeexplore.ieee.org/assets/img/ieee_logo_smedia_200X200.png" alt=""></a></div>
    <p class="card-excerpt">In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image. In this method, the features learned by the convolutional layers are boosted with a new long short-term dependence-aware (LSTD) module, which enables the intermediate convolutional feature maps to perceive the graphical long short-term dependency among different hand (or body) parts using the designed Graphical ConvLSTM. Learning a set of features that are reliable and discriminatively representative of the pose of a hand (or body) part is difficult due to the ambiguities, texture and illumination variation, and self-occlusion in the real application of 3D pose estimation. To improve the reliability of the features for representing each body part and enhance the LSTD module, we further introduce a context consistency gate (CCG) in this paper, with which the convolutional feature maps are modulated according to their consistency with the context representations. We evaluate the proposed method on challenging benchmark datasets for 3D hand pose estimation and 3D full body pose estimation. Experimental results show the effectiveness of our method that achieves state-of-the-art performance on both of the tasks.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thenextweb.com/syndication/2020/02/01/machine-learning-for-everyone-how-to-implement-pose-estimation-in-a-browser-using-your-webcam">Machine learning for everyone: How to implement pose estimation in a browse</a></div>
    <div class="card-image"><a href="https://thenextweb.com/syndication/2020/02/01/machine-learning-for-everyone-how-to-implement-pose-estimation-in-a-browser-using-your-webcam"><img src="https://img-cdn.tnwcdn.com/image/tnw-blurple?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2020%2F01%2FCopy-of-Copy-of-Copy-of-Copy-of-...-5.png&signature=582671f024531819e6affd97994117f8" alt=""></a></div>
    <p class="card-excerpt">The 20th century turned out to be an era of exponential growth in the field of machine learning. The 3000-year-old ancient game of ‘Go’ that computer scientists predicted will take another decade to crack was made possible by Google Brai</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://blog.nanonets.com/human-pose-estimation-2d-guide">A 2019 guide to Human Pose Estimation with Deep Learning</a></div>
    <p class="card-excerpt"></p>
  </div>
</div>
</body></html>
