<html><head><meta charset="utf-8"><title>benchmarks</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">⟵ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>benchmarks</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://lmarena.ai/">Chatbot Arena (formerly LMSYS): Free AI Chat to Compare & Test Best AI Chatbots</a></div>
    <div class="card-image"><a href="https://lmarena.ai/"><img src="https://storage.googleapis.com/public-arena-asset/lmsys.jpg" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://baymard.com/ux-benchmark?_hsenc=p2ANqtz-8vKdTwWLUAiR59qo6YQ_JNSaLK6trzBlYG6V0DtlCCHvakteivmgUcdACP140zbIAtp2EVem2uJQoyPAknl5-ThPCilA&_hsmi=115628620">319 Top Ecommerce Sites Ranked by User Experience Performance – Baymard</a></div>
    <p class="card-excerpt">See the ranked UX performance of the 319 leading ecommerce sites in the US and Europe. The chart summarizes 100,000+ UX performance ratings.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://artificialanalysis.ai/">AI Model & API Providers Analysis | Artificial Analysis</a></div>
    <div class="card-image"><a href="https://artificialanalysis.ai/"><img src="https://artificialanalysis.ai/img/open-graph/og-image.png" alt=""></a></div>
    <p class="card-excerpt">Comparison and analysis of AI models and API hosting providers. Independent benchmarks across key performance metrics including quality, price, output speed & latency.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/">A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.21.48-PM.png" alt=""></a></div>
    <p class="card-excerpt">Context engineering for large language models—frameworks, architectures, and strategies to optimize AI reasoning, and scalability</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2504.20879">The Leaderboard Illusion</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2504.20879"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Measuring progress is fundamental to the advancement of any scientific field. As benchmarks play an increasingly central role, they also grow more susceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems. Yet, in this work we identify systematic issues that have resulted in a distorted playing field. We find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired. We establish that the ability of these providers to choose the best score leads to biased Arena scores due to selective disclosure of performance results. At an extreme, we identify 27 private LLM variants tested by Meta in the lead-up to the Llama-4 release. We also establish that proprietary closed models are sampled at higher rates (number of battles) and have fewer models removed from the arena than open-weight and open-source alternatives. Both these policies lead to large data access asymmetries over time. Providers like Google and OpenAI have received an estimated 19.2% and 20.4% of all data on the arena, respectively. In contrast, a combined 83 open-weight models have only received an estimated 29.7% of the total data. We show that access to Chatbot Arena data yields substantial benefits; even limited additional data can result in relative performance gains of up to 112% on the arena distribution, based on our conservative estimates. Together, these dynamics result in overfitting to Arena-specific dynamics rather than general model quality. The Arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform. We offer actionable recommendations to reform the Chatbot Arena's evaluation framework and promote fairer, more transparent benchmarking for the field</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://git.zib.de/qopt/qoblib-quantum-optimization-benchmarking-library">QOpt / QOBLIB - Quantum Optimization Benchmarking Library · GitLab</a></div>
    <div class="card-image"><a href="https://git.zib.de/qopt/qoblib-quantum-optimization-benchmarking-library"><img src="https://git.zib.de/assets/twitter_card-570ddb06edf56a2312253c5872489847a0f385112ddbcd71ccfa1570febab5d2.jpg" alt=""></a></div>
    <p class="card-excerpt">This is the ZIB GitLab instance</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="http://www.techmeme.com/250407/p2#a250407p2">A look at the ARC-AGI exam designed by French computer scientist François Chollet to show the gulf between AI models' memorized answers and “fluid intelligence”</a></div>
    <div class="card-image"><a href="http://www.techmeme.com/250407/p2#a250407p2"><img src="https://i.imgur.com/q0p1thB.jpg" alt=""></a></div>
    <p class="card-excerpt">By Matteo Wong / The Atlantic. View the full context on Techmeme.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.theatlantic.com/technology/archive/2025/04/arc-agi-chollet-test/682295/?gift=2iIN4YrefPjuvZ5d2Kh3089M3DxlABplHmODO9XssmE&utm_source=copy-link&utm_medium=social&utm_campaign=share">The Man Out to Prove How Dumb AI Still Is</a></div>
    <div class="card-image"><a href="https://www.theatlantic.com/technology/archive/2025/04/arc-agi-chollet-test/682295/?gift=2iIN4YrefPjuvZ5d2Kh3089M3DxlABplHmODO9XssmE&utm_source=copy-link&utm_medium=social&utm_campaign=share"><img src="https://cdn.theatlantic.com/thumbor/TQ7unWwrL3WWTg13JHKKLeS9j1w=/0x43:2000x1085/1200x625/filters:watermark(https://cdn.theatlantic.com/media/files/badge_2x.png,-20,20,0,33)/media/img/mt/2025/04/THE_ATLANTIC_ANIMATION_V2/original.gif" alt=""></a></div>
    <p class="card-excerpt">François Chollet has constructed the ultimate test for the bots.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://developer.nvidia.com/blog/llm-benchmarking-fundamental-concepts/">LLM Benchmarking: Fundamental Concepts | NVIDIA Technical Blog</a></div>
    <div class="card-image"><a href="https://developer.nvidia.com/blog/llm-benchmarking-fundamental-concepts/"><img src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/03/data-center.png" alt=""></a></div>
    <p class="card-excerpt">The past few years have witnessed the rise in popularity of generative AI and large language models (LLMs), as part of a broad AI revolution.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2025/04/02/what-is-meteor-score/">What is METEOR score? - Dataconomy</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2025/04/02/what-is-meteor-score/"><img src="https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png" alt=""></a></div>
    <p class="card-excerpt">METEOR Score is a metric used to evaluate the quality of machine translation based on precision, recall, word alignment, and linguistic flexibility.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://artificialanalysis.ai/leaderboards/models">LLM Leaderboard</a></div>
    <div class="card-image"><a href="https://artificialanalysis.ai/leaderboards/models"><img src="https://artificialanalysis.ai/img/open-graph/og-image.png" alt=""></a></div>
    <p class="card-excerpt">Comparison and ranking the performance of over 30 AI models (LLMs) across key metrics including quality, price, performance and speed (output speed - tokens per second & latency - TTFT), context window & others.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/aidanmclaughlin/AidanBench">aidanmclaughlin/AidanBench: Aidan Bench attempts to measure in LLMs.</a></div>
    <div class="card-image"><a href="https://github.com/aidanmclaughlin/AidanBench"><img src="https://repository-images.githubusercontent.com/838396720/3107078a-5021-424f-a295-6306de266b1e" alt=""></a></div>
    <p class="card-excerpt">Aidan Bench attempts to measure  in LLMs. - aidanmclaughlin/AidanBench</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/06/19/key-metrics-for-evaluating-large-language-models-llms">Key Metrics for Evaluating Large Language Models (LLMs)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/06/19/key-metrics-for-evaluating-large-language-models-llms"><img src="https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-7.20.10-PM-1024x906.png" alt=""></a></div>
    <p class="card-excerpt">Evaluating Large Language Models (LLMs) is a challenging problem in language modeling, as real-world problems are complex and variable. Conventional benchmarks frequently fail to fully represent LLMs' all-encompassing performance. A recent LinkedIn post has emphasized a number of important measures that are essential to comprehend how well new models function, which are as follows. MixEval Achieving a balance between thorough user inquiries and effective grading systems is necessary for evaluating LLMs. Conventional standards based on ground truth and LLM-as-judge benchmarks encounter difficulties such as biases in grading and possible contamination over time.  MixEval solves these problems by combining real-world user</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://spectrum.ieee.org/mlperf-nvidia-conquers">Nvidia Conquers Latest AI Tests​</a></div>
    <div class="card-image"><a href="https://spectrum.ieee.org/mlperf-nvidia-conquers"><img src="https://spectrum.ieee.org/media-library/row-upon-row-of-computers-emerging-from-the-darkness.jpg?id=52442384&width=1200&height=600&coordinates=0%2C20%2C0%2C20" alt=""></a></div>
    <p class="card-excerpt">GPU maker tops new MLPerf benchmarks on graph neural nets and LLM fine-tuning</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM Leaderboard : a Hugging Face Space by HuggingFaceH4</a></div>
    <div class="card-image"><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/spaces/open-llm-leaderboard/open_llm_leaderboard.png" alt=""></a></div>
    <p class="card-excerpt">Track, rank and evaluate open LLMs and chatbots</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://benchmarks.llmonitor.com">Asking 60+ LLMs a set of 20 questions</a></div>
    <p class="card-excerpt">Human-readable benchmarks of 60+ open-source and proprietary LLMs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.turingpost.com/p/top3llmsope">A Deep Dive Into LLaMA, Falcon, Llama 2 and Their Remarkable Fine-Tuned Ver</a></div>
    <div class="card-image"><a href="https://www.turingpost.com/p/top3llmsope"><img src="https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/f739d30a-90f3-4c02-9e23-f40e93f92c28/Frame_143.png?t=1693246280" alt=""></a></div>
    <p class="card-excerpt">Exploring the Development of the 3 Leading Open LLMs and Their Chatbot Derivatives</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/06/calculate-computational-efficiency-deep-learning-models-flops-macs.html">Calculate Computational Efficiency of Deep Learning Models with FLOPs and M</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/06/calculate-computational-efficiency-deep-learning-models-flops-macs.html"><img src="https://www.kdnuggets.com/wp-content/uploads/li_calculate_computational_efficiency_deep_learning_models_flops_macs_2.png" alt=""></a></div>
    <p class="card-excerpt">In this article we will learn about its definition, differences and how to calculate FLOPs and MACs using Python packages.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://hgpu.org/?p=28050">Towards a Benchmarking Suite for Kernel Tuners</a></div>
    <div class="card-image"><a href="https://hgpu.org/?p=28050"><img src="https://hgpu.org/img/social-logo.png" alt=""></a></div>
    <p class="card-excerpt">As computing system become more complex, it is becoming harder for programmers to keep their codes optimized as the hardware gets updated. Autotuners try to alleviate this by hiding as many archite…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.datasciencecentral.com/how-to-choose-the-best-machine-learning-technique-comparison-table">How to Choose the Best Machine Learning Technique: Comparison Table</a></div>
    <div class="card-image"><a href="https://www.datasciencecentral.com/how-to-choose-the-best-machine-learning-technique-comparison-table"><img src="https://www.datasciencecentral.com/wp-content/uploads/2022/11/jp3-scaled.jpg" alt=""></a></div>
    <p class="card-excerpt">How to Choose the Best Machine Learning Technique: Comparison Table</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nngroup.com/articles/product-ux-benchmarks">7 Steps to Benchmark Your Product’s UX</a></div>
    <div class="card-image"><a href="https://www.nngroup.com/articles/product-ux-benchmarks"><img src="https://media.nngroup.com/media/articles/opengraph_images/7-Steps-Benchmark_Social-Media-Posts_2020.png" alt=""></a></div>
    <p class="card-excerpt">Benchmark your UX by first determining appropriate metrics and a study methodology. Then track these metrics across different releases of your product by running studies that follow the same established methodology.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/12-twitter-sentiment-analysis-algorithms-compared-23e2d2c63d90?source=rss----7f60cf5620c9---4">12 Twitter Sentiment Analysis Algorithms Compared</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/12-twitter-sentiment-analysis-algorithms-compared-23e2d2c63d90?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/0*kJawLKlRt398g2xy.jpg" alt=""></a></div>
    <p class="card-excerpt">12 sentiment analysis algorithms were compared on the accuracy of tweet classification. The fasText deep learning system was the winner.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="http://benchmarkfcns.xyz/fcns">Benchmark functions | BenchmarkFcns</a></div>
    <p class="card-excerpt">This website is for sale! benchmarkfcns.xyz is your first and best source for all of the information you’re looking for. From general topics to more of what you would expect to find here, benchmarkfcns.xyz has it all. We hope you find what you are searching for!</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://openai.com/blog/ai-and-efficiency">AI and Efficiency</a></div>
    <div class="card-image"><a href="https://openai.com/blog/ai-and-efficiency"><img src="https://images.ctfassets.net/kftzwdyauwt9/e5cba1f8-883b-4961-dca6f726f936/be1a627ab2f509a68b91b8a7ef29f610/image_128.png?w=1600&h=900&fit=fill" alt=""></a></div>
    <p class="card-excerpt">We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="http://blog.bigml.com/2020/03/20/machine-learning-benchmarking-youre-doing-it-wrong">Machine Learning Benchmarking: You’re Doing It Wrong</a></div>
    <div class="card-image"><a href="http://blog.bigml.com/2020/03/20/machine-learning-benchmarking-youre-doing-it-wrong"><img src="https://blog.bigml.com/wp-content/uploads/2020/03/fruit_apples_produce_oranges_comparison_supermaket_chalkandcheese_applesandpears-464484.jpg?w=497" alt=""></a></div>
    <p class="card-excerpt">I’m not going to bury the lede: Most machine learning benchmarks are bad.  And not just kinda-sorta nit-picky bad, but catastrophically and fundamentally flawed.  TL;DR: Please, for the love of sta…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://mlperf.org">Benchmark Work | Benchmarks MLCommons</a></div>
    <div class="card-image"><a href="https://mlperf.org"><img src="https://mlcommons.org/wp-content/uploads/2023/10/decoration-2.png" alt=""></a></div>
    <p class="card-excerpt">MLCommons ML benchmarks help balance the benefits and risks of AI through quantitative tools that guide responsible AI development.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://mlperf.org/inference-results">Inference Results – MLPerf</a></div>
    <div class="card-image"><a href="https://mlperf.org/inference-results"><img src="https://mlcommons.org/wp-content/uploads/2023/10/decoration-2.png" alt=""></a></div>
    <p class="card-excerpt">MLCommons ML benchmarks help balance the benefits and risks of AI through quantitative tools that guide responsible AI development.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://docs.google.com/presentation/d/1j_-tDctiFQew9PAKMZPvH87rFeXCSIcP81Ti8CDGnLg/edit?usp=embed_facebook">Buyer UX ecommerce Benchmarking</a></div>
    <div class="card-image"><a href="https://docs.google.com/presentation/d/1j_-tDctiFQew9PAKMZPvH87rFeXCSIcP81Ti8CDGnLg/edit?usp=embed_facebook"><img src="https://lh7-us.googleusercontent.com/docs/AHkbwyIbKFrYx10_wOZnlNkHuuz1xGHxf5lE1gUiH17pWc4PjAVoA3XpKiXARePf-FLnzFQJFuamxVwUFGFI1BiYqqyyEQi-LRhvSXLEGYXCqeCSewEKxgTG=w1200-h630-p" alt=""></a></div>
    <p class="card-excerpt">Buyer Experience Benchmarking of 5 Top eCommerce Sites Dec 2018 Ken Leaver</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nextplatform.com/2018/08/30/one-deep-learning-benchmark-to-rule-them-all">One Deep Learning Benchmark to Rule Them All</a></div>
    <div class="card-image"><a href="https://www.nextplatform.com/2018/08/30/one-deep-learning-benchmark-to-rule-them-all"><img src="https://www.nextplatform.com/wp-content/uploads/2016/05/TPU_main2-1024x1024.jpg" alt=""></a></div>
    <p class="card-excerpt">Over the last few years we have detailed the explosion in new machine learning systems with the influx of novel architectures from deep learning chip</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://machinelearningmastery.com/start-with-gradient-boosting">Start With Gradient Boosting, Results from Comparing 13 Algorithms on 165 D</a></div>
    <div class="card-image"><a href="https://machinelearningmastery.com/start-with-gradient-boosting"><img src="https://machinelearningmastery.com/wp-content/uploads/2018/01/Algorithm-performance-improvement-via-parameter-tuning.png" alt=""></a></div>
    <p class="card-excerpt">Which machine learning algorithm should you use? It is a central question in applied machine learning. In a recent paper by Randal Olson and others, they attempt to answer it and give you a guide for algorithms and parameters to try on your problem first, before spot checking a broader suite of algorithms. In this post, you will discover a…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.google.com/search?aqs=chrome..69i57.7070j0j7&ie=UTF-8&oq=machine+learning+benchmarks&q=machine+learning+benchmarks&sourceid=chrome">machine learning benchmarks - Google Search</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="http://jakevdp.github.io/blog/2014/05/09/why-python-is-slow">Why Python is Slow: Looking Under the Hood | Pythonic Perambulations</a></div>
    <p class="card-excerpt"></p>
  </div>
</div>
</body></html>
