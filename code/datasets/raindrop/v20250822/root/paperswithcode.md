<div class="nav">

⟵ [Up](index.html)  \|  [Index](index.html)

</div>

# paperswithcode

<div class="cards">

<div class="card">

<div class="card-title">

[How To Build an LLM-Powered App To Chat with
PapersWithCode](https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*0AW3FGe41K7h3E0p)](https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4)

</div>

Keep up with the latest ML research

</div>

<div class="card">

<div class="card-title">

[ArXiv.org Reaches a Milestone and a
Reckoning](https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning)

</div>

<div class="card-image">

[![](https://static.scientificamerican.com/sciam/cache/file/AFD5B975-B600-4C35-AA8B265090FFE58E_source.jpg?w=1200)](https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning)

</div>

Runaway success and underfunding have led to growing pains for the
preprint server

</div>

<div class="card">

<div class="card-title">

[PyTorch vs TensorFlow in
2023](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022)

</div>

<div class="card-image">

[![](https://www.assemblyai.com/blog/content/images/size/w1200/2023/01/pytorch_vs_tensorflow_2023.png)](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022)

</div>

Should you use PyTorch vs TensorFlow in 2023? This guide walks through
the major pros and cons of PyTorch vs TensorFlow, and how you can pick
the right framework.

</div>

<div class="card">

<div class="card-title">

[louisfb01/best_AI_papers_2021: A curated list of the latest
breakthroughs in AI (in 2021) by release date with a clear video
explanation, link to a more in-depth article, and
code.](https://github.com/louisfb01/best_AI_papers_2021)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/4ddf0f05bcc43ff97da72ed99caa033c5b6740257f8a08e1a985e8785441c523/louisfb01/best_AI_papers_2021)](https://github.com/louisfb01/best_AI_papers_2021)

</div>

A curated list of the latest breakthroughs in AI (in 2021) by release
date with a clear video explanation, link to a more in-depth article,
and code. - louisfb01/best_AI_papers_2021

</div>

<div class="card">

<div class="card-title">

[Four Deep Learning Papers to Read in December
2021](https://towardsdatascience.com/four-deep-learning-papers-to-read-in-december-2021-e28f31e6aab4?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*Z5toROiPiwNvvpwOXywFoA.png)](https://towardsdatascience.com/four-deep-learning-papers-to-read-in-december-2021-e28f31e6aab4?source=rss----7f60cf5620c9---4)

</div>

From Sensory Substitution to Decision Transformers, Persistent Evolution
Strategies and Sharpness-Aware Minimization

</div>

<div class="card">

<div class="card-title">

[Papers with Code - Paper with Code
Newsletter](https://paperswithcode.com/newsletter)

</div>

<div class="card-image">

[![](https://paperswithcode.com/static/logo.png)](https://paperswithcode.com/newsletter)

</div>

Papers With Code highlights trending Machine Learning research and the
code to implement it.

</div>

<div class="card">

<div class="card-title">

[The Methods Corpus \| Papers With
Code](https://paperswithcode.com/methods)

</div>

<div class="card-image">

[![](https://paperswithcode.com/static/methods.jpeg)](https://paperswithcode.com/methods)

</div>

2284 methods • 143838 papers with code.

</div>

<div class="card">

<div class="card-title">

[Papers with Code 2020
Review](https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*rErHDsF_8dtSYWjs0rpcTQ.png)](https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658)

</div>

Papers with Code indexes various machine learning artifacts — papers,
code, results — to facilitate discovery and comparison. Using this…

</div>

<div class="card">

<div class="card-title">

[Methodology \| Papers With
Code](https://paperswithcode.com/task/representation-learning)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/representation-learning_Rkb0arA.jpeg)](https://paperswithcode.com/task/representation-learning)

</div>

\*\*Representation Learning\*\* is a process in machine learning where
algorithms extract meaningful patterns from raw data to create
representations that are easier to understand and process. These
representations can be designed for interpretability, reveal hidden
features, or be used for transfer learning. They are valuable across
many fundamental machine learning tasks like \[image
classification\](/task/image-classification) and
\[retrieval\](/task/image-retrieval). Deep neural networks can be
considered representation learning models that typically encode
information which is projected into a different subspace. These
representations are then usually passed on to a linear classifier to,
for instance, train a classifier. Representation learning can be divided
into: - \*\*Supervised representation learning\*\*: learning
representations on task A using annotated data and used to solve task
B - \*\*Unsupervised representation learning\*\*: learning
representations on a task in an unsupervised way (label-free data).
These are then used to address downstream tasks and reducing the need
for annotated data when learning news tasks. Powerful models like
\[GPT\](/method/gpt) and \[BERT\](/method/bert) leverage unsupervised
representation learning to tackle language tasks. More recently,
\[self-supervised learning (SSL)\](/task/self-supervised-learning) is
one of the main drivers behind unsupervised representation learning in
fields like computer vision and NLP. Here are some additional readings
to go deeper on the task: - \[Representation Learning: A Review and New
Perspectives\](/paper/representation-learning-a-review-and-new) - Bengio
et al. (2012) - \[A Few Words on Representation
Learning\](https://sthalles.github.io/a-few-words-on-representation-learning/) -
Thalles Silva ( Image credit: \[Visualizing and Understanding
Convolutional Networks\](https://arxiv.org/pdf/1311.2901.pdf) )

</div>

<div class="card">

<div class="card-title">

[Computer Vision \| Papers With
Code](https://paperswithcode.com/task/image-retrieval)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/4f7e5080-e315-4357-9918-7169df9995db.png)](https://paperswithcode.com/task/image-retrieval)

</div>

\*\*Image Retrieval\*\* is a fundamental and long-standing computer
vision task that involves finding images similar to a provided query
from a large database. It's often considered as a form of fine-grained,
instance-level classification. Not just integral to image recognition
alongside \[classification\](/task/image-classification) and
\[detection\](/task/image-detection), it also holds substantial business
value by helping users discover images aligning with their interests or
requirements, guided by visual similarity or other parameters. ( Image
credit:
\[DELF\](https://github.com/tensorflow/models/tree/master/research/delf)
)

</div>

<div class="card">

<div class="card-title">

[Computer Vision \| Papers With
Code](https://paperswithcode.com/task/denoising)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-28_at_22.38.38_yCcs3qr.png)](https://paperswithcode.com/task/denoising)

</div>

\*\*Denoising\*\* is a task in image processing and computer vision that
aims to remove or reduce noise from an image. Noise can be introduced
into an image due to various reasons, such as camera sensor limitations,
lighting conditions, and compression artifacts. The goal of denoising is
to recover the original image, which is considered to be noise-free,
from a noisy observation. ( Image credit: \[Beyond a Gaussian
Denoiser\](https://arxiv.org/pdf/1608.03981v1.pdf) )

</div>

<div class="card">

<div class="card-title">

[Computer Vision \| Papers With
Code](https://paperswithcode.com/task/domain-adaptation)

</div>

<div class="card-image">

[![](https://production-media.paperswithcode.com/tasks/Webp.net-resizeimage_2_ioK1H9H.png)](https://paperswithcode.com/task/domain-adaptation)

</div>

\*\*Domain Adaptation\*\* is the task of adapting models across domains.
This is motivated by the challenge where the test and training datasets
fall from different data distributions due to some factor. Domain
adaptation aims to build machine learning models that can be generalized
into a target domain and dealing with the discrepancy across domain
distributions. Further readings: - \[A Brief Review of Domain
Adaptation\](https://paperswithcode.com/paper/a-brief-review-of-domain-adaptation)
( Image credit: \[Unsupervised Image-to-Image Translation
Networks\](https://arxiv.org/pdf/1703.00848v6.pdf) )

</div>

</div>
