<div class="nav">

⟵ [Up](index.html)  \|  [Index](index.html)

</div>

# arxiv

<div class="cards">

<div class="card">

<div class="card-title">

[Understanding the Landscape of Ampere GPU Memory
Errors](https://arxiv.org/html/2508.03513v1)

</div>

</div>

<div class="card">

<div class="card-title">

[Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2506.21734)

</div>

Reasoning, the process of devising and executing complex goal-oriented
action sequences, remains a critical challenge in AI. Current large
language models (LLMs) primarily employ Chain-of-Thought (CoT)
techniques, which suffer from brittle task decomposition, extensive data
requirements, and high latency. Inspired by the hierarchical and
multi-timescale processing in the human brain, we propose the
Hierarchical Reasoning Model (HRM), a novel recurrent architecture that
attains significant computational depth while maintaining both training
stability and efficiency. HRM executes sequential reasoning tasks in a
single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level
module responsible for slow, abstract planning, and a low-level module
handling rapid, detailed computations. With only 27 million parameters,
HRM achieves exceptional performance on complex reasoning tasks using
only 1000 training samples. The model operates without pre-training or
CoT data, yet achieves nearly perfect performance on challenging tasks
including complex Sudoku puzzles and optimal path finding in large
mazes. Furthermore, HRM outperforms much larger models with
significantly longer context windows on the Abstraction and Reasoning
Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and
general-purpose reasoning systems.

</div>

<div class="card">

<div class="card-title">

[LLM Research Papers: The 2025 List (January to
June)](https://sebastianraschka.com/blog/2025/llm-research-papers-the-2025-list-january-to-june.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/llm-research-papers-the-2025-list-january-to-june/hero.jpeg)](https://sebastianraschka.com/blog/2025/llm-research-papers-the-2025-list-january-to-june.html)

</div>

The latest in LLM research with a hand-curated, topic-organized list of
over 200 research papers from 2025.

</div>

<div class="card">

<div class="card-title">

[LLM Research Papers: The 2024
List](https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_campaign=post&utm_medium=web)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba1c2ab-7ae7-4f22-86df-f116f2914cd5_1272x1232.png)](https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_campaign=post&utm_medium=web)

</div>

A curated list of interesting LLM-related research papers from 2024,
shared for those looking for something to read over the holidays.

</div>

<div class="card">

<div class="card-title">

[2504](https://arxiv.org/pdf/2504.11760)

</div>

</div>

<div class="card">

<div class="card-title">

[LLM Post-Training: A Deep Dive into Reasoning Large Language
Models](https://arxiv.org/html/2502.21321?fbclid=IwY2xjawJtMIRleHRuA2FlbQIxMQABHtJFOZyM1YENbtAyJPt3Tu4AwMLLtXMWUkanORsu4qZWoDfwikg1UiegOAkK_aem_4SsqZCqR6ngkPHdizAPnEw)

</div>

</div>

<div class="card">

<div class="card-title">

[Modern GPU core scheduling](https://arxiv.org/pdf/2503.20481)

</div>

</div>

<div class="card">

<div class="card-title">

[Beyond Human Intervention: Algorithmic Collusion through Multi-Agent
Learning Strategies](https://freakonometrics.hypotheses.org/79219)

</div>

<div class="card-image">

[![](https://freakonometrics.hypotheses.org/wp-content/cleo-commons/images/favicon_150x150.png)](https://freakonometrics.hypotheses.org/79219)

</div>

Our paper, Beyond Human Intervention: Algorithmic Collusion through
Multi-Agent Learning Strategies, with Suzie Grondin and Philipp Ratz is
now available online Collusion in market pricing is a concept associated
with human actions to raise market prices through artificially limited
supply. Recently, the idea of algorithmic collusion was put forward,
where the human action in the … Continue reading Beyond Human
Intervention: Algorithmic Collusion through Multi-Agent Learning
Strategies →

</div>

<div class="card">

<div class="card-title">

[Noteworthy LLM Research Papers of
2024](https://sebastianraschka.com/blog/2025/llm-research-2024.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/llm-research-2024/hero.jpg)](https://sebastianraschka.com/blog/2025/llm-research-2024.html)

</div>

This article covers 12 influential AI research papers of 2024, ranging
from mixture-of-experts models to new LLM scaling laws for precision..

</div>

<div class="card">

<div class="card-title">

[An Opinionated Evals Reading List — Apollo
Research](https://www.apolloresearch.ai/blog/an-opinionated-evals-reading-list?utm_source=chatgpt.com)

</div>

<div class="card-image">

[![](http://static1.squarespace.com/static/6593e7097565990e65c886fd/65940f02f1fcb826ed2a7229/670e662d065b1f4ab82aab5e/1734295113640/Screenshot+2024-10-15+at+15.25.10.png?format=1500w)](https://www.apolloresearch.ai/blog/an-opinionated-evals-reading-list?utm_source=chatgpt.com)

</div>

A long reading list of evals papers with recommendations and comments by
the evals team.

</div>

<div class="card">

<div class="card-title">

[The 2025 AI Engineering Reading
List](https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242370c-229f-453d-924a-7a5aa4d20a4c_1090x502.png)](https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web)

</div>

We picked 50 paper/models/blogs across 10 fields in AI Eng: LLMs,
Benchmarks, Prompting, RAG, Agents, CodeGen, Vision, Voice, Diffusion,
Finetuning. If you're starting from scratch, start here.

</div>

<div class="card">

<div class="card-title">

[100 Must-Read Generative AI Papers from
2024](https://open.substack.com/pub/thenuancedperspective/p/100-must-read-generative-ai-papers?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcfe5315-38ae-475d-9b8a-05df56910378_1800x829.png)](https://open.substack.com/pub/thenuancedperspective/p/100-must-read-generative-ai-papers?r=oc5d&utm_medium=ios)

</div>

A comprehensive list of some of the most impactful generative papers
from last year

</div>

<div class="card">

<div class="card-title">

[Blt patches scale better than
tokens](https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[How to Run a Paper Club (also: LIVE at NeurIPS
2024!)](https://open.substack.com/pub/swyx/p/paperclub?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8244e94e-677c-4f4e-affa-928382f1b9be_1678x1378.png)](https://open.substack.com/pub/swyx/p/paperclub?r=oc5d&utm_medium=ios)

</div>

Your ultimate Paper Club Starter Kit, from your friends at the Latent
Space Paper Club, where we have now read 100 papers. Also: Announcing
Latent Space Paper Club LIVE! at Neurips 2024! Join us!

</div>

<div class="card">

<div class="card-title">

[eugeneyan/llm-paper-notes: Notes from the Latent Space paper club.
Follow along or start your
own!](https://github.com/eugeneyan/llm-paper-notes)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/9c85f10ad2727a21d7a3aa7d87a46809444643e5d716c492825f63c34d60b7bd/eugeneyan/llm-paper-notes)](https://github.com/eugeneyan/llm-paper-notes)

</div>

Notes from the Latent Space paper club. Follow along or start your
own! - eugeneyan/llm-paper-notes

</div>

<div class="card">

<div class="card-title">

[chess2vec_short.pdf](https://www.berkkapicioglu.com/wp-content/uploads/2020/07/chess2vec_short.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[Analyzing the homerun year for LLMs: the top-100 most cited AI papers
in 2023, with all medals for open
models.](https://www.zeta-alpha.com/post/analyzing-the-homerun-year-for-llms-the-top-100-most-cited-ai-papers-in-2023-with-all-medals-for-o)

</div>

9 October 2024, Mathias Parisot, Jakub Zavrel.Even in the red hot global
race for AI dominance, you publish and you perish, unless your peers
pick up your work, build further on it, and you manage to drive real
progress in the field. And of course, we are all very curious who is
currently having that kind of impact. Are the billions of dollars spent
on AI R&D paying off in the long run? So here is, in continuation of our
popular publication impact analysis of last year, Zeta Alpha's ranking
of t

</div>

<div class="card">

<div class="card-title">

[Summary of Ilya Sutskevers AI Reading List · Tensor
Labbet](https://tensorlabbet.com/2024/09/24/ai-reading-list/)

</div>

</div>

<div class="card">

<div class="card-title">

[Aman's AI Journal • Primers • Ilya Sutskever's Top
30](https://aman.ai/primers/ai/top-30-papers/)

</div>

Aman's AI Journal \| Course notes and learning material for Artificial
Intelligence and Deep Learning Stanford classes.

</div>

<div class="card">

<div class="card-title">

[\[2406.01506\] The Geometry of Categorical and Hierarchical Concepts in
Large](https://arxiv.org/abs/2406.01506)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2406.01506)

</div>

The linear representation hypothesis is the informal idea that semantic
concepts are encoded as linear directions in the representation spaces
of large language models (LLMs). Previous work has...

</div>

<div class="card">

<div class="card-title">

[Title:You Only Cache Once: Decoder-Decoder Architectures for Language
Model](https://arxiv.org/abs/2405.05254)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2405.05254)

</div>

We introduce a decoder-decoder architecture, YOCO, for large language
models, which only caches key-value pairs once. It consists of two
components, i.e., a cross-decoder stacked upon a...

</div>

<div class="card">

<div class="card-title">

[\[2404.19737\] Better & Faster Large Language Models via Multi-token
Predicti](https://arxiv.org/abs/2404.19737)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2404.19737)

</div>

Large language models such as GPT and Llama are trained with a
next-token prediction loss. In this work, we suggest that training
language models to predict multiple future tokens at once results...

</div>

<div class="card">

<div class="card-title">

[Collusive Outcomes Without
Collusion](http://d.repec.org/n?r=gth&u=RePEc:arx:papers:2403.07177)

</div>

</div>

<div class="card">

<div class="card-title">

[Auctions with Dynamic
Scoring](http://d.repec.org/n?r=gth&u=RePEc:arx:papers:2403.11022)

</div>

</div>

<div class="card">

<div class="card-title">

[Algorithmic Information Disclosure in Optimal
Auctions](http://d.repec.org/n?r=gth&u=RePEc:arx:papers:2403.08145)

</div>

</div>

<div class="card">

<div class="card-title">

[Equitable Pricing in
Auctions](http://d.repec.org/n?r=gth&u=RePEc:arx:papers:2403.07799)

</div>

</div>

<div class="card">

<div class="card-title">

[Algorithmic Collusion and Price Discrimination: The Over-Usage of
Data](http://d.repec.org/n?r=gth&u=RePEc:arx:papers:2403.06150)

</div>

</div>

<div class="card">

<div class="card-title">

[\[2404.09818\] Error Detection and Correction Codes for Safe In-Memory
Comput](https://arxiv.org/abs/2404.09818)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2404.09818)

</div>

In-Memory Computing (IMC) introduces a new paradigm of computation that
offers high efficiency in terms of latency and power consumption for AI
accelerators. However, the non-idealities and...

</div>

<div class="card">

<div class="card-title">

[Tips for LLM Pretraining and Evaluating Reward
Models](https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms?isFreemail=true&post_id=142924793&publication_id=1174659&r=oc5d&triedRedirect=true)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fabd9ec-29f1-4c1c-85fb-8781e7c6ce0b_1600x436.png)](https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms?isFreemail=true&post_id=142924793&publication_id=1174659&r=oc5d&triedRedirect=true)

</div>

Discussing AI Research Papers in March 2024

</div>

<div class="card">

<div class="card-title">

[language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[10 Noteworthy AI Research Papers of
2023](https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0046298-1059-4538-bcd8-dfcfc863d7c5_1254x810.png)](https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023)

</div>

This year has felt distinctly different. I've been working in, on, and
with machine learning and AI for over a decade, yet I can't recall a
time when these fields were as popular and rapidly evolving as they have
been this year. To conclude an eventful 2023 in machine learning and AI
research, I'm excited to share 10 noteworthy papers I've read this year.
My personal focus has been more on large language models, so you'll find
a heavier emphasis on large language model (LLM) papers than computer
vision papers this year.

</div>

<div class="card">

<div class="card-title">

[\[2302.07730\] Transformer models: an introduction and
catalog](https://arxiv.org/abs/2302.07730)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2302.07730)

</div>

In the past few years we have seen the meteoric appearance of dozens of
foundation models of the Transformer family, all of which have memorable
and sometimes funny, but not self-explanatory,...

</div>

<div class="card">

<div class="card-title">

[A Prompt Pattern Catalog](https://arxiv.org/pdf/2302.11382.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[Coordinated Dynamic Bidding in Repeated Second-Price Auctions with
Budgets](http://d.repec.org/n?r=gth&u=RePEc:arx:papers:2306.07709)

</div>

</div>

<div class="card">

<div class="card-title">

[Distilling Step-by-Step! Outperforming Larger Language Models
with...](https://arxiv.org/abs/2305.02301)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2305.02301)

</div>

Deploying large language models (LLMs) is challenging because they are
memory inefficient and compute-intensive for practical applications. In
reaction, researchers train smaller task-specific...

</div>

<div class="card">

<div class="card-title">

[SparseGPT: Massive Language Models Can Be Accurately Pruned in
One-Shot](https://arxiv.org/abs/2301.00774)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2301.00774)

</div>

We show for the first time that large-scale generative pretrained
transformer (GPT) family models can be pruned to at least 50% sparsity
in one-shot, without any retraining, at minimal loss of...

</div>

<div class="card">

<div class="card-title">

[A Cookbook of Self-Supervised
Learning](https://arxiv.org/abs/2304.12210)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2304.12210)

</div>

Self-supervised learning, dubbed the dark matter of intelligence, is a
promising path to advance machine learning. Yet, much like cooking,
training SSL methods is a delicate art with a high...

</div>

<div class="card">

<div class="card-title">

[Eight Things to Know about Large Language
Models](https://arxiv.org/abs/2304.00612)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2304.00612)

</div>

The widespread public deployment of large language models (LLMs) in
recent months has prompted a wave of new attention and engagement from
advocates, policymakers, and scholars from many fields....

</div>

<div class="card">

<div class="card-title">

[When do you need Chain-of-Thought Prompting for
ChatGPT?](https://arxiv.org/abs/2304.03262)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2304.03262)

</div>

Chain-of-Thought (CoT) prompting can effectively elicit complex
multi-step reasoning from Large Language Models~(LLMs). For example, by
simply adding CoT instruction \`\`Let's think step-by-step''...

</div>

<div class="card">

<div class="card-title">

[A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2303.18223)

</div>

Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to
develop capable AI algorithms for comprehending and...

</div>

<div class="card">

<div class="card-title">

[Top Machine Learning Papers to Read in 2023 -
KDnuggets](https://www.kdnuggets.com/2023/03/top-machine-learning-papers-read-2023.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/wijaya_top_machine_learning_papers_read_2023_1.jpg)](https://www.kdnuggets.com/2023/03/top-machine-learning-papers-read-2023.html)

</div>

These curated papers would step up your machine-learning knowledge.

</div>

<div class="card">

<div class="card-title">

[Must read: the 100 most cited AI papers in
2022](https://www.zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022)

</div>

<div class="card-image">

[![](https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_1000,h_618,al_c,q_85,usm_0.66_1.00_0.01/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg)](https://www.zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022)

</div>

Who Is publishing the most Impactful AI research right now? With the
breakneck pace of innovation in AI, it is crucial to pick up some signal
as soon as possible. No one has the time to read everything, but these
100 papers are sure to bend the road as to where our AI technology is
going. The real test of impact of R&D teams is of course how the
technology appears in products, and OpenAI shook the world by releasing
ChatGPT at the end of November 2022, following fast on their March 2022
paper “T

</div>

<div class="card">

<div class="card-title">

[2012.03854.pdf](https://arxiv.org/pdf/2012.03854.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[2003.05689.pdf](https://arxiv.org/pdf/2003.05689.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[Model Evaluation, Model Selection, and Algorithm Selection in Machine
Learning](https://arxiv.org/pdf/1811.12808.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[2108.02497.pdf](https://arxiv.org/pdf/2108.02497.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[Forecast Evaluation for Data Scientists: Common Pitfalls and Best
Practices](https://arxiv.org/pdf/2203.10716.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[?Top ML Papers of the Week - by elvis - NLP
Newsletter](https://nlpnews.substack.com/p/top-ml-papers-of-the-week-8f6?isFreemail=true&post_id=107962254&publication_id=103238)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvskpvXsAEIy5u.jpg)](https://nlpnews.substack.com/p/top-ml-papers-of-the-week-8f6?isFreemail=true&post_id=107962254&publication_id=103238)

</div>

The top ML Papers of the Week (Mar 6 - Mar 12)

</div>

<div class="card">

<div class="card-title">

[Why People Skip Music? On Predicting Music Skips using
Deep...](https://arxiv.org/abs/2301.03881)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2301.03881)

</div>

Music recommender systems are an integral part of our daily life. Recent
research has seen a significant effort around black-box recommender
based approaches such as Deep Reinforcement Learning...

</div>

<div class="card">

<div class="card-title">

[\[1702.04680v1\] Visual Discovery at
Pinterest](https://arxiv.org/abs/1702.04680v1)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/1702.04680v1)

</div>

Over the past three years Pinterest has experimented with several visual
search and recommendation services, including Related Pins (2014),
Similar Looks (2015), Flashlight (2016) and Lens (2017)....

</div>

<div class="card">

<div class="card-title">

[2212.03551.pdf](https://arxiv.org/pdf/2212.03551.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[\[2206.14007\] The Importance of (Exponentially More) Computing
Power](https://arxiv.org/abs/2206.14007)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2206.14007)

</div>

Denizens of Silicon Valley have called Moore's Law "the most important
graph in human history," and economists have found that Moore's
Law-powered I.T. revolution has been one of the most...

</div>

<div class="card">

<div class="card-title">

[YOLOv7: Trainable bag-of-freebies sets new state-of-the-art
for...](https://arxiv.org/abs/2207.02696)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2207.02696)

</div>

YOLOv7 surpasses all known object detectors in both speed and accuracy
in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8% AP
among all known real-time object detectors with 30...

</div>

<div class="card">

<div class="card-title">

[Machine Learning Operations (MLOps): Overview, Definition, and
Architecture](https://arxiv.org/abs/2205.02302)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2205.02302)

</div>

The final goal of all industrial machine learning (ML) projects is to
develop ML products and rapidly bring them into production. However, it
is highly challenging to automate and operationalize...

</div>

<div class="card">

<div class="card-title">

[Mastering the Game of Stratego with Model-Free
Multiagent...](https://arxiv.org/abs/2206.15378)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2206.15378)

</div>

We introduce DeepNash, an autonomous agent capable of learning to play
the imperfect information game Stratego from scratch, up to a human
expert level. Stratego is one of the few iconic board...

</div>

<div class="card">

<div class="card-title">

[Another Firing Among Google’s A.I. Brain Trust, and More Discord
(Published
2022)](https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html)

</div>

<div class="card-image">

[![](https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/merlin_178423734_12da72a6-6b6b-495e-b905-a3c7cba1d7a4-largeHorizontalJumbo.jpg?year=2022&h=683&w=1024&s=a7b83807f6b081a41aec120db60eed38e88b9162eac453381f720c296eb9a02b&k=ZQJBKqZ0VN)](https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html)

</div>

The researchers are considered a key to the company’s future. But they
have had a hard time shaking infighting and controversy over a variety
of issues.

</div>

<div class="card">

<div class="card-title">

[The Modern Mathematics of Deep
Learning](https://arxiv.org/abs/2105.04026)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2105.04026)

</div>

We describe the new field of mathematical analysis of deep learning.
This field emerged around a list of research questions that were not
answered within the classical framework of learning...

</div>

<div class="card">

<div class="card-title">

[A Comprehensive Benchmark of Deep Learning Libraries on Mobile DevicesA
Com](https://arxiv.org/pdf/2202.06512.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[Computer Science and Game Theory authors/titles recent
submissions](https://arxiv.org/list/cs.GT/recent)

</div>

</div>

<div class="card">

<div class="card-title">

[Detecting Twenty-thousand Classes using Image-level
Supervision](https://arxiv.org/abs/2201.02605v2)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2201.02605v2)

</div>

Current object detectors are limited in vocabulary size due to the small
scale of detection datasets. Image classifiers, on the other hand,
reason about much larger vocabularies, as their datasets...

</div>

<div class="card">

<div class="card-title">

[ArXiv.org Reaches a Milestone and a
Reckoning](https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning)

</div>

<div class="card-image">

[![](https://static.scientificamerican.com/sciam/cache/file/AFD5B975-B600-4C35-AA8B265090FFE58E_source.jpg?w=1200)](https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning)

</div>

Runaway success and underfunding have led to growing pains for the
preprint server

</div>

<div class="card">

<div class="card-title">

[louisfb01/best_AI_papers_2021: A curated list of the latest
breakthroughs in AI (in 2021) by release date with a clear video
explanation, link to a more in-depth article, and
code.](https://github.com/louisfb01/best_AI_papers_2021)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/4ddf0f05bcc43ff97da72ed99caa033c5b6740257f8a08e1a985e8785441c523/louisfb01/best_AI_papers_2021)](https://github.com/louisfb01/best_AI_papers_2021)

</div>

A curated list of the latest breakthroughs in AI (in 2021) by release
date with a clear video explanation, link to a more in-depth article,
and code. - louisfb01/best_AI_papers_2021

</div>

<div class="card">

<div class="card-title">

[Applications and Techniques for Fast Machine Learning in
Science](https://arxiv.org/abs/2110.13041)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2110.13041)

</div>

In this community review report, we discuss applications and techniques
for fast machine learning (ML) in science -- the concept of integrating
power ML methods into the real-time experimental...

</div>

</div>
