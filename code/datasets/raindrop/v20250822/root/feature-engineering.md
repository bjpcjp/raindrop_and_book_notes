<div class="nav">

⟵ [Up](index.html)  \|  [Index](index.html)

</div>

# feature-engineering

<div class="cards">

<div class="card">

<div class="card-title">

[How to Analyze Features Using
Yellowbrick](https://www.statology.org/how-to-analyze-features-using-yellowbrick/)

</div>

<div class="card-image">

[![](https://www.statology.org/wp-content/uploads/2025/02/sta-yellowbrick-02.png)](https://www.statology.org/how-to-analyze-features-using-yellowbrick/)

</div>

In this article, we'll walk through the process of aggregating claims
data to create meaningful provider features, visualize patterns using
Yellowbrick's Parallel Coordinates, and explore other visualization
tools available for feature analysis.

</div>

<div class="card">

<div class="card-title">

[What is Dataset Distillation Learning? A Comprehensive
Overview](https://www.marktechpost.com/2024/06/09/what-is-dataset-distillation-learning-a-comprehensive-overview)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-08-at-8.49.35-PM-1024x889.png)](https://www.marktechpost.com/2024/06/09/what-is-dataset-distillation-learning-a-comprehensive-overview)

</div>

Dataset distillation is an innovative approach that addresses the
challenges posed by the ever-growing size of datasets in machine
learning. This technique focuses on creating a compact, synthetic
dataset that encapsulates the essential information of a larger dataset,
enabling efficient and effective model training. Despite its promise,
the intricacies of how distilled data retains its utility and
information content have yet to be fully understood. Let’s delve into
the fundamental aspects of dataset distillation, exploring its
mechanisms, advantages, and limitations. Dataset distillation aims to
overcome the limitations of large datasets by generating a smaller,
information-dense dataset. Traditional data compression methods

</div>

<div class="card">

<div class="card-title">

[18 Data Profiling Tools Every Developer Must
Know](https://www.marktechpost.com/2024/06/05/18-data-profiling-tools-every-developer-must-know)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-12.48.36-AM-1024x858.png)](https://www.marktechpost.com/2024/06/05/18-data-profiling-tools-every-developer-must-know)

</div>

Analytics, management, and business intelligence (BI) procedures, such
as data cleansing, transformation, and decision-making, rely on data
profiling. Content and quality reviews are becoming more important as
data sets grow in size and variety of sources. In addition,
organizations that rely on data must prioritize data quality review.
Analysts and developers can enhance business operations by analyzing the
dataset and drawing significant insights from it. Data profiling is a
crucial tool. For evaluating data quality. It entails analyzing,
cleansing, transforming, and modeling data to find valuable information,
improve data quality, and assist in better decision-making, What is Data
Profiling? Examining

</div>

<div class="card">

<div class="card-title">

[Basis Functions: Simple Definition - Statistics How
To](https://www.statisticshowto.com/basis-functions-simple-definition)

</div>

<div class="card-image">

[![](https://www.statisticshowto.com/wp-content/uploads/2018/12/cropped-banner-21-1.png)](https://www.statisticshowto.com/basis-functions-simple-definition)

</div>

Types of Functions \> Basis functions (called derived features in
machine learning) are building blocks for creating more complex
functions. In other

</div>

<div class="card">

<div class="card-title">

[Permutation Feature Importance from
Scratch](https://towardsdatascience.com/permutation-feature-importance-from-scratch-b8dcaceba9c2?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1085/1*KW28PqAfeC_tyhPrYVQAXg.png)](https://towardsdatascience.com/permutation-feature-importance-from-scratch-b8dcaceba9c2?source=rss----7f60cf5620c9---4)

</div>

Understanding the importance of permutations in the field of explainable
AI

</div>

<div class="card">

<div class="card-title">

[A Practical Guide to Data Normalization in
R](https://www.r-bloggers.com/2024/04/a-practical-guide-to-data-normalization-in-r)

</div>

<div class="card-image">

[![](https://www.spsanderson.com/steveondata/posts/2024-04-02/index_files/figure-html/unnamed-chunk-4-1.png)](https://www.r-bloggers.com/2024/04/a-practical-guide-to-data-normalization-in-r)

</div>

Introduction Data normalization is a crucial preprocessing step in data
analysis and machine learning workflows. It helps in standardizing the
scale of numeric features, ensuring fair treatment to all variables
regardless of their magnitude. In ...

</div>

<div class="card">

<div class="card-title">

[Planning poker -
Wikipedia](https://en.wikipedia.org/wiki/Planning_poker)

</div>

<div class="card-image">

[![](https://upload.wikimedia.org/wikipedia/commons/e/eb/CrispPlanningPokerDeck.jpg)](https://en.wikipedia.org/wiki/Planning_poker)

</div>

Planning poker, also called Scrum poker, is a consensus-based, gamified
technique for estimating, mostly used for timeboxing in Agile
principles. In planning poker, members of the group make estimates by
playing numbered cards face-down to the table, instead of speaking them
aloud. The cards are revealed, and the estimates are then discussed. By
hiding the figures in this way, the group can avoid the cognitive bias
of anchoring, where the first number spoken aloud sets a precedent for
subsequent estimates.

</div>

<div class="card">

<div class="card-title">

[Why is Feature Scaling Important in Machine Learning? Discussing 6
Feature](https://towardsdatascience.com/why-is-feature-scaling-important-in-machine-learning-discussing-6-feature-scaling-techniques-2773bda5be30?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*ap73KM7JcxuNTRp7PzXleA.jpeg)](https://towardsdatascience.com/why-is-feature-scaling-important-in-machine-learning-discussing-6-feature-scaling-techniques-2773bda5be30?source=rss----7f60cf5620c9---4)

</div>

Standardization, Normalization, Robust Scaling, Mean Normalization,
Maximum Absolute Scaling and Vector Unit Length Scaling

</div>

<div class="card">

<div class="card-title">

<https://www.uber.com/blog/research/maximum-relevance-and-minimum-redundancy-feature-selection-methods-for-a-marketing-machine-learning-platform>

</div>

</div>

<div class="card">

<div class="card-title">

[A practical introduction to sequential feature
selection](https://towardsdatascience.com/a-practical-introduction-to-sequential-feature-selection-a5444eb5b2fd?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1024/0*Hhw0HNLZfX1zy6YO.jpg)](https://towardsdatascience.com/a-practical-introduction-to-sequential-feature-selection-a5444eb5b2fd?source=rss----7f60cf5620c9---4)

</div>

A gentle dive into this unusual feature selection technique

</div>

<div class="card">

<div class="card-title">

[PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition:
Python](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/3921b2adb2d8faa2ca4eab4057b5e8bfa414a53ac9b4d7df19fc6a722aaa3f39/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition)](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition)

</div>

Python Feature Engineering Cookbook Second Edition, published by Packt -
PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition

</div>

<div class="card">

<div class="card-title">

[python-data-science-handbook/scikit/SciKit-Feature-Engineering.ipynb at
master ·
bjpcjp/python-data-science-handbook](https://github.com/bjpcjp/python-data-science-handbook/blob/master/scikit/SciKit-Feature-Engineering.ipynb)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/fb5d1964e7000872cfefb9d9e596de05565e42041392929c31fb051fe3fdaa83/bjpcjp/python-data-science-handbook)](https://github.com/bjpcjp/python-data-science-handbook/blob/master/scikit/SciKit-Feature-Engineering.ipynb)

</div>

Sourced from O'Reilly ebook of the same name.

</div>

<div class="card">

<div class="card-title">

[scikit-learn/63_preprocessing.ipynb at master ·
bjpcjp/scikit-learn](https://github.com/bjpcjp/scikit-learn-0.24/blob/master/63_preprocessing.ipynb)

</div>

<div class="card-image">

[![](https://repository-images.githubusercontent.com/353023783/1f97d000-a99b-11eb-9b40-ad00d6f3c8da)](https://github.com/bjpcjp/scikit-learn-0.24/blob/master/63_preprocessing.ipynb)

</div>

Updates in progress. Jupyter workbooks will be added as time allows. -
bjpcjp/scikit-learn

</div>

<div class="card">

<div class="card-title">

[The 5 Feature Selection Algorithms every Data Scientist should
know](https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*Feid5O1I9KethU8WX45CTg.png)](https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2)

</div>

Bonus: What makes a good footballer great?

</div>

<div class="card">

<div class="card-title">

[Why you should always use feature embeddings with structured
datasets](https://towardsdatascience.com/why-you-should-always-use-feature-embeddings-with-structured-datasets-7f280b40e716?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg)](https://towardsdatascience.com/why-you-should-always-use-feature-embeddings-with-structured-datasets-7f280b40e716?source=rss----7f60cf5620c9---4)

</div>

A simple technique for boosting accuracy on ANY model you use

</div>

<div class="card">

<div class="card-title">

[\[1605.09782v6\] Adversarial Feature
Learning](https://arxiv.org/abs/1605.09782v6)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/1605.09782v6)

</div>

The ability of the Generative Adversarial Networks (GANs) framework to
learn generative models mapping from simple latent distributions to
arbitrarily complex data distributions has been...

</div>

<div class="card">

<div class="card-title">

[Recursive Feature Elimination (RFE) for Feature Selection in
Python](https://machinelearningmastery.com/rfe-feature-selection-in-python)

</div>

<div class="card-image">

[![](https://machinelearningmastery.com/wp-content/uploads/2020/02/Box-Plot-of-RFE-Number-of-Selected-Features-vs-Classification-Accuracy.png)](https://machinelearningmastery.com/rfe-feature-selection-in-python)

</div>

Recursive Feature Elimination, or RFE for short, is a popular feature
selection algorithm. RFE is popular because it is easy to configure and
use and because it is effective at selecting those features (columns) in
a training dataset that are more or most relevant in predicting the
target variable. There are two important configuration options when
using RFE: the choice…

</div>

<div class="card">

<div class="card-title">

[Feature Engineering: Data scientist's Secret Sauce ! -
DataScienceCentral.com](https://www.datasciencecentral.com/profiles/blogs/feature-engineering-data-scientist-s-secret-sauce-1?fbclid=IwAR30CuRTYhY9qxf9StfBl_J7GXHsFcg6gPDaZHvcGFNfAV6KOv6srP3gxn0)

</div>

<div class="card-image">

[![](https://www.datasciencecentral.com/wp-content/uploads/2021/10/2808313467.png)](https://www.datasciencecentral.com/profiles/blogs/feature-engineering-data-scientist-s-secret-sauce-1?fbclid=IwAR30CuRTYhY9qxf9StfBl_J7GXHsFcg6gPDaZHvcGFNfAV6KOv6srP3gxn0)

</div>

originally posted by the author on Linkedin : Link It is very tempting
for  data science practitioners to opt for the best known  algorithms
for a given problem.However It’s not the algorithm alone , which can
provide the best solution  ; Model built on carefully engineered and
selected features can provide far better results. “Any intelligent… Read
More »Feature Engineering: Data scientist's Secret Sauce !

</div>

<div class="card">

<div class="card-title">

[Know Your Data: Part 1 -
KDnuggets](https://www.kdnuggets.com/2019/09/know-data-part-1.html)

</div>

This article will introduce the different type of data sets, data object
and attributes.

</div>

<div class="card">

<div class="card-title">

[Model-agnostic feature importance through ablation - Samuel
Taylor](https://www.samueltaylor.org/articles/feature-importance-for-any-model.html)

</div>

</div>

<div class="card">

<div class="card-title">

[How to find Feature importances for BlackBox
Models?](https://towardsdatascience.com/how-to-find-feature-importances-for-blackbox-models-c418b694659d)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*Ox8Cxbdvyhcxd7VGL49ERw.png)](https://towardsdatascience.com/how-to-find-feature-importances-for-blackbox-models-c418b694659d)

</div>

Permutation Importance as a feature selection method

</div>

<div class="card">

<div class="card-title">

[Labeling, transforming, and structuring training data sets for machine
lear](https://www.oreilly.com/ideas/labeling-transforming-and-structuring-training-data-sets-for-machine-learning)

</div>

<div class="card-image">

[![](https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/08/Labeling-transforming-and-structuring-training-data-sets-for-machine-learning.jpg)](https://www.oreilly.com/ideas/labeling-transforming-and-structuring-training-data-sets-for-machine-learning)

</div>

The O’Reilly Data Show Podcast: Alex Ratner on how to build and manage
training data with Snorkel.

</div>

<div class="card">

<div class="card-title">

[The 5 Feature Selection Algorithms every Data Scientist should
know](https://mlwhiz.com/blog/2019/08/07/feature_selection)

</div>

<div class="card-image">

[![](https://mlwhiz.com/images/fs/1.png)](https://mlwhiz.com/blog/2019/08/07/feature_selection)

</div>

This post is about some of the most common feature selection techniques
one can use while working with data.

</div>

<div class="card">

<div class="card-title">

[The Hitchhiker’s Guide to Feature
Extraction](https://www.reddit.com/r/datascience/comments/bqezb9/the_hitchhikers_guide_to_feature_extraction)

</div>

<div class="card-image">

[![](https://share.redd.it/preview/post/bqezb9)](https://www.reddit.com/r/datascience/comments/bqezb9/the_hitchhikers_guide_to_feature_extraction)

</div>

168 votes, 13 comments. 2.2M subscribers in the datascience community. A
space for data science professionals to engage in discussions and
debates on…

</div>

<div class="card">

<div class="card-title">

[A Feature Selection Tool for Machine Learning in
Python](https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*rqeNwjiakRS-SqsW9wCgrA.jpeg)](https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0)

</div>

Using the FeatureSelector for efficient machine learning workflows

</div>

<div class="card">

<div class="card-title">

[Feature Engineering with
Tidyverse](https://opendatascience.com/blog/feature-engineering-with-tidyverse)

</div>

<div class="card-image">

[![](https://opendatascience.com/wp-content/uploads/2020/02/Untitled-1.png)](https://opendatascience.com/blog/feature-engineering-with-tidyverse)

</div>

Stay up-to-date on the latest data science and AI news in the worlds of
artificial intelligence, machine learning, deep learning,
implementation, and more.

</div>

<div class="card">

<div class="card-title">

[Feature Engineering for Machine Learning: Principles and Techniques for
Data Scientists: 9781491953242: Computer Science Books @
Amazon.com](https://www.amazon.com/Mastering-Feature-Engineering-Principles-Techniques/dp/1491953241)

</div>

</div>

<div class="card">

<div class="card-title">

[Best Practices for Feature
Engineering](https://elitedatascience.com/feature-engineering-best-practices)

</div>

<div class="card-image">

[![](https://elitedatascience.com/wp-content/uploads/2017/07/Feature-Engineering-Best-Practices-Feature-No-Text.jpg)](https://elitedatascience.com/feature-engineering-best-practices)

</div>

Unsure how to perform feature engineering? Here are 20 best practices
and heuristics that will help you engineer great features for machine
learning.

</div>

<div class="card">

<div class="card-title">

[Understanding Feature Engineering (Part 3) — Traditional Methods for
Text
D](https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1024/1*vXKKe3J-lfi1YQ7HC6onxQ.jpeg)](https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41)

</div>

Traditional strategies for taming unstructured, textual data

</div>

<div class="card">

<div class="card-title">

[Understanding Feature Engineering (Part 2) — Categorical
Data](https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*FgMeHrpzkMgDc1RCrl8JNw.jpeg)](https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63)

</div>

Strategies for working with discrete, categorical data

</div>

<div class="card">

<div class="card-title">

[Understanding Feature Engineering (Part 1) — Continuous Numeric
Data](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*_ARjrrFLdgNf-vodDI6PDQ.jpeg)](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)

</div>

Strategies for working with continuous, numerical data

</div>

<div class="card">

<div class="card-title">

[A Beginner’s Guide to Data Engineering — Part I – Robert Chang –
Medium](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*gjgczPgeWlqWEVHtKYpJUg.png)](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)

</div>

Data Engineering: The Close Cousin of Data Science

</div>

<div class="card">

<div class="card-title">

[\[D\] A Comparison of Six Methods for Missing Data
Imputation](https://www.reddit.com/r/MachineLearning/comments/6uqkku/d_a_comparison_of_six_methods_for_missing_data)

</div>

<div class="card-image">

[![](https://i.redd.it/o0h58lzmax6a1.png)](https://www.reddit.com/r/MachineLearning/comments/6uqkku/d_a_comparison_of_six_methods_for_missing_data)

</div>

2.9M subscribers in the MachineLearning community. Beginners -\>
/r/mlquestions , AGI -\> /r/singularity, career advices -\>
/r/cscareerquestions…

</div>

</div>
