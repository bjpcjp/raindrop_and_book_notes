<html><head><meta charset="utf-8"><title>hyperparameters</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">⟵ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>hyperparameters</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/02/24/meet-optuna-an-automatic-hyperparameter-optimization-software-framework-designed-for-machine-learning">Meet Optuna: An Automatic Hyperparameter Optimization Software Framework De</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/02/24/meet-optuna-an-automatic-hyperparameter-optimization-software-framework-designed-for-machine-learning"><img src="https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-24-at-12.42.32-PM.png" alt=""></a></div>
    <p class="card-excerpt">In machine learning, finding the perfect settings for a model to work at its best can be like looking for a needle in a haystack. This process, known as hyperparameter optimization, involves tweaking the settings that govern how the model learns. It's crucial because the right combination can significantly improve a model's accuracy and efficiency. However, this process can be time-consuming and complex, requiring extensive trial and error. Traditionally, researchers and developers have resorted to manual tuning or using grid search and random search methods to find the best hyperparameters. These methods do work to some extent but could be</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://hgpu.org/?p=28050">Towards a Benchmarking Suite for Kernel Tuners</a></div>
    <div class="card-image"><a href="https://hgpu.org/?p=28050"><img src="https://hgpu.org/img/social-logo.png" alt=""></a></div>
    <p class="card-excerpt">As computing system become more complex, it is becoming harder for programmers to keep their codes optimized as the hardware gets updated. Autotuners try to alleviate this by hiding as many archite…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/pdf/2003.05689.pdf">2003.05689.pdf</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/01/hyperparameter-optimization-10-top-python-libraries.html">Hyperparameter Optimization: 10 Top Python Libraries</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/01/hyperparameter-optimization-10-top-python-libraries.html"><img src="https://www.kdnuggets.com/wp-content/uploads/miradi-hyperparameter-optimization-header.jpeg" alt=""></a></div>
    <p class="card-excerpt">Become familiar with some of the most popular Python libraries available for hyperparameter optimization.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.dataknowsall.com/hyperparameter.html">5–10x Faster Hyperparameter Tuning with HalvingGridSearch</a></div>
    <div class="card-image"><a href="https://www.dataknowsall.com/hyperparameter.html"><img src="https://dataknowsall.com/hubfs/hyper_00.png" alt=""></a></div>
    <p class="card-excerpt">How to optimize the hyperparameters of a machine learning model and how to speed up the process</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a?source=rss----7f60cf5620c9---4">The Kaggle Way to Tune Hyperparameters with Optuna</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*AI-YmX3qqycS1Weo" alt=""></a></div>
    <p class="card-excerpt">Easily and efficiently optimize your model’s hyperparameters with Optuna with a mini project</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/automate-hyperparameter-tuning-with-hyperopts-for-multiple-models-22b499298a8a">Automate Hyperparameter Tuning for Multiple Models with Hyperopts</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/automate-hyperparameter-tuning-with-hyperopts-for-multiple-models-22b499298a8a"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*_EKGGNDOF3mJF2EF" alt=""></a></div>
    <p class="card-excerpt">Automate your hyperparameter tuning with Sklearn Pipelines and Hyperopts for multiple models in a single python call. Let's dig into the process...</p>
  </div>
</div>
</body></html>
