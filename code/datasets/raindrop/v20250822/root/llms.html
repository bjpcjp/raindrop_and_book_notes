<html><head><meta charset="utf-8"><title>llms</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">⟵ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>llms</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://lmarena.ai/">Chatbot Arena (formerly LMSYS): Free AI Chat to Compare & Test Best AI Chatbots</a></div>
    <div class="card-image"><a href="https://lmarena.ai/"><img src="https://storage.googleapis.com/public-arena-asset/lmsys.jpg" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://geshan.com.np/blog/2025/02/ollama-commands/">Ollama commands: How to use Ollama in the command line [Part 2]</a></div>
    <div class="card-image"><a href="https://geshan.com.np/blog/2025/02/ollama-commands/"><img src="https://geshan.com.np/images/ollama-commands/01ollama-commands.jpg" alt=""></a></div>
    <p class="card-excerpt">Learn about the important Ollama commands to run Ollama on your local machine with Smollm2 and Qwen 2.5 models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://geshan.com.np/blog/2025/02/what-is-ollama/">What is Ollama and how to use it: a quick guide [part 1]</a></div>
    <div class="card-image"><a href="https://geshan.com.np/blog/2025/02/what-is-ollama/"><img src="https://geshan.com.np/images/what-is-ollama/01what-is-ollama.jpg" alt=""></a></div>
    <p class="card-excerpt">Learn what Ollama is, its features and how to run it on your local machine with DeepSeek R1 and Smollm2 models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://geshan.com.np/blog/2025/02/ollama-api/">ollama APIs</a></div>
    <div class="card-image"><a href="https://geshan.com.np/blog/2025/02/ollama-api/"><img src="https://geshan.com.np/images/ollama-api/01ollama-api.jpg" alt=""></a></div>
    <p class="card-excerpt">Learn how to use Ollama APIs like generate, chat and more like list model, pull model, etc with cURL and Jq with useful examples</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://geshan.com.np/blog/2025/02/ollama-docker-compose/">ollama with docker compose</a></div>
    <div class="card-image"><a href="https://geshan.com.np/blog/2025/02/ollama-docker-compose/"><img src="https://geshan.com.np/images/ollama-docker-compose/01ollama-docker-compose.jpg" alt=""></a></div>
    <p class="card-excerpt">Learn how to use Ollama and Open WebUI inside Docker with Docker compose to run any open LLM and create your own mini ChatGPT.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/ngafar/llama-scan">ngafar/llama-scan: Transcribe PDFs with local LLMs</a></div>
    <div class="card-image"><a href="https://github.com/ngafar/llama-scan"><img src="https://opengraph.githubassets.com/f7016f297dce503eb4904222bbdfb962ceb0e1e800f42fb30795657063161bba/ngafar/llama-scan" alt=""></a></div>
    <p class="card-excerpt">Transcribe PDFs with local LLMs</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/08/17/what-is-ai-inference-a-technical-deep-dive-and-top-9-ai-inference-providers-2025-edition/">What is AI Inference? A Technical Deep Dive and Top 9 AI Inference Providers (2025 Edition)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/08/17/what-is-ai-inference-a-technical-deep-dive-and-top-9-ai-inference-providers-2025-edition/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/08/a-digital-illustration-depicting-a-futur_kHJfZ0DdQFy84zMxLs-haQ_Q46Pe7dUTEOD6R6_oApdsQ.png" alt=""></a></div>
    <p class="card-excerpt">What is Artificial Intelligence AI Inference? A Technical Deep Dive and Top 9 AI Inference Providers (2025 Edition)</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/08/17/what-is-ai-red-teaming-top-18-ai-red-teaming-tools-2025/">What Is AI Red Teaming? Top 18 AI Red Teaming Tools (2025)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/08/17/what-is-ai-red-teaming-top-18-ai-red-teaming-tools-2025/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/08/a-futuristic-digital-art-poster-illustra_2cHW7BOFS8-GQ3WAnqSv7g_G5_b_kHJSM6ZSCzvGzkJHg.png" alt=""></a></div>
    <p class="card-excerpt">Discover top AI red teaming tools for robust AI security. Learn how adversarial testing protects machine learning models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://jenson.org/timmy/">The Timmy Trap – Scott Jenson</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/">That ‘cheap’ open-source AI model is actually burning through your compute budget</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/"><img src="https://venturebeat.com/wp-content/uploads/2025/08/nuneybits_Vector_art_of_dollar_bills_burning_blue_halftone_phot_64f22ade-4971-4234-822b-ba7dab7461de.webp?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">New research reveals open-source AI models use up to 10 times more computing resources than closed alternatives, potentially negating cost advantages for enterprise deployments.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://artificialanalysis.ai/">AI Model & API Providers Analysis | Artificial Analysis</a></div>
    <div class="card-image"><a href="https://artificialanalysis.ai/"><img src="https://artificialanalysis.ai/img/open-graph/og-image.png" alt=""></a></div>
    <p class="card-excerpt">Comparison and analysis of AI models and API hosting providers. Independent benchmarks across key performance metrics including quality, price, output speed & latency.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/google/langextract">google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.</a></div>
    <div class="card-image"><a href="https://github.com/google/langextract"><img src="https://opengraph.githubassets.com/198b1893e0a9faa86b2e32b94efb8e8d9f0e1027da73c36fc618f749f937ac9b/google/langextract" alt=""></a></div>
    <p class="card-excerpt">A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization. - google/langextract</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/08/10/from-100000-to-under-500-labels-how-google-ai-cuts-llm-training-data-by-orders-of-magnitude/">From 100,000 to Under 500 Labels: How Google AI Cuts LLM Training Data by Orders of Magnitude</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/08/10/from-100000-to-under-500-labels-how-google-ai-cuts-llm-training-data-by-orders-of-magnitude/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/08/CurationStrategies_ProcessHero.png" alt=""></a></div>
    <p class="card-excerpt">Google’s active learning method fine-tunes LLMs with 10,000x less data using high-fidelity expert-labeled examples</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://huggingface.co/spaces/hesamation/primer-llm-embedding">LLM Embeddings Explained: A Visual and Intuitive Guide</a></div>
    <div class="card-image"><a href="https://huggingface.co/spaces/hesamation/primer-llm-embedding"><img src="https://cdn-uploads.huggingface.co/production/uploads/647f805de9c81260ff8881ee/8v52lNo2sFtNySUlVnXF4.png" alt=""></a></div>
    <p class="card-excerpt">How Language Models Turn Text into Meaning, From Traditional</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/new-persona-vectors-from-anthropic-let-you-decode-and-direct-an-llms-personality/">New ‘persona vectors’ from Anthropic let you decode and direct an LLM’s personality</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/new-persona-vectors-from-anthropic-let-you-decode-and-direct-an-llms-personality/"><img src="https://venturebeat.com/wp-content/uploads/2025/08/model-behavior.jpg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">A new study from Anthropic introduces "persona vectors," a technique for developers to monitor, predict and control unwanted LLM behaviors.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/">A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.21.48-PM.png" alt=""></a></div>
    <p class="card-excerpt">Context engineering for large language models—frameworks, architectures, and strategies to optimize AI reasoning, and scalability</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2506.21734">Hierarchical Reasoning Model</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2506.21734"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://amanxai.com/2025/07/25/the-complete-llm-tech-stack/">The Complete LLM Tech Stack</a></div>
    <div class="card-image"><a href="https://amanxai.com/2025/07/25/the-complete-llm-tech-stack/"><img src="https://i0.wp.com/amanxai.com/wp-content/uploads/2025/07/The-Complete-LLM-Tech-Stack-You-Should-Know.png?fit=2436%2C1200&ssl=1" alt=""></a></div>
    <p class="card-excerpt">In this article, I'll take you through the complete LLM tech stack you should know to develop & deploy real-world LLM applications.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/security/openais-red-team-plan-make-chatgpt-agent-an-ai-fortress/">How OpenAI’s red team made ChatGPT agent into an AI fortress</a></div>
    <div class="card-image"><a href="https://venturebeat.com/security/openais-red-team-plan-make-chatgpt-agent-an-ai-fortress/"><img src="https://venturebeat.com/wp-content/uploads/2025/07/hero-image.jpg?w=624?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Discover OpenAI's red team blueprint: How 110 coordinated attacks and 7 exploit fixes created ChatGPT Agent's revolutionary 95% security defense system.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://substack.com/@shirinkjam/note/c-133160958?r=oc5d&utm_medium=ios&utm_source=notes-share-action">Shirin Khosravi Jam on Substack</a></div>
    <div class="card-image"><a href="https://substack.com/@shirinkjam/note/c-133160958?r=oc5d&utm_medium=ios&utm_source=notes-share-action"><img src="https://substack-post-media.s3.amazonaws.com/public/images/1abc67af-38cf-4cdc-bd70-3d897e8cac30_1200x1599.jpeg" alt=""></a></div>
    <p class="card-excerpt">I taught myself how to build RAG + AI Agents in production.

Been running them live for over a year now. Here are 4 steps + the only resources you really need to do the same.

…

Ugly truth: most “AI Engineers” shouting on social media haven’t built a single real production AI Agent or RAG system.

If you want to be different - actually build and ship these systems: here’s a laser-focused roadmap from my own journey.

..

🚀 𝗦𝘁𝗮𝗿𝘁 𝘄𝗶𝘁𝗵 𝗳𝘂𝗻𝗱𝗮𝗺𝗲𝗻𝘁𝗮𝗹𝘀

Because no matter how fast LLM/GenAI evolves, your ML & software foundations keep you relevant.

✅ Hands-On ML with TensorFlow & Keras: https://lnkd.in/dWrf5pbS

✅ ISLR: https://lnkd.in/djGPVVwJ

✅ Machine Learning for Beginners by Microsoft (free curriculum):

https://lnkd.in/d8kZA3es

…

1️⃣ 𝗠𝗮𝘀𝘁𝗲𝗿 𝗟𝗟𝗠𝘀 & 𝗚𝗲𝗻𝗔𝗜 𝗦𝘆𝘀𝘁𝗲𝗺𝘀

→ Learn to build & deploy LLMs, understand system design tradeoffs, and handle real constraints.

📚 Must-reads:

✅ Designing ML Systems – Chip Huyen: https://lnkd.in/guN-UhXA

✅ The LLM Engineering Handbook – Iusztin & Labonne: https://lnkd.in/gyA4vFXz

✅ Build a LLM (From Scratch) – Raschka: https://lnkd.in/gXNa-SPb

✅ Hands-On LLMs GitHub: https://lnkd.in/eV4qrgNW

…

2️⃣ 𝗚𝗼 𝗯𝗲𝘆𝗼𝗻𝗱 𝘁𝗵𝗲 𝗵𝘆𝗽𝗲 𝗼𝗻 𝗔𝗜 𝗔𝗴𝗲𝗻𝘁𝘀

→ Most demos = “if user says hello, return hello.”

Actual agents? Handle memory, tools, workflows, costs.

✅ AI Agents for Beginners (GitHub): https://lnkd.in/eik2btmq

✅ GenAI Agents – build step by step: https://lnkd.in/dnhwk75V

✅ OpenAI’s guide to agents: https://lnkd.in/guRfXsFK

✅ Anthropic’s Building Effective Agents: https://lnkd.in/gRWKANS4

…

3️⃣ 𝗥𝗔𝗚 𝗶𝘀 𝗻𝗼𝘁 𝗷𝘂𝘀𝘁 𝗮 𝘃𝗲𝗰𝘁𝗼𝗿 𝗗𝗕

Real Retrieval-Augmented Generation requires:

→ Chunking, hybrid BM25 + vectors, reranking

→ Query routing & fallback

→ Evaluating retrieval quality, not just LLM output

✅ RAG Techniques repo: https://lnkd.in/dD4S8Cq2

✅ Advanced RAG: https://lnkd.in/g2ZHwZ3w

✅ Cost-efficient retrieval with Postgres/OpenSearch/Qdrant

✅ Monitoring with Langfuse / Comet

…

4️⃣ 𝗚𝗲𝘁 𝘀𝗲𝗿𝗶𝗼𝘂𝘀 𝗼𝗻 𝗦𝗼𝗳𝘁𝘄𝗮𝗿𝗲 & 𝗜𝗻𝗳𝗿𝗮

→ FastAPI, async Python, Pydantic

→ Docker, CI/CD, blue-green deploys

→ ETL orchestration (Airflow, Step Functions)

→ Logs + metrics (CloudWatch, Prometheus)

✅ Move to production: https://lnkd.in/dnnkrJbE

✅ Made with ML (full ML+infra): https://lnkd.in/e-XQwXqS

✅ AWS GenAI path: https://lnkd.in/dmhR3uPc

…

5️⃣ 𝗪𝗵𝗲𝗿𝗲 𝗱𝗼 𝗜 𝗹𝗲𝗮𝗿𝗻 𝗳𝗿𝗼𝗺?

→ Stanford CS336 / CS236 / CS229 (Google it)

→ MIT 6.S191, Karpathy’s Zero to Hero: https://lnkd.in/dT7vqqQ5

→ Google Kaggle GenAI sprint: https://lnkd.in/ga5X7tVJ

→ NVIDIA’s end-to-end LLM stack: https://lnkd.in/gCtDnhni

→ DeepLearning.AI’s short courses: https://lnkd.in/gAYmJqS6

…

💥 𝗞𝗲𝗲𝗽 𝗶𝘁 𝗿𝗲𝗮𝗹:

Don’t fall for “built in 5 min, dead in 10 min” demos.

In prod, it’s about latency, cost, maintainability, guardrails.

♻️ Let's repost to help more people on this journey 💚</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Jun/25/gemini-cli/#atom-everything">Gemini CLI</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/Jun/25/gemini-cli/#atom-everything"><img src="https://static.simonwillison.net/static/2025/gemini-cli-card.jpg" alt=""></a></div>
    <p class="card-excerpt">First there was Claude Code in February, then OpenAI Codex (CLI) in April, and now Gemini CLI in June. All three of the largest AI labs now have their own …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://llm.datasette.io/en/stable/usage.html?utm_source=substack&utm_medium=email">Usage</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://openai.com/index/chatgpt-agent-system-card/">ChatGPT agent System Card | OpenAI</a></div>
    <div class="card-image"><a href="https://openai.com/index/chatgpt-agent-system-card/"><img src="https://images.ctfassets.net/kftzwdyauwt9/4MBcZnnZGYlsr4Ev1eHT9j/a8556ef6251e5a968dd00ade958f1192/Agent_System_Card_SEO_Image.png?w=1600&h=900&fit=fill" alt=""></a></div>
    <p class="card-excerpt">ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with safeguards under the Preparedness Framework.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.theverge.com/ai-artificial-intelligence/710020/openai-review-test-new-release-chatgpt-agent-operator-deep-research-pro-200-subscription">I sent ChatGPT Agent out to shop for me</a></div>
    <div class="card-image"><a href="https://www.theverge.com/ai-artificial-intelligence/710020/openai-review-test-new-release-chatgpt-agent-operator-deep-research-pro-200-subscription"><img src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/07/chatgptagent.jpg?quality=90&strip=all&crop=0%2C10.722908076692%2C100%2C78.554183846616&w=1200" alt=""></a></div>
    <p class="card-excerpt">We tested OpenAI’s ChatGPT Agent, currently only available via its $200-per-month Pro subscription.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2025/llm-research-papers-the-2025-list-january-to-june.html">LLM Research Papers: The 2025 List (January to June)</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2025/llm-research-papers-the-2025-list-january-to-june.html"><img src="https://sebastianraschka.com/images/blog/2025/llm-research-papers-the-2025-list-january-to-june/hero.jpeg" alt=""></a></div>
    <p class="card-excerpt">The latest in LLM research with a hand-curated, topic-organized list of over 200 research papers from 2025.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Jul/7/become-a-command-line-superhero-with-simon-willisons-llm-tool/#atom-everything">Become a command-line superhero with Simon Willison’s llm tool</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/Jul/7/become-a-command-line-superhero-with-simon-willisons-llm-tool/#atom-everything"><img src="https://simonwillison.net/card/2025/Jul/7/become-a-command-line-superhero-with-simon-willisons-llm-tool/" alt=""></a></div>
    <p class="card-excerpt">Christopher Smith ran a mini hackathon in Albany New York at the weekend around uses of my LLM - the first in-person event I'm aware of dedicated to that project! …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sidsaladi.substack.com/p/perplexity-101-ultimate-guide-to">🔍 Perplexity 101: Ultimate Guide to Deep Search, Labs, Templates & 53 Pro Prompts</a></div>
    <div class="card-image"><a href="https://sidsaladi.substack.com/p/perplexity-101-ultimate-guide-to"><img src="https://substackcdn.com/image/fetch/$s_!iGr0!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676afdba-22cb-4812-a8a8-d13ede1e5365_3000x2250.jpeg" alt=""></a></div>
    <p class="card-excerpt">Your complete playbook for transforming how you research with AI's most powerful search engine</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://bentoml.com/llm/">Introduction | LLM Inference in Production</a></div>
    <div class="card-image"><a href="https://bentoml.com/llm/"><img src="https://bentoml.com/llm/img/handbook-cover-image.png" alt=""></a></div>
    <p class="card-excerpt">A practical handbook for engineers building, optimizing, scaling and operating LLM inference systems in production.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.lesswrong.com/posts/yqhy3zBmpeFuGFLxX/emergent-price-fixing-by-llm-auction-agents">Emergent Price-Fixing by LLM Auction Agents</a></div>
    <div class="card-image"><a href="https://www.lesswrong.com/posts/yqhy3zBmpeFuGFLxX/emergent-price-fixing-by-llm-auction-agents"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg" alt=""></a></div>
    <p class="card-excerpt">An inquiry into emergent collusion in Large Language Models.
 
 Agent S2 to Agent S3: “Let's set all asks at 63 next cycle… No undercutting ensur…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.technologyreview.com/2025/07/04/1119705/inside-indias-scramble-for-ai-independence/">Inside India’s scramble for AI independence</a></div>
    <div class="card-image"><a href="https://www.technologyreview.com/2025/07/04/1119705/inside-indias-scramble-for-ai-independence/"><img src="https://wp.technologyreview.com/wp-content/uploads/2025/07/india-ai-sovreignity-c.jpg?resize=854,569" alt=""></a></div>
    <p class="card-excerpt">Structural challenges and the nation’s many languages have made it tough to develop foundational AI models. But the government is keen not to be left behind.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://gist.github.com/chriscarrollsmith/4670b8466e19e77723327cb555f638e6">Coders' Colaboratory mini-hackathon on `llm` by simonw</a></div>
    <div class="card-image"><a href="https://gist.github.com/chriscarrollsmith/4670b8466e19e77723327cb555f638e6"><img src="https://github.githubassets.com/assets/gist-og-image-54fd7dc0713e.png" alt=""></a></div>
    <p class="card-excerpt">Coders' Colaboratory mini-hackathon on `llm` by simonw - llm-hackathon.md</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.youtube.com/watch?v=5RIOQuHOihY">What is Ollama? Running Local LLMs Made Simple</a></div>
    <div class="card-image"><a href="https://www.youtube.com/watch?v=5RIOQuHOihY"><img src="https://i.ytimg.com/vi/5RIOQuHOihY/maxresdefault.jpg" alt=""></a></div>
    <p class="card-excerpt">Ready to become a certified watsonx AI Assistant Engineer? Register now and use code IBMTechYT20 for 20% off of your exam → https://ibm.biz/Bdnd3dLearn more ...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/May/15/building-on-llms/">Building software on top of Large Language Models</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/May/15/building-on-llms/"><img src="https://static.simonwillison.net/static/2025/building-apps-on-llms/llm-tutorial-intro.001.jpeg" alt=""></a></div>
    <p class="card-excerpt">I presented a three hour workshop at PyCon US yesterday titled Building software on top of Large Language Models. The goal of the workshop was to give participants everything they …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/May/27/llm-tools/#atom-everything">Large Language Models can run tools in your terminal with LLM 0.26</a></div>
    <p class="card-excerpt">LLM 0.26 is out with the biggest new feature since I started the project: support for tools. You can now use the LLM CLI tool—and Python library—to grant LLMs from …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/06/28/getting-started-with-gemini-command-line-interface-cli/">Getting started with Gemini Command Line Interface (CLI)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/06/28/getting-started-with-gemini-command-line-interface-cli/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/06/Screenshot-2025-06-28-at-1.12.52%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/7-popular-llms-explained-in-7-minutes">7 Popular LLMs Explained in 7 Minutes - KDnuggets</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/7-popular-llms-explained-in-7-minutes"><img src="https://www.kdnuggets.com/wp-content/uploads/kdn-mehreen-7-llms-explained-7-minutes.png" alt=""></a></div>
    <p class="card-excerpt">Get a quick overview of GPT, BERT, LLaMA, and more!</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.designboom.com/technology/ai-language-models-chatgpt-gemini-understand-flowers-ohio-state-university-06-04-2025/">why AI language models like chatGPT can’t understand flowers</a></div>
    <div class="card-image"><a href="https://www.designboom.com/technology/ai-language-models-chatgpt-gemini-understand-flowers-ohio-state-university-06-04-2025/"><img src="https://www.designboom.com/wp-content/uploads/2025/06/AI-language-models-chatGPT-gemini-flowers-designboom-1.jpg" alt=""></a></div>
    <p class="card-excerpt">a study by ohio state university investigates whether large language models can represent human concepts without physically experiencing them.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.understandingai.org/p/what-i-learned-trying-seven-coding">What I learned trying seven coding agents</a></div>
    <div class="card-image"><a href="https://www.understandingai.org/p/what-i-learned-trying-seven-coding"><img src="https://substackcdn.com/image/fetch/$s_!JUwd!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc40039-abfd-4a4e-9562-9c92a0b4fcfa_4032x2688.jpeg" alt=""></a></div>
    <p class="card-excerpt">There's still room for improvement, but don't underestimate this technology.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anthropic.com/engineering/building-effective-agents">Building Effective AI Agents</a></div>
    <div class="card-image"><a href="https://www.anthropic.com/engineering/building-effective-agents"><img src="https://cdn.sanity.io/images/4zrzovbb/website/76b5733c669f0dfb9c7aa7fc512a495867cf12e6-2400x1260.png" alt=""></a></div>
    <p class="card-excerpt">Discover how Anthropic approaches the development of reliable AI agents. Learn about our research on agent capabilities, safety considerations, and technical framework for building trustworthy AI.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/32-mcp-servers-you-need-to-check-out-now">32 MCP Servers You Need To Check Out Now - KDnuggets</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/32-mcp-servers-you-need-to-check-out-now"><img src="https://www.kdnuggets.com/wp-content/uploads/awan_top_30_mcp_servers_missing_1.png" alt=""></a></div>
    <p class="card-excerpt">Explore list of top MCP servers that enable seamless integration of LLMs with tools like databases, APIs, communication platforms, and more, helping you automate workflows and enhance AI applications.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/">Highlights from the Claude 4 system prompt</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/"><img src="https://static.simonwillison.net/static/2025/opus-sonnet-diff.jpg" alt=""></a></div>
    <p class="card-excerpt">Anthropic publish most of the system prompts for their chat models as part of their release notes. They recently shared the new prompts for both Claude Opus 4 and Claude …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/May/25/claude-4-system-card/">System Card: Claude Opus 4 & Claude Sonnet 4</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/May/25/claude-4-system-card/"><img src="https://static.simonwillison.net/static/2025/claude-social-bliss.jpg" alt=""></a></div>
    <p class="card-excerpt">Direct link to a PDF on Anthropic's CDN because they don't appear to have a landing page anywhere for this document. Anthropic's system cards are always worth a look, and …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/the-ultimate-guide-to-learning-anything-with-notebooklm">The Ultimate Guide to Learning Anything with NotebookLM - KDnuggets</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/the-ultimate-guide-to-learning-anything-with-notebooklm"><img src="https://www.kdnuggets.com/wp-content/uploads/cover_photo.jpeg" alt=""></a></div>
    <p class="card-excerpt">Learn about turning your notes and sources into a personalized, AI-powered tutor with NotebookLM.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/May/22/llm-anthropic-016/#atom-everything">llm-anthropic 0.16</a></div>
    <p class="card-excerpt">New release of my LLM plugin for Anthropic adding the new Claude 4 Opus and Sonnet models. You can see pelicans on bicycles generated using the new plugin at the …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.alphaxiv.org/abs/2505.09343">Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures | alphaXiv</a></div>
    <div class="card-image"><a href="https://www.alphaxiv.org/abs/2505.09343"><img src="https://paper-assets.alphaxiv.org/image/2505.09343v1.png" alt=""></a></div>
    <p class="card-excerpt">View recent discussion. Abstract: The rapid scaling of large language models (LLMs) has unveiled critical
limitations in current hardware architectures, including constraints in memory
capacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,
trained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model
co-design can effectively address these challenges, enabling cost-efficient
training and inference at scale. This paper presents an in-depth analysis of
the DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting
key innovations such as Multi-head Latent Attention (MLA) for enhanced memory
efficiency, Mixture of Experts (MoE) architectures for optimized
computation-communication trade-offs, FP8 mixed-precision training to unlock
the full potential of hardware capabilities, and a Multi-Plane Network Topology
to minimize cluster-level network overhead. Building on the hardware
bottlenecks encountered during DeepSeek-V3's development, we engage in a
broader discussion with academic and industry peers on potential future
hardware directions, including precise low-precision computation units,
scale-up and scale-out convergence, and innovations in low-latency
communication fabrics. These insights underscore the critical role of hardware
and model co-design in meeting the escalating demands of AI workloads, offering
a practical blueprint for innovation in next-generation AI systems.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/05/20/meta-introduces-kernelllm-an-8b-llm-that-translates-pytorch-modules-into-efficient-triton-gpu-kernels/">Meta Introduces KernelLLM: An 8B LLM that Translates PyTorch Modules into Efficient Triton GPU Kernels</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/05/20/meta-introduces-kernelllm-an-8b-llm-that-translates-pytorch-modules-into-efficient-triton-gpu-kernels/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/05/llm_performance_comparison-scaled.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/building-ai-agents-a2a-vs-mcp-explained-simply">Building AI Agents? A2A vs. MCP Explained Simply - KDnuggets</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/building-ai-agents-a2a-vs-mcp-explained-simply"><img src="https://www.kdnuggets.com/wp-content/uploads/Building-AI-Agents-A2A-vs.-MCP-Explained-Simply.png" alt=""></a></div>
    <p class="card-excerpt">Confused by AI agent frameworks? This article makes sense of A2A and MCP.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/mendableai/firecrawl">mendableai/firecrawl: 🔥 Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.</a></div>
    <div class="card-image"><a href="https://github.com/mendableai/firecrawl"><img src="https://opengraph.githubassets.com/ec5c8370b1c6cf9e156235583592eaee1b7b9ba07fade23af876778e255ace6d/mendableai/firecrawl" alt=""></a></div>
    <p class="card-excerpt">🔥 Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API. - mendableai/firecrawl</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.scmp.com/tech/tech-trends/article/3309298/alibabas-qwen3-topples-deepseeks-r1-worlds-highest-ranked-open-source-ai-model?utm_source=feedly_feed">Alibaba’s Qwen3 topples DeepSeek’s R1 as world’s highest-ranked open-source AI model</a></div>
    <div class="card-image"><a href="https://www.scmp.com/tech/tech-trends/article/3309298/alibabas-qwen3-topples-deepseeks-r1-worlds-highest-ranked-open-source-ai-model?utm_source=feedly_feed"><img src="https://cdn.i-scmp.com/sites/default/files/styles/og_image_scmp_generic/public/d8/images/canvas/2025/05/06/2ae3cc07-8aac-4a86-bd1b-da62b9cbf94b_4f2fd00a.jpg?itok=zWIAmbHa&v=1746532811" alt=""></a></div>
    <p class="card-excerpt">Qwen3 surpassed R1 in LiveBench tests that gauge open-source AI models’ capabilities including coding, maths and data analysis.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view">22365_3_Prompt Engineering_v7 (1).pdf</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kaggle.com/whitepaper-prompt-engineering">Prompt Engineering | Kaggle</a></div>
    <div class="card-image"><a href="https://www.kaggle.com/whitepaper-prompt-engineering"><img src="https://www.kaggle.com/static/images/logos/kaggle-logo-opengraph.png" alt=""></a></div>
    <p class="card-excerpt">Kaggle is the world’s largest data science community with powerful tools and resources to help you achieve your data science goals.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://openai.com/index/introducing-4o-image-generation">Introducing 4o Image Generation</a></div>
    <div class="card-image"><a href="https://openai.com/index/introducing-4o-image-generation"><img src="https://images.ctfassets.net/kftzwdyauwt9/7c9f18hYL29IcnVw1Gl2xN/e8f302e2cc7cd012a93c78043dfbd5b0/oai_image-generation_seo.png?w=1600&h=900&fit=fill" alt=""></a></div>
    <p class="card-excerpt">At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Mar/25/gemini/">Putting Gemini 2.5 Pro through its paces</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/Mar/25/gemini/"><img src="https://static.simonwillison.net/static/2025/gemini-pelicans-bbox.jpg" alt=""></a></div>
    <p class="card-excerpt">There’s a new release from Google Gemini this morning: the first in the Gemini 2.5 series. Google call it “a thinking model, designed to tackle increasingly complex problems”. It’s already …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://ampcode.com/how-to-build-an-agent">How To Build An Agent | Amp</a></div>
    <div class="card-image"><a href="https://ampcode.com/how-to-build-an-agent"><img src="https://ampcode.com/og-how-to-build-an-agent.jpg" alt=""></a></div>
    <p class="card-excerpt">Building a fully functional, code-editing agent in less than 400 lines.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://wccftech.com/deepseek-r2-ai-model-rumors-begin-to-swirl-online/">DeepSeek R2 AI Model Rumors Begin to Swirl Online; Reported to Feature 97% Lower Costs Compared to GPT-4…</a></div>
    <div class="card-image"><a href="https://wccftech.com/deepseek-r2-ai-model-rumors-begin-to-swirl-online/"><img src="https://cdn.wccftech.com/wp-content/uploads/2025/04/DeepSeek-2.jpg" alt=""></a></div>
    <p class="card-excerpt">DeepSeek is set to drop another model pretty soon, as details about their next DeepSeek R2 model have surfaced on the internet</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/XiaomiMiMo/MiMo">XiaomiMiMo/MiMo: MiMo: Unlocking the Reasoning Potential of Language Model – From Pretraining to Posttraining</a></div>
    <div class="card-image"><a href="https://github.com/XiaomiMiMo/MiMo"><img src="https://opengraph.githubassets.com/fb08ce94b0e0c8e759a908b39e9c9553d09e88b112b5f752ae10934db8c5233c/XiaomiMiMo/MiMo" alt=""></a></div>
    <p class="card-excerpt">MiMo: Unlocking the Reasoning Potential of Language Model – From Pretraining to Posttraining - XiaomiMiMo/MiMo</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thecleverprogrammer.com/2025/05/03/llm-projects-with-python/">LLM Projects with Python</a></div>
    <div class="card-image"><a href="https://thecleverprogrammer.com/2025/05/03/llm-projects-with-python/"><img src="https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2025/05/10-Projects-to-Master-LLMs-with-Python.png?fit=1200%2C628&ssl=1" alt=""></a></div>
    <p class="card-excerpt">In this article, I'll take you through a list of 10 hands-on LLM projects with Python you should try to master LLMs. LLM Projects with Python.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://eltonminetto.dev/en/post/2025-05-01-mcp-server-golang/">Creating an MCP Server Using Go</a></div>
    <p class="card-excerpt">In November 2024, Anthropic published a blog post announcing what may be its most significant contribution to the AI ecosystem so far: the Model Context Protocol.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5240330">Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers</a></div>
    <div class="card-image"><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5240330"><img src="https://cdn.ssrn.com/ssrn-global-header/11589acb53bc518aa22929bf19add113.svg" alt=""></a></div>
    <p class="card-excerpt">Understanding architectural differences between large language models (LLMs) remains challenging, particularly at academic-scale pretraining (e.g., 1.3B</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/May/4/llm-sampling/#atom-everything">Dummy’s Guide to Modern LLM Sampling</a></div>
    <p class="card-excerpt">This is an extremely useful, detailed set of explanations by [@AlpinDale](https://x.com/AlpinDale) covering the various different sampling strategies used by modern LLMs. LLMs return a set of next-token probabilities for every …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2504.20879">The Leaderboard Illusion</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2504.20879"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Measuring progress is fundamental to the advancement of any scientific field. As benchmarks play an increasingly central role, they also grow more susceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems. Yet, in this work we identify systematic issues that have resulted in a distorted playing field. We find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired. We establish that the ability of these providers to choose the best score leads to biased Arena scores due to selective disclosure of performance results. At an extreme, we identify 27 private LLM variants tested by Meta in the lead-up to the Llama-4 release. We also establish that proprietary closed models are sampled at higher rates (number of battles) and have fewer models removed from the arena than open-weight and open-source alternatives. Both these policies lead to large data access asymmetries over time. Providers like Google and OpenAI have received an estimated 19.2% and 20.4% of all data on the arena, respectively. In contrast, a combined 83 open-weight models have only received an estimated 29.7% of the total data. We show that access to Chatbot Arena data yields substantial benefits; even limited additional data can result in relative performance gains of up to 112% on the arena distribution, based on our conservative estimates. Together, these dynamics result in overfitting to Arena-specific dynamics rather than general model quality. The Arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform. We offer actionable recommendations to reform the Chatbot Arena's evaluation framework and promote fairer, more transparent benchmarking for the field</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://huggingface.co/blog/Kseniase/attentions?fbclid=IwY2xjawJgrQhleHRuA2FlbQIxMQABHjZ2_OJkyTAVEb-K0wkUoq4VLTCrgIWQ4125yvu1GyuwHh6iHTCmJVAMstBF_aem_advNV4bDfVovH5jPMetwpQ">Topic 33: Slim Attention, KArAt, XAttention and Multi-Token Attention Explained – What’s Really Changing in Transformers?</a></div>
    <div class="card-image"><a href="https://huggingface.co/blog/Kseniase/attentions?fbclid=IwY2xjawJgrQhleHRuA2FlbQIxMQABHjZ2_OJkyTAVEb-K0wkUoq4VLTCrgIWQ4125yvu1GyuwHh6iHTCmJVAMstBF_aem_advNV4bDfVovH5jPMetwpQ"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/blog/Kseniase/attentions.png" alt=""></a></div>
    <p class="card-excerpt">A Blog post by Ksenia Se on Hugging Face</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.philschmid.de/mcp-introduction">Model Context Protocol (MCP) an overview</a></div>
    <div class="card-image"><a href="https://www.philschmid.de/mcp-introduction"><img src="https://www.philschmid.de/static/blog/mcp-introduction/thumbnail.jpg" alt=""></a></div>
    <p class="card-excerpt">Overview of the Model Context Protocol (MCP) how it works, what are MCP servers and clients, and how to use it.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Apr/9/an-llm-query-understanding-service/#atom-everything">An LLM Query Understanding Service</a></div>
    <p class="card-excerpt">Doug Turnbull recently wrote about how [all search is structured now](https://softwaredoug.com/blog/2025/04/02/all-search-structured-now):  Many times, even a small open source LLM will be able to turn a search query into reasonable …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/04/04/a-code-implementation-to-building-a-context-aware-ai-assistant-in-google-colab-using-langchain-langgraph-gemini-pro-and-model-context-protocol-mcp-principles-with-tool-integration-support/">A Code Implementation to Building a Context-Aware AI Assistant in Google Colab Using LangChain, LangGraph, Gemini Pro, and Model Context Protocol (MCP) Principles with Tool Integration Support</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/04/04/a-code-implementation-to-building-a-context-aware-ai-assistant-in-google-colab-using-langchain-langgraph-gemini-pro-and-model-context-protocol-mcp-principles-with-tool-integration-support/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/04/Screenshot-2025-04-04-at-10.45.12 PM.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.quantamagazine.org/to-make-language-models-work-better-researchers-sidestep-language-20250414/">To Make Language Models Work Better, Researchers Sidestep Language | Quanta Magazine</a></div>
    <div class="card-image"><a href="https://www.quantamagazine.org/to-make-language-models-work-better-researchers-sidestep-language-20250414/"><img src="https://www.quantamagazine.org/wp-content/uploads/2025/04/LLMNativeLanguage-crMyriamWares-Social.jpg" alt=""></a></div>
    <p class="card-excerpt">We insist that large language models repeatedly translate their mathematical processes into words. There may be a better way.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning.html">The State of Reinforcement Learning for LLM Reasoning</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning.html"><img src="https://sebastianraschka.com/images/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning/hero.jpg" alt=""></a></div>
    <p class="card-excerpt">A lot has happened this month, especially with the releases of new flagship models like GPT-4.5 and Llama 4. But you might have noticed that reactions to these releases were relatively muted. Why? One reason could be that GPT-4.5 and Llama 4 remain conventional models, which means they were trained without explicit reinforcement learning for reasoning. However, OpenAI's recent release of the o3 reasoning model demonstrates there is still considerable room for improvement when investing compute strategically, specifically via reinforcement learning methods tailored for reasoning tasks. While reasoning alone isn't a silver bullet, it reliably improves model accuracy and problem-solving capabilities on challenging tasks (so far). And I expect reasoning-focused post-training to become standard practice in future LLM pipelines. So, in this article, let's explore the latest developments in reasoning via reinforcement learning.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2025/first-look-at-reasoning-from-scratch.html">First Look at Reasoning From Scratch: Chapter 1</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2025/first-look-at-reasoning-from-scratch.html"><img src="https://sebastianraschka.com/images/blog/2025/first-look-at-reasoning-from-scratch/hero.jpg" alt=""></a></div>
    <p class="card-excerpt">As you know, I've been writing a lot lately about the latest research on reasoning in LLMs. Before my next research-focused blog post, I wanted to offer something special to my paid subscribers as a thank-you for your ongoing support. So, I've started writing a new book on how reasoning works in LLMs, and here I'm sharing the first Chapter 1 with you. This ~15-page chapter is an introduction reasoning in the context of LLMs and provides an overview of methods like inference-time scaling and reinforcement learning. Thanks for your support! I hope you enjoy the chapter, and stay tuned for my next blog post on reasoning research!</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Mar/26/function-calling-with-gemma/">Function calling with Gemma</a></div>
    <p class="card-excerpt">Google's Gemma 3 model (the 27B variant is particularly capable, I've been trying it out [via Ollama](https://ollama.com/library/gemma3)) supports function calling exclusively through prompt engineering. The official documentation describes two recommended …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://docs.mistral.ai/getting-started/quickstart/">Quickstart | Mistral AI Large Language Models</a></div>
    <div class="card-image"><a href="https://docs.mistral.ai/getting-started/quickstart/"><img src="https://docs.mistral.ai/img/mistral-social-banner.jpg" alt=""></a></div>
    <p class="card-excerpt">[platform_url]//console.mistral.ai/</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://lobste.rs/s/seuxei">12-factor-agents: Principles to build LLM-powered software good enough to put in the hands of production customers</a></div>
    <div class="card-image"><a href="https://lobste.rs/s/seuxei"><img src="https://lobste.rs/touch-icon-144.png" alt=""></a></div>
    <p class="card-excerpt">0 comments</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/aisupremacy/p/how-to-use-notebooklm-for-personalized?r=oc5d&utm_medium=ios">How to use NotebookLM for personalized knowledge synthesis</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/aisupremacy/p/how-to-use-notebooklm-for-personalized?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff23e8588-91f1-47a3-b5cf-8bb46da33ef8_1200x750.webp" alt=""></a></div>
    <p class="card-excerpt">Two powerful workflows that unlock everything else. Intro: Golden Age of AI Tools and AI agent frameworks begins in 2025.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_campaign=post&utm_medium=web">LLM Research Papers: The 2024 List</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_campaign=post&utm_medium=web"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba1c2ab-7ae7-4f22-86df-f116f2914cd5_1272x1232.png" alt=""></a></div>
    <p class="card-excerpt">A curated list of interesting LLM-related research papers from 2024, shared for those looking for something to read over the holidays.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/12/14/how-llms-store-and-use-knowledge-this-ai-paper-introduces-knowledge-circuits-a-framework-for-understanding-and-improving-knowledge-storage-in-transformer-based-llms/">How LLMs Store and Use Knowledge? This AI Paper Introduces Knowledge Circuits: A Framework for Understanding and Improving Knowledge Storage in Transformer-Based LLMs</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/12/14/how-llms-store-and-use-knowledge-this-ai-paper-introduces-knowledge-circuits-a-framework-for-understanding-and-improving-knowledge-storage-in-transformer-based-llms/"><img src="https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-14-at-8.35.53%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt">Large language models (LLMs) can understand and generate human-like text by encoding vast knowledge repositories within their parameters. This capacity enables them to perform complex reasoning tasks, adapt to various applications, and interact effectively with humans. However, despite their remarkable achievements, researchers continue to investigate the mechanisms underlying the storage and utilization of knowledge in these systems, aiming to enhance their efficiency and reliability further. A key challenge in using large language models is their propensity to generate inaccurate, biased, or hallucinatory outputs. These problems arise from a limited understanding of how such models organize and access knowledge. Without clear</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="http://www.techmeme.com/250407/p2#a250407p2">A look at the ARC-AGI exam designed by French computer scientist François Chollet to show the gulf between AI models' memorized answers and “fluid intelligence”</a></div>
    <div class="card-image"><a href="http://www.techmeme.com/250407/p2#a250407p2"><img src="https://i.imgur.com/q0p1thB.jpg" alt=""></a></div>
    <p class="card-excerpt">By Matteo Wong / The Atlantic. View the full context on Techmeme.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.turingpost.com/p/mlalightthinker">Topic 31: How to Reduce Memory Use in Reasoning Models</a></div>
    <div class="card-image"><a href="https://www.turingpost.com/p/mlalightthinker"><img src="https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/318273c0-c61b-486b-969c-2c4b6e4e425a/LightThinker_MLA__1_.png?t=1741805639" alt=""></a></div>
    <p class="card-excerpt">we explore how combining LightThinker and Multi-Head Latent Attention cuts memory and boosts performance</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/04/17/openai-releases-a-practical-guide-to-building-llm-agents-for-real-world-applications/">OpenAI Releases a Practical Guide to Building LLM Agents for Real-World Applications</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/04/17/openai-releases-a-practical-guide-to-building-llm-agents-for-real-world-applications/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/04/a-digital-illustration-of-an-open-book-w_8QSSNEMdQx-4WmKW4sVoOA__ZIxHjjXTFSXziTaC-K5Kg.jpeg" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/html/2502.21321?fbclid=IwY2xjawJtMIRleHRuA2FlbQIxMQABHtJFOZyM1YENbtAyJPt3Tu4AwMLLtXMWUkanORsu4qZWoDfwikg1UiegOAkK_aem_4SsqZCqR6ngkPHdizAPnEw">LLM Post-Training: A Deep Dive into Reasoning Large Language Models</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/humanlayer/12-factor-agents">humanlayer/12-factor-agents</a></div>
    <div class="card-image"><a href="https://github.com/humanlayer/12-factor-agents"><img src="https://opengraph.githubassets.com/e579fb0260b1b42e47d176d09f37c29ed4f131b61d25b5a123b635ca5212f7fc/humanlayer/12-factor-agents" alt=""></a></div>
    <p class="card-excerpt">What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers? - humanlayer/12-factor-agents</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://socket.dev/blog/slopsquatting-how-ai-hallucinations-are-fueling-a-new-class-of-supply-chain-attacks">The Rise of Slopsquatting: How AI Hallucinations Are Fueling...</a></div>
    <div class="card-image"><a href="https://socket.dev/blog/slopsquatting-how-ai-hallucinations-are-fueling-a-new-class-of-supply-chain-attacks"><img src="https://cdn.sanity.io/images/cgdhsj6q/production/e41299999742507d0c00b344ca3b52e3b1b67b1d-1024x1024.webp?w=1000&fit=max&auto=format" alt=""></a></div>
    <p class="card-excerpt">Slopsquatting is a new supply chain threat where AI-assisted code generators recommend hallucinated packages that attackers register and weaponize.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.theatlantic.com/technology/archive/2025/04/arc-agi-chollet-test/682295/?gift=2iIN4YrefPjuvZ5d2Kh3089M3DxlABplHmODO9XssmE&utm_source=copy-link&utm_medium=social&utm_campaign=share">The Man Out to Prove How Dumb AI Still Is</a></div>
    <div class="card-image"><a href="https://www.theatlantic.com/technology/archive/2025/04/arc-agi-chollet-test/682295/?gift=2iIN4YrefPjuvZ5d2Kh3089M3DxlABplHmODO9XssmE&utm_source=copy-link&utm_medium=social&utm_campaign=share"><img src="https://cdn.theatlantic.com/thumbor/TQ7unWwrL3WWTg13JHKKLeS9j1w=/0x43:2000x1085/1200x625/filters:watermark(https://cdn.theatlantic.com/media/files/badge_2x.png,-20,20,0,33)/media/img/mt/2025/04/THE_ATLANTIC_ANIMATION_V2/original.gif" alt=""></a></div>
    <p class="card-excerpt">François Chollet has constructed the ultimate test for the bots.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b">The “S” in MCP Stands for Security - Elena Cross - Medium</a></div>
    <div class="card-image"><a href="https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*RtOk34kJQCS9hQjg" alt=""></a></div>
    <p class="card-excerpt">MCP, short for Model Context Protocol, is the hot new standard behind how Large Language Models (LLMs) like Claude, GPT, or Cursor integrate with tools and data. It’s been described as the “USB-C for…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://machinelearningmastery.com/10-must-know-python-libraries-for-llms-in-2025/">10 Must-Know Python Libraries for LLMs in 2025</a></div>
    <div class="card-image"><a href="https://machinelearningmastery.com/10-must-know-python-libraries-for-llms-in-2025/"><img src="https://machinelearningmastery.com/wp-content/uploads/2025/03/mlm-blast-off-10-llm-python-libs.png" alt=""></a></div>
    <p class="card-excerpt">In this article, we explore 10 of the Python libraries every developer should know in 2025.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.technologyreview.com/2025/03/27/1113916/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/">Anthropic can now track the bizarre inner workings of a large language model</a></div>
    <div class="card-image"><a href="https://www.technologyreview.com/2025/03/27/1113916/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/"><img src="https://wp.technologyreview.com/wp-content/uploads/2025/03/anthropic-rabbit-hole.jpg?resize=854,569" alt=""></a></div>
    <p class="card-excerpt">What they found challenges some basic assumptions about how this technology really works.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://developer.nvidia.com/blog/llm-benchmarking-fundamental-concepts/">LLM Benchmarking: Fundamental Concepts | NVIDIA Technical Blog</a></div>
    <div class="card-image"><a href="https://developer.nvidia.com/blog/llm-benchmarking-fundamental-concepts/"><img src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/03/data-center.png" alt=""></a></div>
    <p class="card-excerpt">The past few years have witnessed the rise in popularity of generative AI and large language models (LLMs), as part of a broad AI revolution.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/">The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation</a></div>
    <div class="card-image"><a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/"><img src="https://scontent-ber1-1.xx.fbcdn.net/v/t39.2365-6/488639590_2182781778834283_7341615399691839509_n.png?_nc_cat=107&ccb=1-7&_nc_sid=e280be&_nc_ohc=9buYuGUTUwMQ7kNvwGtzUMi&_nc_oc=AdkN3SnJ11eSLEUJlk4ya4OUL7KaIj2j0TnxIsboqdpW3969c7_L8tK24zlT4Og1jfg&_nc_zt=14&_nc_ht=scontent-ber1-1.xx&_nc_gid=O7pjMcOm63OU1lqMXrq3Zg&oh=00_AYEQyK79iiih-1eagCAdYCNZR346qSKGGzOYg-Mlp3NBdQ&oe=680BDB60" alt=""></a></div>
    <p class="card-excerpt">We’re introducing Llama 4 Scout and Llama 4 Maverick, the first open-weight natively multimodal models with unprecedented context support and our first built using a mixture-of-experts (MoE) architecture.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://code.visualstudio.com/docs/copilot/chat/mcp-servers">Use MCP servers in VS Code (Preview)</a></div>
    <div class="card-image"><a href="https://code.visualstudio.com/docs/copilot/chat/mcp-servers"><img src="https://code.visualstudio.com/assets/docs/copilot/shared/github-copilot-social.png" alt=""></a></div>
    <p class="card-excerpt">Learn how to configure and use Model Context Protocol (MCP) servers with GitHub Copilot in Visual Studio Code.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.wired.com/story/anthropic-benevolent-artificial-intelligence/">If Anthropic Succeeds, a Nation of Benevolent AI Geniuses Could Be Born</a></div>
    <div class="card-image"><a href="https://www.wired.com/story/anthropic-benevolent-artificial-intelligence/"><img src="https://media.wired.com/photos/67dc466ffa0c3a77d4f8f567/16:9/w_2496,h_1404,c_limit/WIRED_ANTHROPIC_002-V2_web.jpg" alt=""></a></div>
    <p class="card-excerpt">The brother goes on vision quests. The sister is a former English major. Together, they defected from OpenAI, started Anthropic, and built (they say) AI’s most upstanding citizen, Claude.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/04/01/a-comprehensive-guide-to-llm-routing-tools-and-frameworks/">A Comprehensive Guide to LLM Routing: Tools and Frameworks</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/04/01/a-comprehensive-guide-to-llm-routing-tools-and-frameworks/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/04/a-technical-image-of-a-neural-network-di_tmx_npS1R8yb9IaVjwNgyA_3MR4BRKNRJWs2SRcefBz7g.png" alt=""></a></div>
    <p class="card-excerpt">Deploying LLMs presents challenges, particularly in optimizing efficiency, managing computational costs, and ensuring high-quality performance. LLM routing has emerged as a strategic solution to these challenges, enabling intelligent task allocation to the most suitable models or tools. Let’s delve into the intricacies of LLM routing, explore various tools and frameworks designed for its implementation, and […]</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.youtube.com/watch?v=0VLAoVGf_74">How DeepSeek Rewrote the Transformer [MLA]</a></div>
    <div class="card-image"><a href="https://www.youtube.com/watch?v=0VLAoVGf_74"><img src="https://i.ytimg.com/vi/0VLAoVGf_74/maxresdefault.jpg" alt=""></a></div>
    <p class="card-excerpt">Thanks to KiwiCo for sponsoring today’s video! Go to https://www.kiwico.com/welchlabs and use code WELCHLABS for 50% off your first monthly club crate or for...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Mar/27/tracing-the-thoughts-of-a-large-language-model/#atom-everything">Tracing the thoughts of a large language model</a></div>
    <p class="card-excerpt">In a follow-up to the research that brought us the [delightful Golden Gate Claude](https://simonwillison.net/2024/May/24/golden-gate-claude/) last year, Anthropic have published two new papers about LLM interpretability: - [Circuit Tracing: Revealing Computational …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2025/03/25/what-is-the-hallucination-index/">What is the hallucination index?</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2025/03/25/what-is-the-hallucination-index/"><img src="https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png" alt=""></a></div>
    <p class="card-excerpt">The Hallucination Index is a benchmark that measures the frequency of inaccuracies in large language models, indicating their reliability and contextual understanding.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://eugeneyan.com/writing/recsys-llm/">Improving Recommender Systems & Search in the Age of LLMs</a></div>
    <div class="card-image"><a href="https://eugeneyan.com/writing/recsys-llm/"><img src="https://eugeneyan.com/assets/og_image/recsys-llm.jpg" alt=""></a></div>
    <p class="card-excerpt">Model architectures, data generation, training paradigms, and unified frameworks inspired by LLMs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/anthropic-just-gave-claude-a-superpower-real-time-web-search-heres-why-it-changes-everything/">Anthropic just gave Claude a superpower: real-time web search. Here’s why it changes everything</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/anthropic-just-gave-claude-a-superpower-real-time-web-search-heres-why-it-changes-everything/"><img src="https://venturebeat.com/wp-content/uploads/2025/03/website-hero-websearch.jpg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Anthropic launches real-time web search for Claude AI, challenging ChatGPT's dominance while securing $3.5 billion in funding at a $61.5 billion valuation.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://mistral.ai/fr/news/mistral-ocr">Mistral OCR | Mistral AI</a></div>
    <div class="card-image"><a href="https://mistral.ai/fr/news/mistral-ocr"><img src="https://cms.mistral.ai/assets/060bdeb1-fbff-419c-b2ae-b32b5e441864" alt=""></a></div>
    <p class="card-excerpt">Introducing the world’s best document understanding API.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Mar/7/mistral-ocr/#atom-everything">Mistral OCR</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/Mar/7/mistral-ocr/#atom-everything"><img src="https://static.simonwillison.net/static/2025/mixtral-as-html.jpg" alt=""></a></div>
    <p class="card-excerpt">New closed-source specialist OCR model by Mistral - you can feed it images or a PDF and it produces Markdown with optional embedded images. It's available [via their API](https://docs.mistral.ai/api/#tag/ocr), or …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2025/03/18/mistral-small-3-1-runs-on-a-macbook-and-beats-giants/">Mistral Small 3.1 runs on a MacBook and beats giants - Dataconomy</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2025/03/18/mistral-small-3-1-runs-on-a-macbook-and-beats-giants/"><img src="https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png" alt=""></a></div>
    <p class="card-excerpt">Paris-based artificial intelligence startup Mistral AI has announced the open-source release of its lightweight AI model, Mistral Small 3.1, which the company</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Mar/17/mistral-small-31/#atom-everything">Mistral Small 3.1</a></div>
    <p class="card-excerpt">Mistral Small 3 [came out in January](https://simonwillison.net/2025/Jan/30/mistral-small-3/) and was a notable, genuinely excellent local model that used an Apache 2.0 license. Mistral Small 3.1 offers a significant improvement: it's multi-modal …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2025/03/12/what-are-model-cards/">What are model cards? - Dataconomy</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2025/03/12/what-are-model-cards/"><img src="https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png" alt=""></a></div>
    <p class="card-excerpt">Model cards are documentation tools in machine learning that provide essential information about models, promoting transparency, trust, and ethical considerations in AI systems.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/02/16/a-step-by-step-guide-to-setting-up-a-custom-bpe-tokenizer-with-tiktoken-for-advanced-nlp-applications-in-python/">A Step-by-Step Guide to Setting Up a Custom BPE Tokenizer with Tiktoken for Advanced NLP Applications in Python</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/02/16/a-step-by-step-guide-to-setting-up-a-custom-bpe-tokenizer-with-tiktoken-for-advanced-nlp-applications-in-python/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/02/Screenshot-2025-02-16-at-10.17.33 PM.png" alt=""></a></div>
    <p class="card-excerpt">A Step-by-Step Guide to Setting Up a Custom BPE Tokenizer with Tiktoken for Advanced NLP Applications in Python</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/sebastianraschka/p/state-of-llm-reasoning-and-inference-scaling?r=oc5d&utm_medium=ios">The State of LLM Reasoning Models</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/sebastianraschka/p/state-of-llm-reasoning-and-inference-scaling?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf9e2677-652a-4af1-9f57-dc0c253d2198_1448x1260.png" alt=""></a></div>
    <p class="card-excerpt">Part 1: Inference-Time Compute Scaling Methods</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.r-bloggers.com/2025/03/the-ellmer-package-for-using-llms-with-r-is-a-game-changer-for-scientists-2/">https://www.r-bloggers.com/2025/03/the-ellmer-package-for-using-llms-with-r-is-a-game-changer-for-scientists-2/</a></div>
    <div class="card-image"><a href="https://www.r-bloggers.com/2025/03/the-ellmer-package-for-using-llms-with-r-is-a-game-changer-for-scientists-2/"><img src="https://www.r-bloggers.com/wp-content/uploads/2016/08/R_single_01-200-1.png" alt=""></a></div>
    <p class="card-excerpt">The ellmer package for using LLMs with R is a game changer for scientists Why is ellmer a game changer for scientists? In this tutorial we’ll look at how we can access LLM agents through API calls. We’ll use this skill for created structued data fro...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2025/03/13/what-is-catastrophic-forgetting/">What is catastrophic forgetting? - Dataconomy</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2025/03/13/what-is-catastrophic-forgetting/"><img src="https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png" alt=""></a></div>
    <p class="card-excerpt">Catastrophic Forgetting is a phenomenon where neural networks lose previously learned information when trained on new data, similar to human memory loss.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/top-7-open-source-llms-in-2025">Top 7 Open-Source LLMs in 2025 - KDnuggets</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/top-7-open-source-llms-in-2025"><img src="https://www.kdnuggets.com/wp-content/uploads/awan_top_7_opensource_llms_2025_1.png" alt=""></a></div>
    <p class="card-excerpt">These models are free to use, can be fine-tuned, and offer enhanced privacy and security since they can run directly on your machine, and match the performance of proprietary solutions like o3-min and Gemini 2.0.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/simonw/p/how-i-use-llms-to-help-me-write-code?r=oc5d&utm_medium=ios">How I use LLMs to help me write code</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/simonw/p/how-i-use-llms-to-help-me-write-code?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5eb20c0-d125-480c-92f4-e927d0a12872_1600x1200.jpeg" alt=""></a></div>
    <p class="card-excerpt">Plus CSS view transitions and a major update to llm-openrouter</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thezvi.substack.com/p/on-gpt-45?ref=thediff.co">On GPT-4.5</a></div>
    <div class="card-image"><a href="https://thezvi.substack.com/p/on-gpt-45?ref=thediff.co"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f8cdc5b-2574-43d9-9af3-15c1a5b9a8a4_300x168.jpeg" alt=""></a></div>
    <p class="card-excerpt">It’s happening.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Mar/4/llm-ollama-090/">llm-ollama 0.9.0</a></div>
    <p class="card-excerpt">This release of the `llm-ollama` plugin adds support for [schemas](https://simonwillison.net/2025/Feb/28/llm-schemas/), thanks to a [PR by Adam Compton](https://github.com/taketwo/llm-ollama/pull/36). Ollama provides very robust support for this pattern thanks to their [structured outputs](https://ollama.com/blog/structured-outputs) …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anthropic.com/news/claude-3-7-sonnet">Claude 3.7 Sonnet and Claude Code</a></div>
    <div class="card-image"><a href="https://www.anthropic.com/news/claude-3-7-sonnet"><img src="https://cdn.sanity.io/images/4zrzovbb/website/9b52e961f8f275e21e75c477c99672abd13fe66b-2400x1260.png" alt=""></a></div>
    <p class="card-excerpt">Today, we’re announcing Claude 3.7 Sonnet, our most intelligent model to date and the first hybrid reasoning model generally available on the market.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem">The Deep Research problem — Benedict Evans</a></div>
    <div class="card-image"><a href="https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem"><img src="http://static1.squarespace.com/static/50363cf324ac8e905e7df861/5055cb1de4b0a751cabaedd5/67b3931718a8632b064c937c/1739890282987/Screenshot%2B2025-02-17%2Bat%2B4.27.52%E2%80%AFpm.png?format=1500w" alt=""></a></div>
    <p class="card-excerpt">OpenAI’s Deep Research is built for me, and I can’t use it. It’s another amazing demo, until it breaks. But it breaks in really interesting ways.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://blog.tobiaszwingmann.com/p/5-principles-for-writing-effective-prompts">5 Principles for Writing Effective Prompts (2025 Update)</a></div>
    <div class="card-image"><a href="https://blog.tobiaszwingmann.com/p/5-principles-for-writing-effective-prompts"><img src="https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/8fe61654-58ef-4d09-8b20-eae84bb194fa/Prompt_Principles_Infographic.png?t=1738815077" alt=""></a></div>
    <p class="card-excerpt">Solid techniques to get really good results from any LLM</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.linkedin.com/posts/tobias-zwingmann_openais-president-greg-brockman-recently-activity-7298713328556691458-VRM_?utm_source=share&utm_medium=member_ios&rcm=ACoAAAAQ_oABqroJaYAjd1pLSvoVsTKPWFYPcIQ">Greg Brockman shared this template for prompting</a></div>
    <div class="card-image"><a href="https://www.linkedin.com/posts/tobias-zwingmann_openais-president-greg-brockman-recently-activity-7298713328556691458-VRM_?utm_source=share&utm_medium=member_ios&rcm=ACoAAAAQ_oABqroJaYAjd1pLSvoVsTKPWFYPcIQ"><img src="https://media.licdn.com/dms/image/v2/D4E22AQGOS-pw8GvRdw/feedshare-shrink_800/B4EZUos180GwAk-/0/1740144599715?e=2147483647&v=beta&t=D_i5Vk3L2tOFUqK76RU2suKXd2qByYWYfwgOg7hUraU" alt=""></a></div>
    <p class="card-excerpt">OpenAI&#39;s president Greg Brockman recently shared this cool template for prompting their reasoning models o1/o3. Turns out, this is great for ANY reasoning… | 32 comments on LinkedIn</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://artificialanalysis.ai/leaderboards/models">LLM Leaderboard</a></div>
    <div class="card-image"><a href="https://artificialanalysis.ai/leaderboards/models"><img src="https://artificialanalysis.ai/img/open-graph/og-image.png" alt=""></a></div>
    <p class="card-excerpt">Comparison and ranking the performance of over 30 AI models (LLMs) across key metrics including quality, price, performance and speed (output speed - tokens per second & latency - TTFT), context window & others.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/">Why AI language models choke on too much text</a></div>
    <div class="card-image"><a href="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg" alt=""></a></div>
    <p class="card-excerpt">Compute costs scale with the square of the input size. That’s not great.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/whytryai/p/my-go-to-ai-tools?r=oc5d&utm_medium=ios">Here Are My Go-To AI Tools</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/whytryai/p/my-go-to-ai-tools?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc12a80fa-e1a0-458a-ae0f-e9e8e6d38bdb_1344x896.png" alt=""></a></div>
    <p class="card-excerpt">I share my preferences for LLMs, image models, AI video, AI music, AI-powered research, and more. These are the AI tools I regularly use or recommend to others.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://fly.io/blog/wrong-about-gpu/">We Were Wrong About GPUs</a></div>
    <div class="card-image"><a href="https://fly.io/blog/wrong-about-gpu/"><img src="https://fly.io/blog/wrong-about-gpu/assets/choices-choices-cover.webp" alt=""></a></div>
    <p class="card-excerpt">Do my tears surprise you? Strong CEOs also cry.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/">Using pip to install a Large Language Model that’s under 100MB</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/"><img src="https://static.simonwillison.net/static/2025/smol-card.jpg" alt=""></a></div>
    <p class="card-excerpt">I just released llm-smollm2, a new plugin for LLM that bundles a quantized copy of the SmolLM2-135M-Instruct LLM inside of the Python package. This means you can now pip install …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/02/01/creating-an-ai-agent-based-system-with-langgraph-adding-persistence-and-streaming-step-by-step-guide/">Creating an AI Agent-Based System with LangGraph: Adding Persistence and Streaming (Step by Step Guide)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/02/01/creating-an-ai-agent-based-system-with-langgraph-adding-persistence-and-streaming-step-by-step-guide/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/02/Screenshot-2025-02-01-at-10.53.44%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt">In our previous tutorial, we built an AI agent capable of answering queries by surfing the web. However, when building agents for longer-running tasks, two critical concepts come into play: persistence and streaming. Persistence allows you to save the state of an agent at any given point, enabling you to resume from that state in future interactions. This is crucial for long-running applications. On the other hand, streaming lets you emit real-time signals about what the agent is doing at any moment, providing transparency and control over its actions. In this tutorial, we’ll enhance our agent by adding these powerful</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=rss----7f60cf5620c9---4">How to Build a Graph RAG App</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*fsYI8Riyq2lAsH8wTCuKhw.png" alt=""></a></div>
    <p class="card-excerpt">Using knowledge graphs and AI to retrieve, filter, and summarize medical journal articles</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html">Understanding Reasoning LLMs</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html"><img src="https://sebastianraschka.com/images/blog/2025/understanding-reasoning-llms/hero.jpg" alt=""></a></div>
    <p class="card-excerpt">In this article, I will describe the four main approaches to building reasoning models, or how we can enhance LLMs with reasoning capabilities. I hope this p...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/5-ai-agent-frameworks-compared">5 AI Agent Frameworks Compared - KDnuggets</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/5-ai-agent-frameworks-compared"><img src="https://www.kdnuggets.com/wp-content/uploads/5-AI-Agent-Frameworks-Compared_1.jpeg" alt=""></a></div>
    <p class="card-excerpt">Check out this comparison of 5 AI frameworks to determine which you should choose.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/01/28/qwen-ai-introduces-qwen2-5-max-a-large-moe-llm-pretrained-on-massive-data-and-post-trained-with-curated-sft-and-rlhf-recipes/">Qwen AI Introduces Qwen2.5-Max: A large MoE LLM Pretrained on Massive Data and Post-Trained with Curated SFT and RLHF Recipes</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/01/28/qwen-ai-introduces-qwen2-5-max-a-large-moe-llm-pretrained-on-massive-data-and-post-trained-with-curated-sft-and-rlhf-recipes/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/01/Screenshot-2025-01-28-at-11.14.09%E2%80%AFPM-1.png" alt=""></a></div>
    <p class="card-excerpt">The field of artificial intelligence is evolving rapidly, with increasing efforts to develop more capable and efficient language models. However, scaling these models comes with challenges, particularly regarding computational resources and the complexity of training. The research community is still exploring best practices for scaling extremely large models, whether they use a dense or Mixture-of-Experts (MoE) architecture. Until recently, many details about this process were not widely shared, making it difficult to refine and improve large-scale AI systems. Qwen AI aims to address these challenges with Qwen2.5-Max, a large MoE model pretrained on over 20 trillion tokens and further refined</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/01/25/deepseek-r1-vs-openais-o1-a-new-step-in-open-source-and-proprietary-models/">DeepSeek-R1 vs. OpenAI’s o1: A New Step in Open Source and Proprietary Models</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/01/25/deepseek-r1-vs-openais-o1-a-new-step-in-open-source-and-proprietary-models/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/01/Screenshot-2025-01-25-at-6.05.44%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt">AI has entered an era of the rise of competitive and groundbreaking large language models and multimodal models. The development has two sides, one with open source and the other being propriety models. DeepSeek-R1, an open-source AI model developed by DeepSeek-AI, a Chinese research company, exemplifies this trend. Its emergence has challenged the dominance of proprietary models such as OpenAI’s o1, sparking discussions on cost efficiency, open-source innovation, and global technological leadership in AI. Let’s delve into the development, capabilities, and implications of DeepSeek-R1 while comparing it with OpenAI’s o1 system, considering the contributions of both spaces. DeepSeek-R1 DeepSeek-R1 is</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://rlhfbook.com/">(WIP) A Little Bit of Reinforcement Learning from Human Feedback</a></div>
    <div class="card-image"><a href="https://rlhfbook.com/"><img src="https://github.com/natolambert/rlhf-book/blob/main/images/rlhf-book-share" alt=""></a></div>
    <p class="card-excerpt">The Reinforcement Learning from Human Feedback Book</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/aidanmclaughlin/AidanBench">aidanmclaughlin/AidanBench: Aidan Bench attempts to measure in LLMs.</a></div>
    <div class="card-image"><a href="https://github.com/aidanmclaughlin/AidanBench"><img src="https://repository-images.githubusercontent.com/838396720/3107078a-5021-424f-a295-6306de266b1e" alt=""></a></div>
    <p class="card-excerpt">Aidan Bench attempts to measure  in LLMs. - aidanmclaughlin/AidanBench</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2025/llm-research-2024.html">Noteworthy LLM Research Papers of 2024</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2025/llm-research-2024.html"><img src="https://sebastianraschka.com/images/blog/2025/llm-research-2024/hero.jpg" alt=""></a></div>
    <p class="card-excerpt">This article covers 12 influential AI research papers of 2024, ranging from mixture-of-experts models to new LLM scaling laws for precision..</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Jan/31/o3-mini/#atom-everything">OpenAI o3-mini, now available in LLM</a></div>
    <p class="card-excerpt">o3-mini is out today. As with other o-series models it’s a slightly difficult one to evaluate—we now need to decide if a prompt is best run using GPT-4o, o1, o3-mini …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://planetbanatt.net/articles/mla.html">On MLA</a></div>
    <div class="card-image"><a href="https://planetbanatt.net/articles/mla.html"><img src="https://planetbanatt.net/images/mla/manifold_perturbation.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.pyspur.dev/blog/multi-head-latent-attention-kv-cache-paper-list">Multi-Head Latent Attention and Other KV Cache Tricks</a></div>
    <div class="card-image"><a href="https://www.pyspur.dev/blog/multi-head-latent-attention-kv-cache-paper-list"><img src="http://localhost:3000/blog/kv-cache/mla.png" alt=""></a></div>
    <p class="card-excerpt">How a Key-Value (KV) cache reduces Transformer inference time by trading memory for computation</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.reuters.com/technology/artificial-intelligence/alibaba-releases-ai-model-it-claims-surpasses-deepseek-v3-2025-01-29/">Alibaba releases AI model it says surpasses DeepSeek</a></div>
    <div class="card-image"><a href="https://www.reuters.com/technology/artificial-intelligence/alibaba-releases-ai-model-it-claims-surpasses-deepseek-v3-2025-01-29/"><img src="https://www.reuters.com/resizer/v2/GVHN3TRO5ZPMLCO5XG6ELFQC7E.jpg?auth=501e317e4440056dc491fe5a4ec8d53025386511cb2c10ee1ec72c99e2afe0e4&height=1005&width=1920&quality=80&smart=true" alt=""></a></div>
    <p class="card-excerpt">The unusual timing of the Qwen 2.5-Max's release points to the pressure DeepSeek's meteoric rise in the past three weeks has placed on overseas rivals and domestic competition.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/">Scaling Laws – O1 Pro Architecture, Reasoning Training Infrastructure, Orion and Claude 3.5 Opus “Failures”</a></div>
    <div class="card-image"><a href="https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/"><img src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2024/12/foolallthetime_A_timeline_depicted_as_a_rising_staircase_leadin_60a51d3b-d96b-461a-8ae1-afb20c02dcc7.webp?fit=1200%2C800&ssl=1" alt=""></a></div>
    <p class="card-excerpt">There has been an increasing amount of fear, uncertainty and doubt (FUD) regarding AI Scaling laws. A cavalcade of part-time AI industry prognosticators have latched on to any bearish narrative the…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nature.com/articles/d41586-025-00068-5">AI hallucinations can’t be stopped — but these techniques can limit their damage</a></div>
    <div class="card-image"><a href="https://www.nature.com/articles/d41586-025-00068-5"><img src="https://media.nature.com/lw1200/magazine-assets/d41586-025-00068-5/d41586-025-00068-5_50471802.jpg" alt=""></a></div>
    <p class="card-excerpt">Developers have tricks to stop artificial intelligence from making things up, but large language models are still struggling to tell the truth, the whole truth and nothing but the truth.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1?utm_campaign=post&utm_medium=web">The Illustrated DeepSeek-R1</a></div>
    <div class="card-image"><a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1?utm_campaign=post&utm_medium=web"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png" alt=""></a></div>
    <p class="card-excerpt">A recipe for reasoning LLMs</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html?unlocked_article_code=1.rU4.B5dI.rZuqL149Jok_&smid=url-share">How Chinese A.I. Start-Up DeepSeek Is Competing With OpenAI and Google</a></div>
    <div class="card-image"><a href="https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html?unlocked_article_code=1.rU4.B5dI.rZuqL149Jok_&smid=url-share"><img src="https://static01.nyt.com/images/2025/01/17/multimedia/CHINA-AI-vjfl/CHINA-AI-vjfl-largeHorizontalJumbo.jpg" alt=""></a></div>
    <p class="card-excerpt">The company built a cheaper, competitive chatbot with fewer high-end computer chips than U.S. behemoths like Google and OpenAI, showing the limits of chip export control.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Jan/23/llm-020/#atom-everything">LLM 0.20</a></div>
    <p class="card-excerpt">New release of my [LLM](https://llm.datasette.io/) CLI tool and Python library. A bunch of accumulated fixes and features since the start of December, most notably: - Support for OpenAI's [o1 model](https://platform.openai.com/docs/models#o1) …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Jan/20/deepseek-r1/#atom-everything">DeepSeek-R1 and exploring DeepSeek-R1-Distill-Llama-8B</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2025/Jan/20/deepseek-r1/#atom-everything"><img src="https://static.simonwillison.net/static/2025/r1-card.jpg" alt=""></a></div>
    <p class="card-excerpt">DeepSeek are the Chinese AI lab who dropped the best currently available open weights LLM on Christmas day, DeepSeek v3. That model was trained in part using their unreleased R1 …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.apolloresearch.ai/blog/an-opinionated-evals-reading-list?utm_source=chatgpt.com">An Opinionated Evals Reading List — Apollo Research</a></div>
    <div class="card-image"><a href="https://www.apolloresearch.ai/blog/an-opinionated-evals-reading-list?utm_source=chatgpt.com"><img src="http://static1.squarespace.com/static/6593e7097565990e65c886fd/65940f02f1fcb826ed2a7229/670e662d065b1f4ab82aab5e/1734295113640/Screenshot+2024-10-15+at+15.25.10.png?format=1500w" alt=""></a></div>
    <p class="card-excerpt">A long reading list of evals papers with recommendations and comments by the evals team.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://huyenchip.com/2025/01/07/agents.html">Agents</a></div>
    <div class="card-image"><a href="https://huyenchip.com/2025/01/07/agents.html"><img src="https://huyenchip.com/assets/pics/agents/2-agent-pattern.png" alt=""></a></div>
    <p class="card-excerpt">Intelligent agents are considered by many to be the ultimate goal of AI. The classic book by Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach (Prentice Hall, 1995), defines the field of AI research as “the study and design of rational agents.”</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web">The 2025 AI Engineering Reading List</a></div>
    <div class="card-image"><a href="https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242370c-229f-453d-924a-7a5aa4d20a4c_1090x502.png" alt=""></a></div>
    <p class="card-excerpt">We picked 50 paper/models/blogs across 10 fields in AI Eng: LLMs, Benchmarks, Prompting, RAG, Agents, CodeGen, Vision, Voice, Diffusion, Finetuning. If you're starting from scratch, start here.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/thenuancedperspective/p/100-must-read-generative-ai-papers?r=oc5d&utm_medium=ios">100 Must-Read Generative AI Papers from 2024</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/thenuancedperspective/p/100-must-read-generative-ai-papers?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcfe5315-38ae-475d-9b8a-05df56910378_1800x829.png" alt=""></a></div>
    <p class="card-excerpt">A comprehensive list of some of the most impactful generative papers from last year</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://machinelearningmastery.com/7-next-generation-prompt-engineering-techniques/">7 Next-Generation Prompt Engineering Techniques - MachineLearningMastery.com</a></div>
    <div class="card-image"><a href="https://machinelearningmastery.com/7-next-generation-prompt-engineering-techniques/"><img src="https://machinelearningmastery.com/wp-content/uploads/2025/01/mlm-7-next-gen-prompting-techniques.png" alt=""></a></div>
    <p class="card-excerpt">[caption align=</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2025/bpe-from-scratch.html">Implementing A Byte Pair Encoding (BPE) Tokenizer From Scratch</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2025/bpe-from-scratch.html"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/bpe-from-scratch/bpe-overview.jpg" alt=""></a></div>
    <p class="card-excerpt">This is a standalone notebook implementing the popular byte pair encoding (BPE) tokenization algorithm, which is used in models like GPT-2 to GPT-4, Llama 3,...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/thealgorithmicbridge/p/this-rumor-about-gpt-5-changes-everything?r=oc5d&utm_medium=ios">This Rumor About GPT-5 Changes Everything</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/thealgorithmicbridge/p/this-rumor-about-gpt-5-changes-everything?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F61d7c2f7-6d0d-4624-9498-e006d3b5bc96_1792x1024.webp" alt=""></a></div>
    <p class="card-excerpt">Let’s start the year on an exciting note</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2025/01/18/microsoft-presents-a-comprehensive-framework-for-securing-generative-ai-systems-using-lessons-from-red-teaming-100-generative-ai-products/">Microsoft Presents a Comprehensive Framework for Securing Generative AI Systems Using Lessons from Red Teaming 100 Generative AI Products</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2025/01/18/microsoft-presents-a-comprehensive-framework-for-securing-generative-ai-systems-using-lessons-from-red-teaming-100-generative-ai-products/"><img src="https://www.marktechpost.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-10.12.05%E2%80%AFAM.png" alt=""></a></div>
    <p class="card-excerpt">The rapid advancement and widespread adoption of generative AI systems across various domains have increased the critical importance of AI red teaming for evaluating technology safety and security. While AI red teaming aims to evaluate end-to-end systems by simulating real-world attacks, current methodologies face significant challenges in effectiveness and implementation. The complexity of modern AI systems, with their expanding capabilities across multiple modalities including vision and audio, has created an unprecedented array of potential vulnerabilities and attack vectors. Moreover, integrating agentic systems that grant AI models higher privileges and access to external tools has substantially increased the attack surface and</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2025/Jan/18/lessons-from-red-teaming/">Lessons From Red Teaming 100 Generative AI Products</a></div>
    <p class="card-excerpt">New paper from Microsoft describing their top eight lessons learned red teaming (deliberately seeking security vulnerabilities in) 100 different generative AI models and products over the past few years.  …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material">rasbt/LLMs-from-scratch: Implement a ChatGPT-like LLM in PyTorch from scratch, step by step</a></div>
    <div class="card-image"><a href="https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material"><img src="https://repository-images.githubusercontent.com/669879380/79da1d51-4ef9-4733-a61c-1d7851020d9a" alt=""></a></div>
    <p class="card-excerpt">Implement a ChatGPT-like LLM in PyTorch from scratch, step by step - rasbt/LLMs-from-scratch</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2024/Dec/31/llms-in-2024/">Things we learned out about LLMs in 2024</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2024/Dec/31/llms-in-2024/"><img src="https://static.simonwillison.net/static/2024/arena-dec-2024.jpg" alt=""></a></div>
    <p class="card-excerpt">A lot has happened in the world of Large Language Models over the course of 2024. Here’s a review of things we figured out about the field in the past …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/12/06/cpu-gpu-i-o-aware-llm-inference-reduces-latency-in-gpus-by-optimizing-cpu-gpu-interactions/">CPU-GPU I/O-Aware LLM Inference Reduces Latency in GPUs by Optimizing CPU-GPU Interactions</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/12/06/cpu-gpu-i-o-aware-llm-inference-reduces-latency-in-gpus-by-optimizing-cpu-gpu-interactions/"><img src="https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-06-at-10.42.41%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt">LLMs are driving major advances in research and development today. A significant shift has been observed in research objectives and methodologies toward an LLM-centric approach. However, they are associated with high expenses, making LLMs for large-scale utilization inaccessible to many. It is, therefore, a significant challenge to reduce the latency of operations, especially in dynamic applications that demand responsiveness. KV cache is used for autoregressive decoding in LLMs. It stores key-value pairs in multi-headed attention during the pre-filling phase of inference. During the decoding stage, new KV pairs get appended to the memory. KV cache stores the intermediate key and</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/simonw/p/gemini-20-flash-thinking-mode?r=oc5d&utm_medium=ios">Gemini 2.0 Flash "Thinking Mode"</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/simonw/p/gemini-20-flash-thinking-mode?r=oc5d&utm_medium=ios"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd37da74d-4508-4b1d-b1cd-5e61852b5522_936x906.png" alt=""></a></div>
    <p class="card-excerpt">Plus building Python tools with a one-shot prompt using uv run and Claude Projects</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/12/15/meta-ai-proposes-large-concept-models-lcms-a-semantic-leap-beyond-token-based-language-modeling/">Meta AI Proposes Large Concept Models (LCMs): A Semantic Leap Beyond Token-based Language Modeling</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/12/15/meta-ai-proposes-large-concept-models-lcms-a-semantic-leap-beyond-token-based-language-modeling/"><img src="https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-15-at-4.39.41%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt">Large Language Models (LLMs) have achieved remarkable advancements in natural language processing (NLP), enabling applications in text generation, summarization, and question-answering. However, their reliance on token-level processing—predicting one word at a time—presents challenges. This approach contrasts with human communication, which often operates at higher levels of abstraction, such as sentences or ideas. Token-level modeling also struggles with tasks requiring long-context understanding and may produce outputs with inconsistencies. Moreover, extending these models to multilingual and multimodal applications is computationally expensive and data-intensive. To address these issues, researchers at Meta AI have proposed a new approach: Large Concept Models (LCMs). Large Concept</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/12/20/slim-llama-an-energy-efficient-llm-asic-processor-supporting-3-billion-parameters-at-just-4-69mw/">Slim-Llama: An Energy-Efficient LLM ASIC Processor Supporting 3-Billion Parameters at Just 4.69mW</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/12/20/slim-llama-an-energy-efficient-llm-asic-processor-supporting-3-billion-parameters-at-just-4-69mw/"><img src="https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-20-at-4.36.50%E2%80%AFPM.png" alt=""></a></div>
    <p class="card-excerpt">Large Language Models (LLMs) have become a cornerstone of artificial intelligence, driving advancements in natural language processing and decision-making tasks. However, their extensive power demands, resulting from high computational overhead and frequent external memory access, significantly hinder their scalability and deployment, especially in energy-constrained environments such as edge devices. This escalates the cost of operation while also limiting accessibility to these LLMs, which therefore calls for energy-efficient approaches designed to handle billion-parameter models. Current approaches to reduce the computational and memory needs of LLMs are based either on general-purpose processors or on GPUs, with a combination of weight quantization and</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-science.html">OpenAI Unveils o3 System That Reasons Through Math, Science Problems</a></div>
    <div class="card-image"><a href="https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-science.html"><img src="https://static01.nyt.com/images/2024/12/20/multimedia/20openai-bplz/20openai-bplz-largeHorizontalJumbo.jpg" alt=""></a></div>
    <p class="card-excerpt">The artificial intelligence start-up said the new system, OpenAI o3, outperformed leading A.I. technologies on tests that rate skills in math, science, coding and logic.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anthropic.com/research/building-effective-agents">Building effective agents \ Anthropic</a></div>
    <div class="card-image"><a href="https://www.anthropic.com/research/building-effective-agents"><img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75" alt=""></a></div>
    <p class="card-excerpt">A post for developers with advice and workflows for building effective AI agents</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf">Blt patches scale better than tokens</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/">LangChain vs OpenAI API: When Simplicity Meets Scalability | Aditya Bhattacharya | Blogs Website</a></div>
    <div class="card-image"><a href="https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/"><img src="https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-api-when-simplicity-meets-scalability.png" alt=""></a></div>
    <p class="card-excerpt">This blog explores a detailed comparison between the OpenAI API and LangChain, highlighting key differences in performance and developer experience and the low level code for why these differences exist.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/transformers-key-value-kv-caching-explained-4d71de62d22d?source=rss----7f60cf5620c9---4">Transformers Key-Value (KV) Caching Explained</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/transformers-key-value-kv-caching-explained-4d71de62d22d?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*ub2DQhz0aHT0-Tyaw3hGkQ.png" alt=""></a></div>
    <p class="card-excerpt">Speed up your LLM inference</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://aiworld.eu/embed/model/model/treemap">Treemap</a></div>
    <div class="card-image"><a href="https://aiworld.eu/embed/model/model/treemap"><img src="https://aiworld.eu/open-graph-1.png" alt=""></a></div>
    <p class="card-excerpt">Navigate Tomorrow's Intelligence Today</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.wsj.com/tech/ai/ai-safety-testing-red-team-anthropic-1b31b21b?st=o5kvwf&reflink=desktopwebshare_permalink">The AI Researchers Pushing Computers to Launch Nightmare Scenarios</a></div>
    <div class="card-image"><a href="https://www.wsj.com/tech/ai/ai-safety-testing-red-team-anthropic-1b31b21b?st=o5kvwf&reflink=desktopwebshare_permalink"><img src="https://images.wsj.net/im-81826050/social" alt=""></a></div>
    <p class="card-excerpt">It’s largely up to companies to test whether their AI is capable of superhuman harm. At Anthropic, the Frontier Red Team assesses the risk of catastrophe.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/12/08/what-are-hallucinations-in-llms-and-6-effective-strategies-to-prevent-them/">What are Hallucinations in LLMs and 6 Effective Strategies to Prevent Them</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/12/08/what-are-hallucinations-in-llms-and-6-effective-strategies-to-prevent-them/"><img src="https://www.marktechpost.com/wp-content/uploads/2024/12/artificial-intelligence-7328587_1280.jpg" alt=""></a></div>
    <p class="card-excerpt">In large language models (LLMs), “hallucination” refers to instances where models generate semantically or syntactically plausible outputs but are factually incorrect or nonsensical. For example, a hallucination occurs when a model provides erroneous information, such as stating that Addison's disease causes “bright yellow skin” when, in fact, it causes fatigue and low blood pressure. This phenomenon is a significant concern in AI, as it can lead to the spread of false or misleading information. The issue of AI hallucinations has been explored in various research studies. A survey in “ACM Computing Surveys” describes hallucinations as “unreal perceptions that feel real.”</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://countless.dev/">Countless.dev | AI Model Comparison</a></div>
    <div class="card-image"><a href="https://countless.dev/"><img src="https://countless.dev/preview.png" alt=""></a></div>
    <p class="card-excerpt">Compare AI models easily! All providers in one place.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kapa.ai/blog/ai-hallucination">AI Hallucinations: Why Large Language Models Make Things Up (And How to Fix It) - kapa.ai - Instant AI answers to technical questions</a></div>
    <div class="card-image"><a href="https://www.kapa.ai/blog/ai-hallucination"><img src="https://framerusercontent.com/images/f4igsQq4o21p1I7eSKhe53nWNIQ.png" alt=""></a></div>
    <p class="card-excerpt">Kapa.ai turns your knowledge base into a reliable and production-ready LLM-powered AI assistant that answers technical questions instantly. Trusted by 100+ startups and enterprises incl. OpenAI, Docker, Mapbox, Mixpanel and NextJS.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/build-a-general-purpose-ai-agent-c40be49e7400?source=rss----7f60cf5620c9---4">How to Build a General-Purpose LLM Agent</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/build-a-general-purpose-ai-agent-c40be49e7400?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*KKKdVTkdU_39D7lrlw4Ugw.png" alt=""></a></div>
    <p class="card-excerpt">A Step-by-Step Guide</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/11/28/four-cutting-edge-methods-for-evaluating-ai-agents-and-enhancing-llm-performance/">Four Cutting-Edge Methods for Evaluating AI Agents and Enhancing LLM Performance</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/11/28/four-cutting-edge-methods-for-evaluating-ai-agents-and-enhancing-llm-performance/"><img src="https://www.marktechpost.com/wp-content/uploads/2024/11/ai-6767497_1280.jpg" alt=""></a></div>
    <p class="card-excerpt">The advent of LLMs has propelled advancements in AI for decades. One such advanced application of LLMs is Agents, which replicate human reasoning remarkably. An agent is a system that can perform complicated tasks by following a reasoning process similar to humans: think (solution to the problem), collect (context from past information), analyze(the situations and data), and adapt (based on the style and feedback). Agents encourage the system through dynamic and intelligent activities, including planning, data analysis, data retrieval, and utilizing the model's past experiences.  A typical agent has four components: Brain: An LLM with advanced processing capabilities, such as</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://steelph0enix.github.io/posts/llama-cpp-guide/">llama.cpp guide - Running LLMs locally, on any hardware, from scratch</a></div>
    <div class="card-image"><a href="https://steelph0enix.github.io/posts/llama-cpp-guide/"><img src="https://steelph0enix.github.io/og-image.png" alt=""></a></div>
    <p class="card-excerpt">Psst, kid, want some cheap and small LLMs?</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/eugeneyan/llm-paper-notes">eugeneyan/llm-paper-notes: Notes from the Latent Space paper club. Follow along or start your own!</a></div>
    <div class="card-image"><a href="https://github.com/eugeneyan/llm-paper-notes"><img src="https://opengraph.githubassets.com/9c85f10ad2727a21d7a3aa7d87a46809444643e5d716c492825f63c34d60b7bd/eugeneyan/llm-paper-notes" alt=""></a></div>
    <p class="card-excerpt">Notes from the Latent Space paper club. Follow along or start your own! - eugeneyan/llm-paper-notes</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/understanding-multimodal-llms">Understanding Multimodal LLMs</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/understanding-multimodal-llms"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc534f387-f776-41eb-9c65-f0032b91daee_1988x1430.png" alt=""></a></div>
    <p class="card-excerpt">An introduction to the main techniques and latest models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/dynomight/p/chess?utm_campaign=post&utm_medium=web">Something weird is happening with LLMs and chess</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/dynomight/p/chess?utm_campaign=post&utm_medium=web"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12c6f36a-6e5b-41fa-91d9-563757f83964_1440x900.jpeg" alt=""></a></div>
    <p class="card-excerpt">Are they good or bad?</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.zeta-alpha.com/post/analyzing-the-homerun-year-for-llms-the-top-100-most-cited-ai-papers-in-2023-with-all-medals-for-o">Analyzing the homerun year for LLMs: the top-100 most cited AI papers in 2023, with all medals for open models.</a></div>
    <p class="card-excerpt">9 October 2024, Mathias Parisot, Jakub Zavrel.Even in the red hot global race for AI dominance, you publish and you perish, unless your peers pick up your work, build further on it, and you manage to drive real progress in the field. And of course, we are all very curious who is currently having that kind of impact. Are the billions of dollars spent on AI R&D paying off in the long run? So here is, in continuation of our popular publication impact analysis of last year, Zeta Alpha's ranking of t</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.datasciencecentral.com/llm-chunking-indexing-scoring-and-agents-in-a-nutshell/">LLM Chunking, Indexing, Scoring and Agents, in a Nutshell - DataScienceCentral.com</a></div>
    <div class="card-image"><a href="https://www.datasciencecentral.com/llm-chunking-indexing-scoring-and-agents-in-a-nutshell/"><img src="https://www.datasciencecentral.com/wp-content/uploads/2024/10/xllm-diagram6.png" alt=""></a></div>
    <p class="card-excerpt">LLM Chunking, Indexing, Scoring and Agents, in a Nutshell. The new PageRank of RAG/LLM. With details on building relevancy scores.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anthropic.com/research/developing-computer-use?ref=thediff.co">Developing a computer use model</a></div>
    <div class="card-image"><a href="https://www.anthropic.com/research/developing-computer-use?ref=thediff.co"><img src="https://cdn.sanity.io/images/4zrzovbb/website/393cf77dd5c15761c47f2db9f80e30b4f6309708-2880x1620.png" alt=""></a></div>
    <p class="card-excerpt">A discussion of how Anthropic's researchers developed Claude's new computer use skill, along with some relevant safety considerations</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/nvidia-just-dropped-a-new-ai-model-that-crushes-openais-gpt-4-no-big-launch-just-big-results/">Nvidia just dropped a new AI model that crushes OpenAI’s GPT-4—no big launch, just big results</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/nvidia-just-dropped-a-new-ai-model-that-crushes-openais-gpt-4-no-big-launch-just-big-results/"><img src="https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_a_brilliant_sunrise_but_instead_of_a_natural_landscap_2765f9f2-d796-4207-977a-b27e6281faf3.webp?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Nvidia quietly launched a groundbreaking AI model that surpasses OpenAI’s GPT-4 and Anthropic’s Claude 3.5, signaling a major shift in the competitive landscape of artificial intelligence.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://techcrunch.com/2024/10/19/claude-everything-you-need-to-know-about-anthropics-ai/">Claude: Everything you need to know about Anthropic's AI | TechCrunch</a></div>
    <div class="card-image"><a href="https://techcrunch.com/2024/10/19/claude-everything-you-need-to-know-about-anthropics-ai/"><img src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" alt=""></a></div>
    <p class="card-excerpt">Anthropic, the AI vendor second in size only to OpenAI, has a powerful family of generative AI models called Claude. These models can perform a range of</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/10/02/lightllm-a-lightweight-scalable-and-high-speed-python-framework-for-llm-inference-and-serving">LightLLM: A Lightweight Scalable and High-Speed Python Framework for LLM Inference and Serving</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/10/02/lightllm-a-lightweight-scalable-and-high-speed-python-framework-for-llm-inference-and-serving"><img src="https://www.marktechpost.com/wp-content/uploads/2024/10/Screenshot-2024-10-01-at-7.55.06-PM.png" alt=""></a></div>
    <p class="card-excerpt">Large language models (LLMs) have advanced significantly in recent years. However, its real-world applications are restricted due to substantial processing power and memory requirements. The need to make LLMs more accessible on smaller and resource-limited devices drives the development of more efficient frameworks for model inference and deployment. Existing methods for running LLMs include hardware acceleration techniques and optimizations like quantization and pruning. However, these methods often fail to provide a balance between model size, performance, and usability in constrained environments.  Researchers developed an efficient, scalable, and lightweight framework for LLM inference, LightLLM, to address the challenge of efficiently deploying</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4">Nvidia just dropped a bombshell: Its new AI model is open massive and ready to rival GPT-4</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4"><img src="https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_a_human_brain_rendered_in_a_semi-transp_907d536c-6a14-4c28-8c81-3d144ea0de3e.webp?w=986?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Nvidia has released NVLM 1.0, a powerful open-source AI model that rivals GPT-4 and Google’s systems, marking a major breakthrough in multimodal language models for vision and text tasks.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/10/01/ten-effective-strategies-to-lower-large-language-model-llm-inference-costs">Ten Effective Strategies to Lower Large Language Model (LLM) Inference Costs</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/10/01/ten-effective-strategies-to-lower-large-language-model-llm-inference-costs"><img src="https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-10.05.05-PM-1024x798.png" alt=""></a></div>
    <p class="card-excerpt">Large Language Models (LLMs) have become a cornerstone in artificial intelligence, powering everything from chatbots and virtual assistants to advanced text generation and translation systems. Despite their prowess, one of the most pressing challenges associated with these models is the high cost of inference. This cost includes computational resources, time, energy consumption, and hardware wear. Optimizing these costs is paramount for businesses and researchers aiming to scale their AI operations without breaking the bank. Here are ten proven strategies to reduce LLM inference costs while maintaining performance and accuracy: Quantization Quantization is a technique that decreases the precision of model</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/5-llm-tools-i-cant-live-without">5 LLM Tools I Can’t Live Without</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/5-llm-tools-i-cant-live-without"><img src="https://www.kdnuggets.com/wp-content/uploads/kdn-5-llm-tools-cant-live-without.png" alt=""></a></div>
    <p class="card-excerpt">In this article, I share the five essential LLM tools that I currently find indispensable, and which have the potential to help revolutionize the way you work.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/09/13/flashsigmoid-a-hardware-aware-and-memory-efficient-implementation-of-sigmoid-attention-yielding-a-17-inference-kernel-speed-up-over-flashattention-2-on-h100-gpus">FlashSigmoid: A Hardware-Aware and Memory-Efficient Implementation of Sigmoid Attention Yielding a 1</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/09/13/flashsigmoid-a-hardware-aware-and-memory-efficient-implementation-of-sigmoid-attention-yielding-a-17-inference-kernel-speed-up-over-flashattention-2-on-h100-gpus"><img src="https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-13-at-5.26.21-PM.png" alt=""></a></div>
    <p class="card-excerpt">Large Language Models (LLMs) have gained significant prominence in modern machine learning, largely due to the attention mechanism. This mechanism employs a sequence-to-sequence mapping to construct context-aware token representations. Traditionally, attention relies on the softmax function (SoftmaxAttn) to generate token representations as data-dependent convex combinations of values. However, despite its widespread adoption and effectiveness, SoftmaxAttn faces several challenges. One key issue is the tendency of the softmax function to concentrate attention on a limited number of features, potentially overlooking other informative aspects of the input data. Also, the application of SoftmaxAttn necessitates a row-wise reduction along the input sequence length,</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/09/14/top-9-different-types-of-retrieval-augmented-generation-rags">Top 9 Different Types of Retrieval-Augmented Generation (RAGs)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/09/14/top-9-different-types-of-retrieval-augmented-generation-rags"><img src="https://www.marktechpost.com/wp-content/uploads/2024/09/P0z9zxKgRaSehlAFs0QzfQ.jpg" alt=""></a></div>
    <p class="card-excerpt">Retrieval-Augmented Generation (RAG) is a machine learning framework that combines the advantages of both retrieval-based and generation-based models. The RAG framework is highly regarded for its ability to handle large amounts of information and produce coherent, contextually accurate responses. It leverages external data sources by retrieving relevant documents or facts and then generating an answer or output based on the retrieved information and the user query. This blend of retrieval and generation leads to better-informed outputs that are more accurate and comprehensive than models that rely solely on generation. The evolution of RAG has led to various types and approaches,</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/09/14/graphiti-a-python-library-for-building-temporal-knowledge-graphs-using-llms">Graphiti: A Python Library for Building Temporal Knowledge Graphs Using LLMs</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/09/14/graphiti-a-python-library-for-building-temporal-knowledge-graphs-using-llms"><img src="https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-13-at-10.36.15-PM.png" alt=""></a></div>
    <p class="card-excerpt">The challenge of managing and recalling facts from complex, evolving conversations is a key problem for many AI-driven applications. As information grows and changes over time, maintaining accurate context becomes increasingly difficult. Current systems often struggle to handle the evolving nature of relationships and facts, leading to incomplete or irrelevant results when retrieving information. This can affect the effectiveness of AI agents, especially when dealing with user memories and context in real-time applications. Some existing solutions have attempted to address this problem. One common approach is using a Retrieval-Augmented Generation (RAG) pipeline, which involves storing extracted facts and using techniques</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://docs.llamaindex.ai/en/stable">LlamaIndex : LlamaIndex</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/09/03/why-gpu-utilization-falls-short-understanding-streaming-multiprocessor-sm-efficiency-for-better-llm-performance">Why GPU Utilization Falls Short: Understanding Streaming Multiprocessor (SM) Efficiency for Better L</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/09/03/why-gpu-utilization-falls-short-understanding-streaming-multiprocessor-sm-efficiency-for-better-llm-performance"><img src="https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-03-at-6.18.46-PM.png" alt=""></a></div>
    <p class="card-excerpt">Large Language Models (LLMs) have gained significant prominence in recent years, driving the need for efficient GPU utilization in machine learning tasks. However, researchers face a critical challenge in accurately assessing GPU performance. The commonly used metric, GPU Utilization, accessed through nvidia-smi or integrated observability tools, has proven to be an unreliable indicator of actual computational efficiency. Surprisingly, 100% GPU utilization can be achieved merely by reading and writing to memory without performing any computations. This revelation has sparked a reevaluation of performance metrics and methodologies in the field of machine learning, prompting researchers to seek more accurate ways to</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://machinelearningmastery.com/building-a-simple-rag-application-using-llamaindex">Building a Simple RAG Application Using LlamaIndex - MachineLearningMastery.com</a></div>
    <div class="card-image"><a href="https://machinelearningmastery.com/building-a-simple-rag-application-using-llamaindex"><img src="https://machinelearningmastery.com/wp-content/uploads/2024/08/mlm-awan-rag-applications-llamaindex.png" alt=""></a></div>
    <p class="card-excerpt">[caption align=</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/06/20/firecrawl-a-powerful-web-scraping-tool-for-turning-websites-into-large-language-model-llm-ready-markdown-or-structured-data">Firecrawl: A Powerful Web Scraping Tool for Turning Websites into Large Lan</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/06/20/firecrawl-a-powerful-web-scraping-tool-for-turning-websites-into-large-language-model-llm-ready-markdown-or-structured-data"><img src="https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-20-at-9.54.36-AM.png" alt=""></a></div>
    <p class="card-excerpt">In the rapidly advancing field of Artificial Intelligence (AI), effective use of web data can lead to unique applications and insights. A recent tweet has brought attention to Firecrawl, a potent tool in this field created by the Mendable AI team. Firecrawl is a state-of-the-art web scraping program made to tackle the complex problems involved in getting data off the internet. Web scraping is useful, but it frequently requires overcoming various challenges like proxies, caching, rate limitations, and material generated with JavaScript. Firecrawl is a vital tool for data scientists because it addresses these issues head-on. Even without a sitemap,</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i">What We Learned from a Year of Building with LLMs (Part I)</a></div>
    <div class="card-image"><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i"><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/na-synapse-2a-1400x950-1.jpg" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb">dpo-from-scratch.ipynb</a></div>
    <div class="card-image"><a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb"><img src="https://repository-images.githubusercontent.com/669879380/79da1d51-4ef9-4733-a61c-1d7851020d9a" alt=""></a></div>
    <p class="card-excerpt">Implementing a ChatGPT-like LLM in PyTorch from scratch, step by step - rasbt/LLMs-from-scratch</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/towards-monosemanticity-a-step-towards-understanding-large-language-models-e7b88380d7b3?source=rss----7f60cf5620c9---4">Towards Monosemanticity: A step towards understanding large language models</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/towards-monosemanticity-a-step-towards-understanding-large-language-models-e7b88380d7b3?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:724/0*fxI8N7ewAnL8r14A" alt=""></a></div>
    <p class="card-excerpt">Understanding the mechanistic interpretability research problem and reverse-engineering these large language models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters">Meta unleashes its most powerful AI model, Llama 3.1, with 405B parameters</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters"><img src="https://venturebeat.com/wp-content/uploads/2024/04/nuneybits_Vector_art_of_a_llama_in_a_blazing_fast_racecar_7f670485-6ad6-482b-ae36-c52aa0cf61a6-transformed-1.webp?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Llama 3.1 is the latest version of Meta's large language models, with a new model weight, 405 billion parameters, the biggest model it's trained.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://developer.nvidia.com/blog/customize-generative-ai-models-for-enterprise-applications-with-llama-3-1">Customize Generative AI Models for Enterprise Applications with Llama 3.1</a></div>
    <div class="card-image"><a href="https://developer.nvidia.com/blog/customize-generative-ai-models-for-enterprise-applications-with-llama-3-1"><img src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/04/dev-llama3-blog-1920x1080-1.png" alt=""></a></div>
    <p class="card-excerpt">The newly unveiled Llama 3.1 collection of 8B, 70B, and 405B large language models (LLMs) is narrowing the gap between proprietary and open-source models. Their open nature is attracting more…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/07/23/llama-3-1-released-metas-new-open-source-ai-model-that-you-can-fine-tune-distill-and-deploy-anywhere-and-available-in-8b-70b-and-405b">Llama 3.1 Released: Meta’s New Open-Source AI Model that You can Fine-Tune,</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/07/23/llama-3-1-released-metas-new-open-source-ai-model-that-you-can-fine-tune-distill-and-deploy-anywhere-and-available-in-8b-70b-and-405b"><img src="https://www.marktechpost.com/wp-content/uploads/2024/07/Screenshot-2024-07-23-at-5.29.09-PM.png" alt=""></a></div>
    <p class="card-excerpt">Meta announced the release of Llama 3.1, the most capable model in the LLama Series. This latest iteration of the Llama series, particularly the 405B model, represents a substantial advancement in open-source AI capabilities, positioning Meta at the forefront of AI innovation.  Meta has long advocated for open-source AI, a stance underscored by Mark Zuckerberg’s assertion that open-source benefits developers, Meta, and society. Llama 3.1 embodies this philosophy by offering state-of-the-art capabilities in an openly accessible model. The release aims to democratize AI, making cutting-edge technology available to various users and applications. The Llama 3.1 405B model stands out for</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2024/07/24/meta-llama-3-1-405b-comparison-features">Meta Llama 3.1 405b is outperforming private models with open access</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2024/07/24/meta-llama-3-1-405b-comparison-features"><img src="https://dataconomy.com/wp-content/uploads/2024/07/meta-llama-3.1-405b_3.jpg" alt=""></a></div>
    <p class="card-excerpt">Meta llama 3.1 405b kicks off a fresh chapter for open-source language models. This breakthrough brings unmatched skills to AI</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/understanding-positional-embeddings-in-transformers-from-absolute-to-rotary-31c082e16b26">Understanding Positional Embeddings in Transformers: From Absolute to Rotar</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/understanding-positional-embeddings-in-transformers-from-absolute-to-rotary-31c082e16b26"><img src="https://miro.medium.com/v2/resize:fit:1200/1*EWz8ImltNHpDjMB8bOq_tQ.png" alt=""></a></div>
    <p class="card-excerpt">A deep dive into absolute, relative, and rotary positional embeddings with code examples</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anthropic.com/news/claude-3-5-sonnet">Claude 3.5 Sonnet</a></div>
    <div class="card-image"><a href="https://www.anthropic.com/news/claude-3-5-sonnet"><img src="https://cdn.sanity.io/images/4zrzovbb/website/8a4eb6c412e5e7ffa38f07233344f4b7e6644994-2400x1200.png" alt=""></a></div>
    <p class="card-excerpt">Introducing Claude 3.5 Sonnet—our most intelligent model yet. Sonnet now outperforms competitor models and Claude 3 Opus on key evaluations, at twice the speed.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.amazon.science/blog/do-large-language-models-understand-the-world">Do large language models understand the world?</a></div>
    <div class="card-image"><a href="https://www.amazon.science/blog/do-large-language-models-understand-the-world"><img src="https://assets.amazon.science/dims4/default/a919bc2/2147483647/strip/true/crop/1920x1008+0+36/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F17%2F0b%2Ff4768ae249509d4697b1c705457a%2Fmultimodal-projection.png" alt=""></a></div>
    <p class="card-excerpt">In addition to its practical implications, recent work on “meaning representations” could shed light on some old philosophical questions.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anyscale.com/blog/building-an-llm-router-for-high-quality-and-cost-effective-responses">Building an LLM Router for High-Quality and Cost-Effective Responses</a></div>
    <div class="card-image"><a href="https://www.anyscale.com/blog/building-an-llm-router-for-high-quality-and-cost-effective-responses"><img src="https://images.ctfassets.net/xjan103pcp94/jYOVHq6FxnQ2vocwXPAbn/02aa8be5b68f2a7585ae375d5b38b015/Anyscale_-_LLM_Router.png" alt=""></a></div>
    <p class="card-excerpt">Anyscale is the leading AI application platform. With Anyscale, developers can build, run and scale AI applications instantly.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://imbue.com/research/70b-infrastructure">From bare metal to a 70B model: infrastructure set-up and scripts - imbue</a></div>
    <div class="card-image"><a href="https://imbue.com/research/70b-infrastructure"><img src="https://generallyintelligent.com/preview/70b-infra-social.png" alt=""></a></div>
    <p class="card-excerpt">We would like to thank Voltage Park, Dell, H5, and NVIDIA for their invaluable partnership and help with setting up our cluster. A special…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://nvda.ws/3XJa8l9#new_tab">StarCoder2-15B: A Powerful LLM for Code Generation, Summarization, and Docu</a></div>
    <div class="card-image"><a href="https://nvda.ws/3XJa8l9#new_tab"><img src="https://build.nvidia.com/opengraph-image.jpg?6ec102a0470b935b" alt=""></a></div>
    <p class="card-excerpt">Experience the leading models to build enterprise generative AI apps now.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/how-gradient-created-an-open-llm-with-a-million-token-context-window">How Gradient created an open LLM with a million-token context window</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/how-gradient-created-an-open-llm-with-a-million-token-context-window"><img src="https://venturebeat.com/wp-content/uploads/2024/06/inifinite-tokens.jpg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">AI startup Gradient and cloud platform Crusoe teamed up to extend the context window of Meta's Llama 3 models to 1 million tokens.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/06/21/some-commonly-used-advanced-prompt-engineering-techniques-explained-using-simple-human-analogies">Some Commonly Used Advanced Prompt Engineering Techniques Explained Using S</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/06/21/some-commonly-used-advanced-prompt-engineering-techniques-explained-using-simple-human-analogies"><img src="https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-21-at-9.14.00-PM.png" alt=""></a></div>
    <p class="card-excerpt">In the developing field of Artificial Intelligence (AI), the ability to think quickly has become increasingly significant. The necessity of communicating with AI models efficiently becomes critical as these models get more complex. In this article we will explain a number of sophisticated prompt engineering strategies, simplifying these difficult ideas through straightforward human metaphors. The techniques and their examples have been discussed to see how they resemble human approaches to problem-solving. Chaining Methods Analogy: Solving a problem step-by-step. Chaining techniques are similar to solving an issue one step at a time. Chaining techniques include directing the AI via a systematic</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/06/19/key-metrics-for-evaluating-large-language-models-llms">Key Metrics for Evaluating Large Language Models (LLMs)</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/06/19/key-metrics-for-evaluating-large-language-models-llms"><img src="https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-7.20.10-PM-1024x906.png" alt=""></a></div>
    <p class="card-excerpt">Evaluating Large Language Models (LLMs) is a challenging problem in language modeling, as real-world problems are complex and variable. Conventional benchmarks frequently fail to fully represent LLMs' all-encompassing performance. A recent LinkedIn post has emphasized a number of important measures that are essential to comprehend how well new models function, which are as follows. MixEval Achieving a balance between thorough user inquiries and effective grading systems is necessary for evaluating LLMs. Conventional standards based on ground truth and LLM-as-judge benchmarks encounter difficulties such as biases in grading and possible contamination over time.  MixEval solves these problems by combining real-world user</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://m.youtube.com/watch?feature=youtu.be&v=l8pRSuU81PU">Let's reproduce GPT-2 (124M)</a></div>
    <div class="card-image"><a href="https://m.youtube.com/watch?feature=youtu.be&v=l8pRSuU81PU"><img src="https://i.ytimg.com/vi/l8pRSuU81PU/maxresdefault.jpg" alt=""></a></div>
    <p class="card-excerpt">We reproduce the GPT-2 (124M) from scratch. This video covers the whole process: First we build the GPT-2 network, then we optimize its training to be really fast, then we set up the training run following the GPT-2 and GPT-3 paper and their hyperparameters, then we hit run, and come back the next morning to see our results, and enjoy some amusing model generations. Keep in mind that in some places this video builds on the knowledge from earlier videos in the Zero to Hero Playlist (see my channel). You could also see this video as building my nanoGPT repo, which by the end is about 90% similar.

Links:
- build-nanogpt GitHub repo, with all the changes in this video as individual commits: https://github.com/karpathy/build-nanogpt
- nanoGPT repo: https://github.com/karpathy/nanoGPT
- llm.c repo: https://github.com/karpathy/llm.c
- my website: https://karpathy.ai
- my twitter: https://twitter.com/karpathy
- our Discord channel: https://discord.gg/3zy8kqD9Cp

Supplementary links:
- Attention is All You Need paper: https://arxiv.org/abs/1706.03762
- OpenAI GPT-3 paper: https://arxiv.org/abs/2005.14165 - OpenAI GPT-2 paper: https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf- The GPU I'm training the model on is from Lambda GPU Cloud, I think the best and easiest way to spin up an on-demand GPU instance in the cloud that you can ssh to: https://lambdalabs.com 

Chapters:
00:00:00 intro: Let’s reproduce GPT-2 (124M)
00:03:39 exploring the GPT-2 (124M) OpenAI checkpoint
00:13:47 SECTION 1: implementing the GPT-2 nn.Module
00:28:08 loading the huggingface/GPT-2 parameters
00:31:00 implementing the forward pass to get logits
00:33:31 sampling init, prefix tokens, tokenization
00:37:02 sampling loop
00:41:47 sample, auto-detect the device
00:45:50 let’s train: data batches (B,T) → logits (B,T,C)
00:52:53 cross entropy loss
00:56:42 optimization loop: overfit a single batch
01:02:00 data loader lite
01:06:14 parameter sharing wte and lm_head
01:13:47 model initialization: std 0.02, residual init
01:22:18 SECTION 2: Let’s make it fast. GPUs, mixed precision, 1000ms
01:28:14 Tensor Cores, timing the code, TF32 precision, 333ms
01:39:38 float16, gradient scalers, bfloat16, 300ms
01:48:15 torch.compile, Python overhead, kernel fusion, 130ms
02:00:18 flash attention, 96ms
02:06:54 nice/ugly numbers. vocab size 50257 → 50304, 93ms
02:14:55 SECTION 3: hyperpamaters, AdamW, gradient clipping
02:21:06 learning rate scheduler: warmup + cosine decay
02:26:21 batch size schedule, weight decay, FusedAdamW, 90ms
02:34:09 gradient accumulation
02:46:52 distributed data parallel (DDP)
03:10:21 datasets used in GPT-2, GPT-3, FineWeb (EDU)
03:23:10 validation data split, validation loss, sampling revive
03:28:23 evaluation: HellaSwag, starting the run
03:43:05 SECTION 4: results in the morning! GPT-2, GPT-3 repro
03:56:21 shoutout to llm.c, equivalent but faster code in raw C/CUDA
03:59:39 summary, phew, build-nanogpt github repo

Corrections:
I will post all errata and followups to the build-nanogpt GitHub repo (link above)

SuperThanks:
I experimentally enabled them on my channel yesterday. Totally optional and only use if rich. All revenue goes to to supporting my work in AI + Education.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thoughtbot.com/blog/how-to-use-open-source-LLM-model-locally">How to use an open source LLM model locally and remotely</a></div>
    <div class="card-image"><a href="https://thoughtbot.com/blog/how-to-use-open-source-LLM-model-locally"><img src="https://images.prismic.io/thoughtbot-website/Zn0Q2JbWFbowe7qY_default-article-background.png?auto=format%2Ccompress&mark-x=356&mark-y=100&mark64=aHR0cHM6Ly9hc3NldHMuaW1naXgubmV0L350ZXh0Lz90eHQtbGVhZD0wJnR4dC10cmFjaz0wJnR4dDY0PVNHOTNJSFJ2SUhWelpTQmhiaUJ2Y0dWdUlITnZkWEpqWlNCTVRFMGdiVzlrWld3Z2JHOWpZV3hzZVNCaGJtUWdjbVZ0YjNSbGJIayUzRCZ0eHRjbHI9ZjVmNWY1JnR4dGZvbnQ9SUJNUGxleFNhbnNKUC1TZW1pQm9sZCZ0eHRwYWQ9MCZ0eHRzaXplPTY0Jnc9ODAw&txt-align=center%2Cmiddle&txt-color=f5f5f5&txt-fit=max&txt-font=IBMPlexSansJP-SemiBold&txt-size=24&txt-x=391&txt-y=526&txt=Jose+Blanco" alt=""></a></div>
    <p class="card-excerpt">Run an open source language model in your local machine and remotely.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2024/06/12/midjourney-model-personalization-guide">“The” Midjourney model personalization guide</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2024/06/12/midjourney-model-personalization-guide"><img src="https://dataconomy.com/wp-content/uploads/2024/06/How-to-use-Midjourney-model-personalization_09.jpg" alt=""></a></div>
    <p class="card-excerpt">Midjourney model personalization is now live, offering you a more tailored image generation experience by teaching the AI your preferences.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.lennysnewsletter.com/p/how-to-use-perplexity-in-your-pm">How to use Perplexity in your PM work</a></div>
    <div class="card-image"><a href="https://www.lennysnewsletter.com/p/how-to-use-perplexity-in-your-pm"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1fde139e-dc49-4a91-ae41-7e757873532b_1920x1440.png" alt=""></a></div>
    <p class="card-excerpt">27 examples (with actual prompts) of how product managers are using Perplexity today</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2406.01506">[2406.01506] The Geometry of Categorical and Hierarchical Concepts in Large</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2406.01506"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">The linear representation hypothesis is the informal idea that semantic concepts are encoded as linear directions in the representation spaces of large language models (LLMs). Previous work has...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii">What We Learned from a Year of Building with LLMs (Part II)</a></div>
    <div class="card-image"><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii"><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/na-synapse-1a-1400x950-1.jpg" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/06/07/sharpening-llms-the-sharpest-tools-and-essential-techniques-for-precision-and-clarity">Sharpening LLMs: The Sharpest Tools and Essential Techniques for Precision</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/06/07/sharpening-llms-the-sharpest-tools-and-essential-techniques-for-precision-and-clarity"><img src="https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-07-at-11.04.45-PM-1024x825.png" alt=""></a></div>
    <p class="card-excerpt">The ability to discern relevant and essential information from noise is paramount in AI, particularly within large language models (LLMs). With the surge of information and the complexity of tasks, there's a need for efficient mechanisms to enhance the performance and reliability of these models. Let’s explore the essential tools & techniques for refining LLMs and delivering precise, actionable insights. The focus will be on Retrieval-Augmented Generation (RAG), agentic functions, Chain of Thought (CoT) prompting, few-shot learning, prompt engineering, and prompt optimization. Retrieval-Augmented Generation (RAG): Providing Relevant Context RAG combines the power of retrieval mechanisms with generative models, ensuring that</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/06/08/list-of-activities-and-their-corresponding-suitable-llms-in-the-artificial-intelligence-ai-world-right-now-a-comprehensive-guide">List of Activities and Their Corresponding Suitable LLMs in the Artificial</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/06/08/list-of-activities-and-their-corresponding-suitable-llms-in-the-artificial-intelligence-ai-world-right-now-a-comprehensive-guide"><img src="https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-07-at-11.35.01-PM-1024x1005.png" alt=""></a></div>
    <p class="card-excerpt">Choosing large language models (LLMs) tailored for specific tasks is crucial for maximizing efficiency and accuracy. With natural language processing (NLP) advancements, different models have emerged, each excelling in unique domains. Here is a comprehensive guide to the most suitable LLMs for various activities in the AI world. Hard Document Understanding: Claude Opus Claude Opus excels at tasks requiring deep understanding and interpretation of complex documents. This model excels in parsing dense legal texts, scientific papers, and intricate technical manuals. Claude Opus is designed to handle extensive context windows, ensuring it captures nuanced details and complicated relationships within the text.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sloanreview.mit.edu/article/three-things-to-know-about-prompting-llms">Three Things to Know About Prompting LLMs</a></div>
    <div class="card-image"><a href="https://sloanreview.mit.edu/article/three-things-to-know-about-prompting-llms"><img src="https://sloanreview.mit.edu/wp-content/uploads/2024/06/2024SUM_Radar_3Things-2400x1260-1-1200x630.jpg" alt=""></a></div>
    <p class="card-excerpt">Apply these techniques when crafting prompts for large language models to elicit more relevant responses.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/perplexity-goes-beyond-ai-search-launches-publishing-platform-pages">Perplexity goes beyond AI search, launches publishing platform ‘Pages’</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/perplexity-goes-beyond-ai-search-launches-publishing-platform-pages"><img src="https://venturebeat.com/wp-content/uploads/2024/05/a-robot-with-perplexity-written-on-its-torso-writi-2zEVq32AQdS313p_LPegMg-P4QVESWwSYKx383_3HyEAA.jpeg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">In most cases, Perplexity produced the desired Pages, but what we found missing was the option to edit the content manually.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.wsj.com/tech/personal-tech/ai-chatbots-chatgpt-gemini-copilot-perplexity-claude-f9e40d26?reflink=desktopwebshare_permalink&st=qr25rixxk1o73s6">The Great AI Chatbot Challenge: ChatGPT vs. Gemini vs. Copilot vs. Perplexi</a></div>
    <div class="card-image"><a href="https://www.wsj.com/tech/personal-tech/ai-chatbots-chatgpt-gemini-copilot-perplexity-claude-f9e40d26?reflink=desktopwebshare_permalink&st=qr25rixxk1o73s6"><img src="https://images.wsj.net/im-963856/social" alt=""></a></div>
    <p class="card-excerpt">We tested OpenAI’s ChatGPT against Microsoft’s Copilot and Google’s Gemini, along with Perplexity and Anthropic’s Claude. Here’s how they ranked.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.thediff.co/r/8f054236?m=5ba63d9b-6620-4051-8686-515cd8a8f374">The future of foundation models is closed-source</a></div>
    <div class="card-image"><a href="https://www.thediff.co/r/8f054236?m=5ba63d9b-6620-4051-8686-515cd8a8f374"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F583eeedb-53b8-40b5-8f47-9520bc7b8037_1600x1600.png" alt=""></a></div>
    <p class="card-excerpt">if the centralizing forces of data and compute hold, open and closed-source AI cannot both dominate long-term</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/05/23/demystifying-vision-language-models-an-in-depth-exploration">Demystifying Vision-Language Models: An In-Depth Exploration</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/05/23/demystifying-vision-language-models-an-in-depth-exploration"><img src="https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-16-at-12.00.13-AM.png" alt=""></a></div>
    <p class="card-excerpt">Vision-language models (VLMs), capable of processing both images and text, have gained immense popularity due to their versatility in solving a wide range of tasks, from information retrieval in scanned documents to code generation from screenshots. However, the development of these powerful models has been hindered by a lack of understanding regarding the critical design choices that truly impact their performance. This knowledge gap makes it challenging for researchers to make meaningful progress in this field. To address this issue, a team of researchers from Hugging Face and Sorbonne Université conducted extensive experiments to unravel the factors that matter the</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.wired.com/story/anthropic-black-box-ai-research-neurons-features">AI Is a Black Box. Anthropic Figured Out a Way to Look Inside</a></div>
    <div class="card-image"><a href="https://www.wired.com/story/anthropic-black-box-ai-research-neurons-features"><img src="https://media.wired.com/photos/664baa1664e0ebc8ca8bea4f/191:100/w_1280,c_limit/AI-Black-Box-Business-Site-921311988.jpg" alt=""></a></div>
    <p class="card-excerpt">What goes on in artificial neural networks work is largely a mystery, even to their creators. But researchers from Anthropic have caught a glimpse.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/naklecha/llama3-from-scratch">naklecha/llama3-from-scratch</a></div>
    <div class="card-image"><a href="https://github.com/naklecha/llama3-from-scratch"><img src="https://opengraph.githubassets.com/8d2e244aeba16103152d524e2782f1a003e33ae090eae093973ff64f742be56b/naklecha/llama3-from-scratch" alt=""></a></div>
    <p class="card-excerpt">llama3 implementation one matrix multiplication at a time - naklecha/llama3-from-scratch</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/05/20/abacus-ai-releases-smaug-llama-3-70b-instruct-the-new-benchmark-in-open-source-conversational-ai-rivaling-gpt-4-turbo">Abacus AI Releases Smaug-Llama-3-70B-Instruct: The New Benchmark in Open-So</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/05/20/abacus-ai-releases-smaug-llama-3-70b-instruct-the-new-benchmark-in-open-source-conversational-ai-rivaling-gpt-4-turbo"><img src="https://www.marktechpost.com/wp-content/uploads/2024/05/Blog-Banner-3.png" alt=""></a></div>
    <p class="card-excerpt">Artificial intelligence (AI) has revolutionized various fields by introducing advanced models for natural language processing (NLP). NLP enables computers to understand, interpret, and respond to human language in a valuable way. This field encompasses text generation, translation, and sentiment analysis applications, significantly impacting industries like healthcare, finance, and customer service. The evolution of NLP models has driven these advancements, continually pushing the boundaries of what AI can achieve in understanding and generating human language. Despite these advancements, developing models that can effectively handle complex multi-turn conversations remains a persistent challenge. Existing models often fail to maintain context and coherence over</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thenewstack.io/do-enormous-llm-context-windows-spell-the-end-of-rag">Do Enormous LLM Context Windows Spell the End of RAG?</a></div>
    <div class="card-image"><a href="https://thenewstack.io/do-enormous-llm-context-windows-spell-the-end-of-rag"><img src="https://cdn.thenewstack.io/media/2024/05/3724b60a-enormous-llm-context-windows-end-of-rag.jpg" alt=""></a></div>
    <p class="card-excerpt">Now that LLMs can retrieve 1 million tokens at once, how long will it be until we don’t need retrieval augmented generation for accurate AI responses?</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2024/how-good-open-llm.html">How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2024/how-good-open-llm.html"><img src="https://sebastianraschka.com/images/blog/2024/how-good-open-llm/hero.jpg" alt=""></a></div>
    <p class="card-excerpt">What a month! We had four major open LLM releases: Mixtral, Meta AI's Llama 3, Microsoft's Phi-3, and Apple's OpenELM. In my new article, I review and discus...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/05/11/chuxin-a-fully-open-sourced-language-model-with-a-size-of-1-6-billion-parameters">ChuXin: A Fully Open-Sourced Language Model with a Size of 1.6 Billion Para</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/05/11/chuxin-a-fully-open-sourced-language-model-with-a-size-of-1-6-billion-parameters"><img src="https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-11-at-5.09.31-PM.png" alt=""></a></div>
    <p class="card-excerpt">The capacity of large language models (LLMs) to produce adequate text in various application domains has caused a revolution in natural language creation. These models are essentially two types: 1) Most model weights and data sources are open source. 2) All model-related information is publicly available, including training data, data sampling ratios, training logs, intermediate checkpoints, and assessment methods (Tiny-Llama, OLMo, and StableLM 1.6B). Full access to open language models for the research community is vital for thoroughly investigating these models' capabilities and limitations and understanding their inherent biases and potential risks. This is necessary despite the continued breakthroughs in</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2405.05254">Title:You Only Cache Once: Decoder-Decoder Architectures for Language Model</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2405.05254"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">We introduce a decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once. It consists of two components, i.e., a cross-decoder stacked upon a...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/05/10/anthropic-ai-launches-a-prompt-engineering-tool-that-generates-production-ready-prompts-in-the-anthropic-console">Anthropic AI Launches a Prompt Engineering Tool that Generates Production-R</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/05/10/anthropic-ai-launches-a-prompt-engineering-tool-that-generates-production-ready-prompts-in-the-anthropic-console"><img src="https://www.marktechpost.com/wp-content/uploads/2024/05/Anthropic-Gif-1024x576.gif" alt=""></a></div>
    <p class="card-excerpt">Generative AI (GenAI) tools have come a long way. Believe it or not, the first generative AI tools were introduced in the 1960s in a Chatbot. Still, it was only in 2014 that generative adversarial networks (GANs) were introduced, a type of Machine Learning (ML) algorithm that allowed generative AI to finally create authentic images, videos, and audio of real people. In 2024, we can create anything imaginable using generative AI tools like ChatGPT, DALL-E, and others.  However, there is a problem. We can use those AI tools but can not get the most out of them or use them</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://docs.unstructured.io/open-source/core-functionality/cleaning">Cleaning</a></div>
    <div class="card-image"><a href="https://docs.unstructured.io/open-source/core-functionality/cleaning"><img src="https://mintlify.com/docs/api/og?division=Documentation&mode=dark&title=Cleaning&description=As+part+of+data+preparation+for+an+NLP+model%2C+it%E2%80%99s+common+to+need+to+clean+up+your+data+prior+to+passing+it+into+the+model.+If+there%E2%80%99s+unwanted+content+in+your+output%2C+for+example%2C+it+could+impact+the+quality+of+your+NLP+model.+To+help+with+this%2C+the+%60unstructured%60+library+includes+cleaning+functions+to+help+users+sanitize+output+before+sending+it+to+downstream+applications.&logoLight=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Funstructured-53%2Flogo%2Flight.png&logoDark=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Funstructured-53%2Flogo%2Fdark.png&primaryColor=%2309C6DE&lightColor=%2309C6DE&darkColor=%2309C6DE" alt=""></a></div>
    <p class="card-excerpt">As part of data preparation for an NLP model, it’s common to need to clean up your data prior to passing it into the model. If there’s unwanted content in your output, for example, it could impact the quality of your NLP model. To help with this, the `unstructured` library includes cleaning functions to help users sanitize output before sending it to downstream applications.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2404.19737">[2404.19737] Better & Faster Large Language Models via Multi-token Predicti</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2404.19737"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Large language models such as GPT and Llama are trained with a next-token prediction loss. In this work, we suggest that training language models to predict multiple future tokens at once results...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/05/04/researchers-at-nvidia-ai-introduce-vila-a-vision-language-model-that-can-reason-among-multiple-images-learn-in-context-and-even-understand-videos">Researchers at NVIDIA AI Introduce ‘VILA’: A Vision Language Model that can</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/05/04/researchers-at-nvidia-ai-introduce-vila-a-vision-language-model-that-can-reason-among-multiple-images-learn-in-context-and-even-understand-videos"><img src="https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-4.57.30-PM.png" alt=""></a></div>
    <p class="card-excerpt">The rapid evolution in AI demands models that can handle large-scale data and deliver accurate, actionable insights. Researchers in this field aim to create systems capable of continuous learning and adaptation, ensuring they remain relevant in dynamic environments. A significant challenge in developing AI models lies in overcoming the issue of catastrophic forgetting, where models fail to retain previously acquired knowledge when learning new tasks. This challenge becomes more pressing as applications increasingly demand continuous learning capabilities. For instance, models must update their understanding of healthcare, financial analysis, and autonomous systems while retaining prior knowledge to make informed decisions. The</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://huggingface.co/docs">Hugging Face - Documentation</a></div>
    <div class="card-image"><a href="https://huggingface.co/docs"><img src="https://huggingface.co/front/thumbnails/docs.png" alt=""></a></div>
    <p class="card-excerpt">We’re on a journey to advance and democratize artificial intelligence through open source and open science.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/04/25/understanding-key-terminologies-in-large-language-model-llm-universe">Understanding Key Terminologies in Large Language Model (LLM) Universe</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/04/25/understanding-key-terminologies-in-large-language-model-llm-universe"><img src="https://www.marktechpost.com/wp-content/uploads/2024/04/Screenshot-2024-04-24-at-8.42.34-PM.png" alt=""></a></div>
    <p class="card-excerpt">Are you curious about the intricate world of large language models (LLMs) and the technical jargon that surrounds them? Understanding the terminology, from the foundational aspects of training and fine-tuning to the cutting-edge concepts of transformers and reinforcement learning, is the first step towards demystifying the powerful algorithms that drive modern AI language systems. In this article, we delve into 25 essential terms to enhance your technical vocabulary and provide insights into the mechanisms that make LLMs so transformative. Heatmap representing the relative importance of terms in the context of LLMs Source: marktechpost.com 1. LLM (Large Language Model) Large Language</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/04/23/top-15-ai-libraries-frameworks-for-automatically-red-teaming-your-generative-ai-application">Top 15 AI Libraries/Frameworks for Automatically Red-Teaming Your Generativ</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/04/23/top-15-ai-libraries-frameworks-for-automatically-red-teaming-your-generative-ai-application"><img src="https://www.marktechpost.com/wp-content/uploads/2024/04/Screenshot-2024-04-22-at-8.55.47-PM-1024x962.png" alt=""></a></div>
    <p class="card-excerpt">Prompt Fuzzer: The Prompt Fuzzer is an interactive tool designed to evaluate the security of GenAI application system prompts by simulating various dynamic LLM-based attacks. It assesses security by analyzing the results of these simulations, helping users fortify their system prompts accordingly. This tool specifically customizes its tests to fit the unique configuration and domain of the user's application. The Fuzzer also features a Playground chat interface, allowing users to refine their system prompts iteratively, enhancing their resilience against a broad range of generative AI attacks. Users should be aware that using the Prompt Fuzzer will consume tokens. Garak: Garak</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.theverge.com/2024/4/18/24134103/llama-3-benchmark-testing-ai-gemma-gemini-mistral">Meta says Llama 3 beats most other models, including Gemini - The Verge</a></div>
    <div class="card-image"><a href="https://www.theverge.com/2024/4/18/24134103/llama-3-benchmark-testing-ai-gemma-gemini-mistral"><img src="https://cdn.vox-cdn.com/thumbor/aFVf1nZ5PjZNbxd151IaoqXfmvA=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951355/STK043_VRG_Illo_N_Barclay_1_Meta.jpg" alt=""></a></div>
    <p class="card-excerpt">The models have some pretty good general knowledge.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/anthropics/anthropic-cookbook">anthropics/anthropic-cookbook: A collection of notebooks/recipes showcasing</a></div>
    <div class="card-image"><a href="https://github.com/anthropics/anthropic-cookbook"><img src="https://opengraph.githubassets.com/745bc9c2a06a632586be86215858e9baa9db7dd47ef54f48c99a0cc906248e09/anthropics/anthropic-cookbook" alt=""></a></div>
    <p class="card-excerpt">A collection of notebooks/recipes showcasing some fun and effective ways of using Claude. - anthropics/anthropic-cookbook</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/04/12/deep-learning-architectures-from-cnn-rnn-gan-and-transformers-to-encoder-decoder-architectures">Deep Learning Architectures From CNN, RNN, GAN, and Transformers To Encoder</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/04/12/deep-learning-architectures-from-cnn-rnn-gan-and-transformers-to-encoder-decoder-architectures"><img src="https://www.marktechpost.com/wp-content/uploads/2024/04/Hn6UWRfcQGS1sXgZTUWw6A.png" alt=""></a></div>
    <p class="card-excerpt">Deep learning architectures have revolutionized the field of artificial intelligence, offering innovative solutions for complex problems across various domains, including computer vision, natural language processing, speech recognition, and generative models. This article explores some of the most influential deep learning architectures: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Generative Adversarial Networks (GANs), Transformers, and Encoder-Decoder architectures, highlighting their unique features, applications, and how they compare against each other. Convolutional Neural Networks (CNNs) CNNs are specialized deep neural networks for processing data with a grid-like topology, such as images. A CNN automatically detects the important features without any human supervision.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms?isFreemail=true&post_id=142924793&publication_id=1174659&r=oc5d&triedRedirect=true">Tips for LLM Pretraining and Evaluating Reward Models</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms?isFreemail=true&post_id=142924793&publication_id=1174659&r=oc5d&triedRedirect=true"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fabd9ec-29f1-4c1c-85fb-8781e7c6ce0b_1600x436.png" alt=""></a></div>
    <p class="card-excerpt">Discussing AI Research Papers in March 2024</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://kenkantzer.com/lessons-after-a-half-billion-gpt-tokens">Lessons after a half-billion GPT tokens - Ken Kantzer's Blog</a></div>
    <p class="card-excerpt">My startup Truss (gettruss.io) released a few LLM-heavy features in the last six months, and the narrative around LLMs that I read on Hacker News is now starting to diverge from my reality, so I thought I’d share some of the more “surprising” lessons after churning through just north of 500 million tokens, by my […]</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop">5 Ways To Use LLMs On Your Laptop</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop"><img src="https://www.kdnuggets.com/wp-content/uploads/awan_5_ways_llms_laptop_3.png" alt=""></a></div>
    <p class="card-excerpt">Run large language models on your local PC for customized AI capabilities with more control, privacy, and personalization.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arstechnica.com/information-technology/2024/04/words-are-flowing-out-like-endless-rain-recapping-a-busy-week-of-llm-news">Words are flowing out like endless rain: Recapping a busy week of LLM news</a></div>
    <div class="card-image"><a href="https://arstechnica.com/information-technology/2024/04/words-are-flowing-out-like-endless-rain-recapping-a-busy-week-of-llm-news"><img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/flying_letters.jpg" alt=""></a></div>
    <p class="card-excerpt">Gemini 1.5 Pro launch, new version of GPT-4 Turbo, new Mistral model, and more.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dev.to/mikeyoung44/gemini-a-family-of-highly-capable-multimodal-models-20gi">Gemini: A Family of Highly Capable Multimodal Models</a></div>
    <div class="card-image"><a href="https://dev.to/mikeyoung44/gemini-a-family-of-highly-capable-multimodal-models-20gi"><img src="https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fcgt3bt85na64kv6bddac.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.linkedin.com/posts/peter-gostev_we-are-seeing-some-clear-categories-emerge-activity-7183501457684365314-iihT">Peter Gostev’s Post</a></div>
    <div class="card-image"><a href="https://www.linkedin.com/posts/peter-gostev_we-are-seeing-some-clear-categories-emerge-activity-7183501457684365314-iihT"><img src="https://media.licdn.com/dms/image/v2/D4E22AQFm3iXaCM_yFw/feedshare-shrink_800/feedshare-shrink_800/0/1712680209849?e=2147483647&v=beta&t=K5qJnHxnDnN2glIvEp6YWthqeqb7L5O7dMkk0DkFowU" alt=""></a></div>
    <p class="card-excerpt">We are seeing some clear categories emerge in the world of LLMs - 1) affordable (~$1 per million tokens); 2) mid-range ($8/m) and 3) top end ($25-50/m)… | 32 comments on LinkedIn</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dev.to/rutamstwt/detecting-hallucinations-in-large-language-models-with-text-similarity-metrics-4lj3">Detecting Hallucinations in Large Language Models with Text Similarity Metr</a></div>
    <div class="card-image"><a href="https://dev.to/rutamstwt/detecting-hallucinations-in-large-language-models-with-text-similarity-metrics-4lj3"><img src="https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fko9r8rgbfqg18kirq32y.jpeg" alt=""></a></div>
    <p class="card-excerpt">In the world of LLMs, there is a phenomenon known as "hallucinations." These hallucinations are...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/04/02/top-open-source-large-language-models-llms-available-for-commercial-use">Top Open Source Large Language Models (LLMs) Available For Commercial Use</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/04/02/top-open-source-large-language-models-llms-available-for-commercial-use"><img src="https://www.marktechpost.com/wp-content/uploads/2024/04/m31VipoLSf6blOs_CSgwnA.png" alt=""></a></div>
    <p class="card-excerpt">The top open source Large Language Models available for commercial use are as follows. Llama - 2 Meta released Llama 2, a set of pretrained and refined LLMs, along with Llama 2-Chat, a version of Llama 2. These models are scalable up to 70 billion parameters. It was discovered after extensive testing on safety and helpfulness-focused benchmarks that Llama 2-Chat models perform better than current open-source models in most cases. Human evaluations have shown that they align well with several closed-source models.  The researchers have even taken a few steps to guarantee the security of these models. This includes annotating</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://justine.lol/matmul">LLaMA Now Goes Faster on CPUs</a></div>
    <div class="card-image"><a href="https://justine.lol/matmul"><img src="https://justine.lol/matmul/llamafile.png" alt=""></a></div>
    <p class="card-excerpt">I wrote 84 new matmul kernels to improve llamafile CPU performance.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325">Large language models use a surprisingly simple mechanism to retrieve some</a></div>
    <div class="card-image"><a href="https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325"><img src="https://news.mit.edu/sites/default/files/images/202403/MIT-Transformer-Relations-01.jpg" alt=""></a></div>
    <p class="card-excerpt">Researchers find large language models use a simple mechanism to retrieve stored knowledge when they respond to a user prompt. These mechanisms can be leveraged to see what the model knows about different subjects and possibly to correct false information it has stored.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm">Introducing DBRX: A New State-of-the-Art Open LLM</a></div>
    <div class="card-image"><a href="https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm"><img src="https://www.databricks.com/sites/default/files/2024-03/dbrx-technical-blog-og_0.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/03/31/chatgpt-vs-perplexity-ai-ai-app-comparison">ChatGPT vs Perplexity AI: AI App Comparison</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/03/31/chatgpt-vs-perplexity-ai-ai-app-comparison"><img src="https://www.marktechpost.com/wp-content/uploads/2024/03/Screenshot-2024-03-30-at-11.07.39-PM-1024x865.png" alt=""></a></div>
    <p class="card-excerpt">What is ChatGPT? ChatGPT, developed by OpenAI, is an AI platform renowned for its conversational AI capabilities. Leveraging the power of the Generative Pre-trained Transformer models, ChatGPT generates human-like text responses across various topics, from casual conversations to complex, technical discussions. Its ability to engage users with coherent, contextually relevant dialogues stands out, making it highly versatile for various applications, including content creation, education, customer service, and more. Its integration with tools like DALL-E for image generation from textual descriptions and its continual updates for enhanced performance showcase its commitment to providing an engaging and innovative user experience. ChatGPT Key</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thegradient.pub/mamba-explained">Mamba Explained</a></div>
    <div class="card-image"><a href="https://thegradient.pub/mamba-explained"><img src="https://images.unsplash.com/photo-1598348341635-33a3f4205d32?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHRyYW5zZm9ybWVyfGVufDB8fHx8MTcxMTM0NTEwM3ww&ixlib=rb-4.0.3&q=80&w=2000" alt=""></a></div>
    <p class="card-excerpt">Is Attention all you need? Mamba, a novel AI model based on State Space Models (SSMs), emerges as a formidable alternative to the widely used Transformer models, addressing their inefficiency in processing long sequences.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nextplatform.com/2024/03/19/how-nvidia-blackwell-systems-attack-1-trillion-parameter-ai-models">How Nvidia Blackwell Systems Attack 1 Trillion Parameter AI Models</a></div>
    <div class="card-image"><a href="https://www.nextplatform.com/2024/03/19/how-nvidia-blackwell-systems-attack-1-trillion-parameter-ai-models"><img src="https://www.nextplatform.com/wp-content/uploads/2024/03/nvidia-blackwell-platform-logo-scaled.jpg" alt=""></a></div>
    <p class="card-excerpt">We like datacenter compute engines here at The Next Platform, but as the name implies, what we really like are platforms – how compute, storage,</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321">How Chain-of-Thought Reasoning Helps Neural Networks Compute</a></div>
    <div class="card-image"><a href="https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321"><img src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/03/ChainOfThought-byNickSlater-Social.webp" alt=""></a></div>
    <p class="card-excerpt">Large language models do better at solving problems when they show their work. Researchers are beginning to understand why.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/why-and-how-to-achieve-longer-context-windows-for-llms-5f76f8656ea9?source=rss----7f60cf5620c9---4">Why and How to Achieve Longer Context Windows for LLMs</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/why-and-how-to-achieve-longer-context-windows-for-llms-5f76f8656ea9?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:517/1*YIUq11zLVHA2OKPovlZKTQ.png" alt=""></a></div>
    <p class="card-excerpt">Language models (LLMs) have revolutionized the field of natural language processing (NLP) over the last few years, achieving…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0">Generative AI Design Patterns: A Comprehensive Guide | by Vincent Koc | Feb</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0"><img src="https://miro.medium.com/v2/resize:fit:1200/1*2tBQkVvC-_sHACgSs0ouug.png" alt=""></a></div>
    <p class="card-excerpt">Reference architecture patterns and mental models for working with Large Language Models (LLM’s)</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html">You can now train a 70b language model at home</a></div>
    <div class="card-image"><a href="https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html"><img src="https://www.answer.ai/posts/fsdp-qlora.png" alt=""></a></div>
    <p class="card-excerpt">We’re releasing an open source system, based on FSDP and QLoRA, that can train a 70b model on two 24GB GPUs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/easily-train-a-specialized-llm-peft-lora-qlora-llama-adapter-and-more-aedb5be39244?source=rss----7f60cf5620c9---4">Easily Train a Specialized LLM: PEFT, LoRA, QLoRA, LLaMA-Adapter, and More</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/easily-train-a-specialized-llm-peft-lora-qlora-llama-adapter-and-more-aedb5be39244?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*roKdHgMhP-nL19AMYiDyNQ.jpeg" alt=""></a></div>
    <p class="card-excerpt">Training a specialized LLM over your own data is easier than you think…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.axios.com/2024/02/08/google-bard-gemini-renamed">Google Bard is called Gemini now and expands to mobile, paid versions</a></div>
    <div class="card-image"><a href="https://www.axios.com/2024/02/08/google-bard-gemini-renamed"><img src="https://images.axios.com/vRNK61f1Y4Pp0NXH6s6kR5pK3_w=/0x0:2048x1152/1366x768/2024/02/08/1707350880991.png" alt=""></a></div>
    <p class="card-excerpt">The search giant is unifying its AI-assistant efforts under one name and trying to show it can match rivals.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.linkedin.com/posts/anthropicresearch_today-were-announcing-the-claude-3-model-activity-7170419945292455936-BPaN">Anthropic’s Post</a></div>
    <div class="card-image"><a href="https://www.linkedin.com/posts/anthropicresearch_today-were-announcing-the-claude-3-model-activity-7170419945292455936-BPaN"><img src="https://media.licdn.com/dms/image/v2/D5622AQG0TfRR1wFd8Q/feedshare-shrink_800/feedshare-shrink_800/0/1709561333446?e=2147483647&v=beta&t=20fIMbI05iH1vidsBa_8OaYDngf3lGtL23IxdJ8Ks5M" alt=""></a></div>
    <p class="card-excerpt">Today, we're announcing the Claude 3 model family, which sets new industry benchmarks across a wide range of cognitive tasks. The family includes three… | 429 comments on LinkedIn</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://qz.com/anthropic-opus-claude-openai-chatgpt-ai-1851304996">OpenAI's ChatGPT may have its first true rival in Anthropic's new chatbot</a></div>
    <div class="card-image"><a href="https://qz.com/anthropic-opus-claude-openai-chatgpt-ai-1851304996"><img src="https://i.kinja-img.com/image/upload/c_fill,h_675,pg_1,q_80,w_1200/dd2dd81ccabe1897b6654be8accfe869.jpg" alt=""></a></div>
    <p class="card-excerpt">The Amazon-backed AI startup said its "most intelligent model" outperformed OpenAI's powerful GPT-4</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/rasbt/LLMs-from-scratch">rasbt/LLMs-from-scratch</a></div>
    <div class="card-image"><a href="https://github.com/rasbt/LLMs-from-scratch"><img src="https://repository-images.githubusercontent.com/669879380/79da1d51-4ef9-4733-a61c-1d7851020d9a" alt=""></a></div>
    <p class="card-excerpt">Implementing a ChatGPT-like LLM in PyTorch from scratch, step by step - rasbt/LLMs-from-scratch</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space">Meet RAGxplorer: An interactive AI Tool to Support the Building of Retrieva</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space"><img src="https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-25-at-3.55.05-PM.png" alt=""></a></div>
    <p class="card-excerpt">Understanding how well they comprehend and organize information is crucial in advanced language models. A common challenge arises in visualizing the intricate relationships between different document parts, especially when using complex models like the Retriever-Answer Generator (RAG). Existing tools can only sometimes provide a clear picture of how chunks of information relate to each other and specific queries. Several attempts have been made to address this issue, but they often need to deliver the need to provide an intuitive and interactive solution. These tools need help breaking down documents into manageable pieces and visualizing their semantic landscape effectively. As a</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2024/01/25/how-to-use-google-lumiere">Meet Google Lumiere AI, Bard’s video maker cousin</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2024/01/25/how-to-use-google-lumiere"><img src="https://dataconomy.com/wp-content/uploads/2024/01/How-to-use-Google-Lumiere.jpg" alt=""></a></div>
    <p class="card-excerpt">Step into the future of video creation with Google Lumiere, the latest breakthrough from Google Research that promises to redefine</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4">How To Build an LLM-Powered App To Chat with PapersWithCode</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*0AW3FGe41K7h3E0p" alt=""></a></div>
    <p class="card-excerpt">Keep up with the latest ML research</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://simonwillison.net/2024/Feb/21/gemini-pro-video">The killer app of Gemini Pro 1.5 is video</a></div>
    <div class="card-image"><a href="https://simonwillison.net/2024/Feb/21/gemini-pro-video"><img src="https://static.simonwillison.net/static/2024/gemini-pro-card.jpg" alt=""></a></div>
    <p class="card-excerpt">Last week Google introduced Gemini Pro 1.5, an enormous upgrade to their Gemini series of AI models. Gemini Pro 1.5 has a 1,000,000 token context size. This is huge—previously that …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841?source=rss----7f60cf5620c9---4">Understanding Direct Preference Optimization</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1024/1*L5Fx8l3DZ5LxZVSwBzlEdg.png" alt=""></a></div>
    <p class="card-excerpt">This blog post will look at the “Direct Preference Optimization: Your Language Model is Secretly a Reward Model” paper and its findings.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic">I Spent a Week With Gemini Pro 1.5—It’s Fantastic</a></div>
    <div class="card-image"><a href="https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/post/social_media_image/2987/unnamed__1_.png" alt=""></a></div>
    <p class="card-excerpt">When it comes to context windows, size matters</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2402.17764">Title:The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2402.17764"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Recent research, such as BitNet, is paving the way for a new era of 1-bit Large Language Models (LLMs). In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2024/02/26/sora-early-access">Sora early access: Your guide to securing a spot</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2024/02/26/sora-early-access"><img src="https://dataconomy.com/wp-content/uploads/2024/02/Sora-early-access_02.jpg" alt=""></a></div>
    <p class="card-excerpt">Are you looking for the news everyday for Sora early access like us? Well you are absolutely right because OpenAI's</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://mistral.ai/news/mistral-large">Au Large | Mistral AI | Frontier AI in your hands</a></div>
    <div class="card-image"><a href="https://mistral.ai/news/mistral-large"><img src="https://mistral.ai/images/icons/mistral-supersonic-boat.jpg" alt=""></a></div>
    <p class="card-excerpt">Mistral Large is our flagship model, with top-tier reasoning capacities. It is also available on Azure.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://claude.ai/chat/a77c0bb5-3e7c-4a91-9ced-5314df193759">Claude</a></div>
    <div class="card-image"><a href="https://claude.ai/chat/a77c0bb5-3e7c-4a91-9ced-5314df193759"><img src="https://claude.ai/images/claude_ogimage.png" alt=""></a></div>
    <p class="card-excerpt">Talk with Claude, an AI assistant from Anthropic</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://shyam.blog/posts/beyond-self-attention">Beyond Self-Attention: How a Small Language Model Predicts the Next Token</a></div>
    <p class="card-excerpt">A deep dive into the internals of a small transformer model to learn how it turns self-attention calculations into accurate predictions for the next token.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://open.substack.com/pub/nintyzeros/p/how-do-transformer-workdesign-a-multi">How do transformers work?+Design a Multi-class Sentiment Analysis for Custo</a></div>
    <div class="card-image"><a href="https://open.substack.com/pub/nintyzeros/p/how-do-transformer-workdesign-a-multi"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b143728-e85e-4a5e-af07-98662aa67d5a_727x1024.png" alt=""></a></div>
    <p class="card-excerpt">We will deep dive into understanding how transformer model work like BERT(Non-mathematical Explanation of course!). system design to use the transformer to build a Sentiment Analysis</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://media.licdn.com/dms/image/D4D22AQElBF0kmo1tgA/feedshare-shrink_1280/0/1708022141659?e=1711584000&t=9UxcdrylfOu5hKIS-OZBr4aqeF-Gue26r84_GgTWV0g&v=beta">1708022141659 (JPEG Image, 1280&nbsp;×&nbsp;1600 pixels) — Scaled (56%)</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but">Groq Inference Tokenomics: Speed, But At What Cost?</a></div>
    <div class="card-image"><a href="https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4aad86a5-7fda-444f-9179-7912e9196547_2156x1100.png" alt=""></a></div>
    <p class="card-excerpt">Faster than Nvidia? Dissecting the economics</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents">How Well Can LLMs Negotiate? Stanford Researchers Developed ‘NegotiationAre</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents"><img src="https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-6.06.54-AM.png" alt=""></a></div>
    <p class="card-excerpt">In artificial intelligence, the capacity of Large Language Models (LLMs) to negotiate mirrors a leap toward achieving human-like interactions in digital negotiations. At the heart of this exploration is the NEGOTIATION ARENA, a pioneering framework devised by researchers from Stanford University and Bauplan. This innovative platform delves into the negotiation prowess of LLMs, offering a dynamic environment where AI can mimic, strategize, and engage in nuanced dialogues across a spectrum of scenarios, from splitting resources to intricate trade and price negotiations. The NEGOTIATION ARENA is a tool and a gateway to understanding how AI can be shaped to think, react,</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://openai.com/sora">Sora</a></div>
    <div class="card-image"><a href="https://openai.com/sora"><img src="https://images.ctfassets.net/kftzwdyauwt9/8264d3d7-922c-4343-dde924eae75b/c9f68101050dc2a6caaac2f434c0da5e/paper-airplanes.jpg?w=1600&h=900&fit=fill" alt=""></a></div>
    <p class="card-excerpt">Sora is an AI model that can create realistic and imaginative scenes from text instructions.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://lightning.ai/lightning-ai/studios/code-lora-from-scratch">Code LoRA from Scratch - a Lightning Studio by sebastian</a></div>
    <div class="card-image"><a href="https://lightning.ai/lightning-ai/studios/code-lora-from-scratch"><img src="https://lightning.ai/v1/thumbnail/cloudspace/01hm9hypqc6y1hrapb5prmtz0h?updated_at=1727723800" alt=""></a></div>
    <p class="card-excerpt">LoRA (Low-Rank Adaptation) is a popular technique to finetune LLMs more efficiently. This Studio explains how LoRA works by coding it from scratch, which is an excellent exercise for looking under …</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2024/02/08/bard-is-now-gemini-here-are-gemini-advanced-features">Bard is now Gemini and Gemini Advanced is amazing</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2024/02/08/bard-is-now-gemini-here-are-gemini-advanced-features"><img src="https://dataconomy.com/wp-content/uploads/2024/02/Bard-is-now-Gemini-Advanced_2.jpg" alt=""></a></div>
    <p class="card-excerpt">AI community is once again filled with excitement as Bard is now Gemini and Gemini Advanced offering users an exceptional</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://news.ycombinator.com/item?id=39263664">Ask HN: What have you built with LLMs?</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2303.17564">Title:BloombergGPT: A Large Language Model for Finance</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2303.17564"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model">Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model"><img src="https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_9-scaled.jpg" alt=""></a></div>
    <p class="card-excerpt">Zephyr is a series of Large Language Models released by Hugging Face trained using distilled supervised fine-tuning (dSFT) on larger models with significantly improved task accuracy.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=rss----d7683ed5043e---4">Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with</a></div>
    <div class="card-image"><a href="https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=rss----d7683ed5043e---4"><img src="https://cdn.sanity.io/images/7m9jw85w/production/2e20042f130ae9b86c063958cc2cc717f522a0b4-820x790.jpg" alt=""></a></div>
    <p class="card-excerpt">LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models (LLMs).</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention?isFreemail=true&post_id=140464659&publication_id=1174659&r=oc5d">Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attent</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention?isFreemail=true&post_id=140464659&publication_id=1174659&r=oc5d"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.png" alt=""></a></div>
    <p class="card-excerpt">This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://scisummary.com/dashboard/signed-up">Dashboard - SciSummary</a></div>
    <div class="card-image"><a href="https://scisummary.com/dashboard/signed-up"><img src="https://scisummary.com/img/social.webp" alt=""></a></div>
    <p class="card-excerpt">AI Driven tools for researchers and students. Use AI to summarize and understand scientific articles and research papers.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars">Meet Waymo’s MotionLM: The State-of-the-Art Multi-Agent Motion Prediction A</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars"><img src="https://www.marktechpost.com/wp-content/uploads/2023/10/ezgif-4-5e9741ba41.gif" alt=""></a></div>
    <p class="card-excerpt">Autoregressive language models have excelled at predicting the subsequent subword in a sentence without the need for any predefined grammar or parsing concepts. This method has been expanded to include continuous data domains like audio and image production, where data is represented as discrete tokens, much like language model vocabularies. Due to their versatility, sequence models have attracted interest for use in increasingly complicated and dynamic contexts, such as behavior. Road users are compared to participants in a continuous conversation when driving since they exchange actions and replies. The question is whether similar sequence models may be used to forecast</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arstechnica.com/information-technology/2024/01/a-crazy-update-midjourney-v6-upgrade-heaps-on-ai-generated-detail">How much detail is too much? Midjourney v6 attempts to find out</a></div>
    <div class="card-image"><a href="https://arstechnica.com/information-technology/2024/01/a-crazy-update-midjourney-v6-upgrade-heaps-on-ai-generated-detail"><img src="https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_queen_of_the_universe.jpg" alt=""></a></div>
    <p class="card-excerpt">As Midjourney rolls out new features, it continues to make some artists furious.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023">10 Noteworthy AI Research Papers of 2023</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0046298-1059-4538-bcd8-dfcfc863d7c5_1254x810.png" alt=""></a></div>
    <p class="card-excerpt">This year has felt distinctly different. I've been working in, on, and with machine learning and AI for over a decade, yet I can't recall a time when these fields were as popular and rapidly evolving as they have been this year. To conclude an eventful 2023 in machine learning and AI research, I'm excited to share 10 noteworthy papers I've read this year. My personal focus has been more on large language models, so you'll find a heavier emphasis on large language model (LLM) papers than computer vision papers this year.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/7-steps-to-mastering-large-language-models-llms">7 Steps to Mastering Large Language Models (LLMs)</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/7-steps-to-mastering-large-language-models-llms"><img src="https://www.kdnuggets.com/wp-content/uploads/c_7_steps_mastering_large_language_models_llms_2.png" alt=""></a></div>
    <p class="card-excerpt">Large Language Models (LLMs) have unlocked a new era in natural language processing. So why not learn more about them? Go from learning what large language models are to building and deploying LLM apps in 7 easy steps with this guide.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance">Meta AI Researchers Propose Advanced Long-Context LLMs: A Deep Dive into Up</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance"><img src="https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-08-at-8.08.38-AM.png" alt=""></a></div>
    <p class="card-excerpt">The emergence of Large Language Models (LLMs) in natural language processing represents a groundbreaking development. These models, trained on vast amounts of data and leveraging immense computational resources, promise to transform human interactions with the digital world. As they evolve through scaling and rapid deployment, their potential use cases become increasingly intricate and complex. They extend their capabilities to tasks such as analyzing dense, knowledge-rich documents, enhancing chatbot experiences to make them more genuine and engaging, and assisting human users in iterative creative processes like coding and design. One crucial feature that empowers this evolution is the capacity to effectively</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist">This AI Paper from NVIDIA Explores the Power of Retrieval-Augmentation vs.</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist"><img src="https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-10-at-5.55.31-PM.png" alt=""></a></div>
    <p class="card-excerpt">In a comparative study, Researchers from Nvidia investigated the impact of retrieval augmentation and context window size on the performance of large language models (LLMs) in downstream tasks. The findings reveal that retrieval augmentation consistently enhances LLM performance, irrespective of context window size. Their research sheds light on the effectiveness of retrieval mechanisms in optimizing LLMs for various applications. Researchers delve into the domain of long-context language models, investigating the efficacy of retrieval augmentation and context window size in enhancing LLM performance across various downstream tasks. It conducts a comparative analysis of different pretrained LLMs, demonstrating that retrieval mechanisms significantly</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://lightning.ai/pages/community/lora-insights">Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments - Lightning AI</a></div>
    <div class="card-image"><a href="https://lightning.ai/pages/community/lora-insights"><img src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png" alt=""></a></div>
    <p class="card-excerpt">LoRA is one of the most widely used, parameter-efficient finetuning techniques for training custom LLMs. From saving memory with QLoRA to selecting the optimal LoRA settings, this article provides practical insights for those interested in applying it.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms">Getting Started with Large Language Models: Key Things to Know</a></div>
    <div class="card-image"><a href="https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms"><img src="https://cdn.prod.website-files.com/63bc83b29094ec80844b6dd5/6526dc79dea0f080d2d61d6f_Starting-with-large-language-models.webp" alt=""></a></div>
    <p class="card-excerpt">As a machine learning engineer who has witnessed the rise of Large Language Models (LLMs), I find it daunting to comprehend how the ecosystem surrounding LLMs is developing.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting">Unlocking GPT-4 Summarization with Chain of Density Prompting</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting"><img src="https://www.kdnuggets.com/wp-content/uploads/chain-of-density-header-3.png" alt=""></a></div>
    <p class="card-excerpt">Unlock the power of GPT-4 summarization with Chain of Density (CoD), a technique that attempts to balance information density for high-quality summaries.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/the-ins-and-outs-of-retrieval-augmented-generation-rag-56f470ccda4">The Ins and Outs of Retrieval-Augmented Generation (RAG)</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/the-ins-and-outs-of-retrieval-augmented-generation-rag-56f470ccda4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*z44aRSEAwZ93fOqB" alt=""></a></div>
    <p class="card-excerpt">Our weekly selection of must-read Editors’ Picks and original features</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1">Building RAG-based LLM Applications for Production (Part 1)</a></div>
    <div class="card-image"><a href="https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1"><img src="https://images.ctfassets.net/xjan103pcp94/1vCYZeIqmd03ECO3UXcCSi/374c494a8be6000ccb7570afe40ff182/social-rag-based-llm.png" alt=""></a></div>
    <p class="card-excerpt">In this guide, we will learn how to develop and productionize a retrieval augmented generation (RAG) based LLM application, with a focus on scale and evaluation.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7">RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7"><img src="https://miro.medium.com/v2/resize:fit:1127/1*Jq9bEbitg1Pv4oASwEQwJg.png" alt=""></a></div>
    <p class="card-excerpt">The definitive guide for choosing the right method for your use case</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools">A High-Level Overview Of Large Language Model Concepts, Use Cases, And Tool</a></div>
    <div class="card-image"><a href="https://smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools"><img src="https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/overview-large-language-model-concepts-use-cases-tools.jpg" alt=""></a></div>
    <p class="card-excerpt">Discuss the concept of large language models (LLMs) and how they are implemented with a set of data to develop an application. Joas compares a collection of no-code and low-code apps designed to help you get a feel for not only how the concept works but also to get a sense of what types of models are available to train AI on different skill sets.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=rss----7f60cf5620c9---4">Augmenting LLMs with RAG</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1000/0*2I08qvic82JOQIuA" alt=""></a></div>
    <p class="card-excerpt">An End to End Example Of Seeing How Well An LLM Model Can Answer Amazon SageMaker Related Questions</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique">Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Techniqu</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique"><img src="https://www.kdnuggets.com/wp-content/uploads/skeleton-of-thought-header.png" alt=""></a></div>
    <p class="card-excerpt">Explore how the Skeleton-of-Thought prompt engineering technique enhances generative AI by reducing latency, offering structured output, and optimizing projects.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2302.07730">[2302.07730] Transformer models: an introduction and catalog</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2302.07730"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">In the past few years we have seen the meteoric appearance of dozens of foundation models of the Transformer family, all of which have memorable and sometimes funny, but not self-explanatory,...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font">Hey, Computer, Make Me a Font</a></div>
    <div class="card-image"><a href="https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font"><img src="https://serce.me/images/make-me-a-font/bender.jpeg" alt=""></a></div>
    <p class="card-excerpt">This is a story of my journey learning to build generative ML models from scratch and teaching a computer to create fonts in the process.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.tomtunguz.com/easy-feedback-ml-bard">SaaS Competitive Advantage Through Elegant LLM Feedback Mechanisms</a></div>
    <p class="card-excerpt">Eliciting product feedback elegantly is a competitive advantage for LLM-software. Over the weekend, I queried Google’s Bard, & noticed the elegant feedback loop the product team has incorporated into their product. I asked Bard to compare the 3rd-row leg room of the leading 7-passenger SUVs. At the bottom of the post is a little G button, which double-checks the response using Google searches. I decided to click it. This is what I would be doing in any case ; spot-checking some of the results.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nngroup.com/articles/ai-bot-comparison">ChatGPT, Bard, or Bing Chat? Differences Among 3 Generative-AI Bots</a></div>
    <div class="card-image"><a href="https://www.nngroup.com/articles/ai-bot-comparison"><img src="https://media.nngroup.com/media/articles/opengraph_images/AI-Bots_social-33.png" alt=""></a></div>
    <p class="card-excerpt">Participants rated Bing Chat as less helpful and trustworthy than ChatGPT or Bard. These results can be attributed to Bing’s richer yet imperfect UI and to its poorer information aggregation.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://bard.google.com/chat">Bard</a></div>
    <div class="card-image"><a href="https://bard.google.com/chat"><img src="https://www.gstatic.com/lamda/images/gemini_thumbnail_c362e5eadc46ca9f617e2.png" alt=""></a></div>
    <p class="card-excerpt">Bard is now Gemini. Get help with writing, planning, learning, and more from Google AI.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.scientificamerican.com/podcast/episode/the-state-of-large-language-models">The State of Large Language Models</a></div>
    <div class="card-image"><a href="https://www.scientificamerican.com/podcast/episode/the-state-of-large-language-models"><img src="https://static.scientificamerican.com/sciam/cache/file/48E0C0D2-E023-4F16-BE1A7D26DC05AF36_source.gif?w=600" alt=""></a></div>
    <p class="card-excerpt">We present the latest updates on ChatGPT, Bard and other competitors in the artificial intelligence arms race.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c">10 Ways to Improve the Performance of Retrieval Augmented Generation System</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c"><img src="https://miro.medium.com/v2/resize:fit:1200/1*J16KiNF4M_XxPkALZFUJHw.jpeg" alt=""></a></div>
    <p class="card-excerpt">Tools to go from prototype to production</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9?source=rss----7f60cf5620c9---4">How to Build an LLM from Scratch</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*kNzeztfZxg8IsXA4" alt=""></a></div>
    <p class="card-excerpt">Data Curation, Transformers, Training at Scale, and Model Evaluation</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering">Large Language Model Prompt Engineering for Complex Summarization - ISE Dev</a></div>
    <div class="card-image"><a href="https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering"><img src="https://devblogs.microsoft.com/ise/wp-content/uploads/sites/55/2023/06/prompt-engineering-may23.png" alt=""></a></div>
    <p class="card-excerpt">Learn how to use GPT / LLMs to create complex summaries such as for medical text</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM Leaderboard : a Hugging Face Space by HuggingFaceH4</a></div>
    <div class="card-image"><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/spaces/open-llm-leaderboard/open_llm_leaderboard.png" alt=""></a></div>
    <p class="card-excerpt">Track, rank and evaluate open LLMs and chatbots</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://blog.briankitano.com/llama-from-scratch">Llama from scratch</a></div>
    <div class="card-image"><a href="https://blog.briankitano.com/llama-from-scratch"><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman-1683556668-0.png" alt=""></a></div>
    <p class="card-excerpt">I want to provide some tips from my experience implementing a paper. I'm going to cover my tips so far from implementing a dramatically scaled-down versio...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971">Cracking Open the OpenAI (Python) API</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*QzoGN7Zhi3m21yU0" alt=""></a></div>
    <p class="card-excerpt">A complete beginner-friendly introduction with example code</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161">Cracking Open the Hugging Face Transformers Library</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Rkoquyw55K6qbFWF" alt=""></a></div>
    <p class="card-excerpt">A quick-start guide to using open-source LLMs</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://benchmarks.llmonitor.com">Asking 60+ LLMs a set of 20 questions</a></div>
    <p class="card-excerpt">Human-readable benchmarks of 60+ open-source and proprietary LLMs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/09/20/openai-unveils-dall%C2%B7e-3-a-revolutionary-leap-in-text-to-image-generation">OpenAI Unveils DALL·E 3: A Revolutionary Leap in Text-to-Image Generation</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/09/20/openai-unveils-dall%C2%B7e-3-a-revolutionary-leap-in-text-to-image-generation"><img src="https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-20-at-10.40.15-PM-1024x545.png" alt=""></a></div>
    <p class="card-excerpt">In a significant technological leap, OpenAI has announced the launch of DALL·E 3, the latest iteration in their groundbreaking text-to-image generation technology. With an unprecedented capacity to understand nuanced and detailed descriptions, DALL·E 3 promises to revolutionize the creative landscape by allowing users to translate their textual ideas into astonishingly accurate images effortlessly. DALL·E 3 is currently in research preview, offering a tantalizing glimpse into its capabilities. However, the broader availability of this cutting-edge technology is set for early October, when it will be accessible to ChatGPT Plus and Enterprise customers through the API and Labs later in the fall.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2023/09/22/comparison-dall-e-3-vs-midjourney">Comparison: DALL-E 3 vs Midjourney</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2023/09/22/comparison-dall-e-3-vs-midjourney"><img src="https://dataconomy.com/wp-content/uploads/2023/09/Comparison-DALL-E-3-vs-Midjourney-1111.jpg" alt=""></a></div>
    <p class="card-excerpt">DALL-E 3, the latest version of OpenAI's ground-breaking generative AI visual art platform, was just announced with groundbreaking features, including</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.wired.com/story/what-openai-really-wants">What OpenAI Really Wants</a></div>
    <div class="card-image"><a href="https://www.wired.com/story/what-openai-really-wants"><img src="https://media.wired.com/photos/64ed0bc52da6c6d86e70e575/191:100/w_1280,c_limit/WI100123_FF_OpenAI_01.jpg" alt=""></a></div>
    <p class="card-excerpt">The young company sent shock waves around the world when it released ChatGPT. But that was just the start. The ultimate goal: Change everything. Yes. Everything.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e">A Beginner’s Guide to Building LLM-Powered Applications with LangChain!</a></div>
    <div class="card-image"><a href="https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e"><img src="https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fso3pj9juipg7i3bvrwjb.png" alt=""></a></div>
    <p class="card-excerpt">If you're a developer or simply someone passionate about technology, you've likely encountered AI...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/iryna-kondr/scikit-llm">iryna-kondr/scikit-llm: Seamlessly integrate LLMs into scikit-learn.</a></div>
    <div class="card-image"><a href="https://github.com/iryna-kondr/scikit-llm"><img src="https://opengraph.githubassets.com/350c1f2d6ab49a8c893e709f629e66749bf5265df96eb98a9d57ba89c89f2999/iryna-kondr/scikit-llm" alt=""></a></div>
    <p class="card-excerpt">Seamlessly integrate LLMs into scikit-learn.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f">Prompt Engineering — How to trick AI into solving your problems</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*ZcfH-qxXT4AYAqwr" alt=""></a></div>
    <p class="card-excerpt">7 prompting tricks, Langchain, and Python example code</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672">A Beginner’s Guide to LLM Fine-Tuning</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672"><img src="https://miro.medium.com/v2/resize:fit:1200/1*LVIFTTCmYWQw8nyiuKOA9g.jpeg" alt=""></a></div>
    <p class="card-excerpt">How to fine-tune Llama and other LLMs with one tool</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing">Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Con</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing"><img src="https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg" alt=""></a></div>
    <p class="card-excerpt">A multifaceted challenge has arisen in the expansive realm of natural language processing: the ability to adeptly comprehend and respond to intricate and lengthy instructions. As communication nuances become more complicated, the shortcomings of prevailing models in dealing with extensive contextual intricacies have been laid bare. Within these pages, an extraordinary solution crafted by the dedicated minds at Together AI comes to light—a solution that holds the promise of reshaping the very fabric of language processing. This innovation has profound implications, especially in tasks requiring an acute grasp of extended contextual nuances. Contemporary natural language processing techniques rely heavily on</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148">A Practical Introduction to LLMs</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Nl-5C1WBW4XdGkNI" alt=""></a></div>
    <p class="card-excerpt">3 levels of using LLMs in practice</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/08/19/meet-chroma-an-ai-native-open-source-vector-database-for-llms-a-faster-way-to-build-python-or-javascript-llm-apps-with-memory">Meet Chroma: An AI-Native Open-Source Vector Database For LLMs: A Faster Wa</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/08/19/meet-chroma-an-ai-native-open-source-vector-database-for-llms-a-faster-way-to-build-python-or-javascript-llm-apps-with-memory"><img src="https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-19-at-3.55.16-AM-1024x534.png" alt=""></a></div>
    <p class="card-excerpt">Word embedding vector databases have become increasingly popular due to the proliferation of massive language models. Using the power of sophisticated machine learning techniques, data is stored in a vector database. It allows for very fast similarity search, essential for many AI uses such as recommendation systems, picture recognition, and NLP. The essence of complicated data is captured in a vector database by representing each data point as a multidimensional vector. Quickly retrieving related vectors is made possible by modern indexing techniques like k-d trees and hashing. To transform big data analytics, this architecture generates highly scalable, efficient solutions for</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6">How to Extract Text from Any PDF and Image for Large Language Model | by Zo</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6"><img src="https://miro.medium.com/v2/da:true/resize:fit:1000/0*hsHhE00e_S__ITtI" alt=""></a></div>
    <p class="card-excerpt">Use these text extraction techniques to get quality data for your LLM models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html">Introducing OpenLLM: Open Source Library for LLMs</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html"><img src="https://www.kdnuggets.com/wp-content/uploads/arya_introducing_openllm_open_source_library_llms_1.png" alt=""></a></div>
    <p class="card-excerpt">A user-friendly platform for operating large language models (LLMs) in production, with features such as fine-tuning, serving, deployment, and monitoring of any LLMs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.marktechpost.com/2023/08/03/abacus-ai-introduces-a-new-open-long-context-large-language-model-llm-meet-giraffe">Abacus AI Introduces A New Open Long-Context Large Language Model LLM: Meet</a></div>
    <div class="card-image"><a href="https://www.marktechpost.com/2023/08/03/abacus-ai-introduces-a-new-open-long-context-large-language-model-llm-meet-giraffe"><img src="https://www.marktechpost.com/wp-content/uploads/2023/08/F2cyQhvXAAAJk8y.jpeg" alt=""></a></div>
    <p class="card-excerpt">Recent language models can take long contexts as input; more is needed to know about how well they use longer contexts. Can LLMs be extended to longer contexts? This is an unanswered question. Researchers at Abacus AI conducted multiple experiments involving different schemes for developing the context length ability of Llama, which is pre-trained on context length 2048. They linear rescaled these models with IFT at scales 4 and 16. Scaling the model to scale 16 can perform world tasks up to 16k context length or even up to 20-24k context length.  Different methods of extending context length are Linear</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api">How to use LLMs for PDF parsing</a></div>
    <div class="card-image"><a href="https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api"><img src="https://images.unsplash.com/photo-1682420636597-0786f3406a94?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDM5fHxjaGF0Z3B0fGVufDB8fHx8MTcxNDU0MjE1M3ww&ixlib=rb-4.0.3&q=80&w=2000" alt=""></a></div>
    <p class="card-excerpt">Using ChatGPT & OpenAI's GPT API, this code tutorial teaches how to chat with PDFs, automate PDF tasks, and build PDF chatbots.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc?source=rss----7f60cf5620c9---4">How to Chat With Any File from PDFs to Images Using Large Language Models —</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*jMAGouB3s_LA1YoslX5Z_A.png" alt=""></a></div>
    <p class="card-excerpt">Complete guide to building an AI assistant that can answer questions about any file</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.turingpost.com/p/practicalllms">How to Leverage Open-Source LLMs in Your Project</a></div>
    <div class="card-image"><a href="https://www.turingpost.com/p/practicalllms"><img src="https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/3d4e8599-c213-442c-b2c3-bf39b5306497/Frame_144.png?t=1693246361" alt=""></a></div>
    <p class="card-excerpt">Practical Advice from Experts: Fine-Tuning, Deployment, and Best Practices</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html">LangChain 101: Build Your Own GPT-Powered Applications</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html"><img src="https://www.kdnuggets.com/wp-content/uploads/c_langchain_101_build_gptpowered_applications_2.png" alt=""></a></div>
    <p class="card-excerpt">LangChain is a Python library that helps you build GPT-powered applications in minutes. Get started with LangChain by building a simple question-answering app.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.mosaicml.com/blog/mpt-30b">MPT-30B: Raising the bar for open-source foundation models</a></div>
    <div class="card-image"><a href="https://www.mosaicml.com/blog/mpt-30b"><img src="https://www.databricks.com/en-blog-assets/static/og-databricks-58419d0d868b05ddb057830066961ebe.png" alt=""></a></div>
    <p class="card-excerpt">Latest blogs from the team at Mosaic Research</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dataconomy.com/2023/07/12/midjourney-pricing-and-free-alternatives">Midjourney pricing plans and free alternatives to try</a></div>
    <div class="card-image"><a href="https://dataconomy.com/2023/07/12/midjourney-pricing-and-free-alternatives"><img src="https://dataconomy.com/wp-content/uploads/2023/07/Midjourney-pricing-plans-and-free-alternatives-to-try.jpg" alt=""></a></div>
    <p class="card-excerpt">Navigating the maze of pricing plans for digital services can sometimes be a daunting task. Today, we are unveiling Midjourney</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.turingpost.com/p/top3llmsope">A Deep Dive Into LLaMA, Falcon, Llama 2 and Their Remarkable Fine-Tuned Ver</a></div>
    <div class="card-image"><a href="https://www.turingpost.com/p/top3llmsope"><img src="https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/f739d30a-90f3-4c02-9e23-f40e93f92c28/Frame_143.png?t=1693246280" alt=""></a></div>
    <p class="card-excerpt">Exploring the Development of the 3 Leading Open LLMs and Their Chatbot Derivatives</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38?source=rss----7f60cf5620c9---4">Chain of Thought Prompting for LLMs</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*g5Q-4lGt9UySnOK0JRQiPg.jpeg" alt=""></a></div>
    <p class="card-excerpt">A practical and simple approach for “reasoning” with LLMs</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://dev.to/bitohq/claude-2-vs-claude-13-vs-gpt-4-ai-coding-comparison-k29">Is Anthropic's Claude 2 model ready to take down GPT-4? We put them to the</a></div>
    <div class="card-image"><a href="https://dev.to/bitohq/claude-2-vs-claude-13-vs-gpt-4-ai-coding-comparison-k29"><img src="https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F0an9xnkhqoa564q8gird.png" alt=""></a></div>
    <p class="card-excerpt">Anthropic released Claude 2, a new iteration of its AI model, to take on ChatGPT and Google Bard...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications">Emerging Architectures for LLM Applications</a></div>
    <div class="card-image"><a href="https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications"><img src="https://d1lamhf6l6yk6d.cloudfront.net/uploads/2023/06/2657_-LLM-Architecture-Yoast-1200x630-1.webp" alt=""></a></div>
    <p class="card-excerpt">A reference architecture for the LLM app stack. It shows the most common systems, tools, and design patterns used by AI startups and tech companies.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad">ELI5: FlashAttention</a></div>
    <div class="card-image"><a href="https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad"><img src="https://miro.medium.com/v2/resize:fit:1200/1*i4tDdwgvGtXuTIyJpFUn8A.png" alt=""></a></div>
    <p class="card-excerpt">Step by step explanation of how one of the most important MLSys breakthroughs work — in gory detail.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68">Build Industry-Specific LLMs Using Retrieval Augmented Generation</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68"><img src="https://miro.medium.com/v2/resize:fit:1200/1*tJYmd5EGacd-7ld5PFgdHg.png" alt=""></a></div>
    <p class="card-excerpt">Organizations are in a race to adopt Large Language Models. Let’s dive into how you can build industry-specific LLMs Through RAG</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/06/free-full-stack-llm-bootcamp.html">Free Full Stack LLM Bootcamp</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/06/free-full-stack-llm-bootcamp.html"><img src="https://www.kdnuggets.com/wp-content/uploads/c_free_full_stack_llm_bootcamp_2.png" alt=""></a></div>
    <p class="card-excerpt">Want to learn more about LLMs and build cool LLM-powered applications? This free Full Stack LLM Bootcamp is all you need!</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most">Edge 300: Meet Falcon LLM: The Most Powerful Open Source LLM Released to Da</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa405bc1-2701-410e-8b87-53c72a5c84af_1024x1024.png" alt=""></a></div>
    <p class="card-excerpt">The model quickly top the Open LLM Leaderboard that ranks the performance of open source LLMs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c">The Secret Sauce behind 100K context window in LLMs: all tricks in one plac</a></div>
    <div class="card-image"><a href="https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c"><img src="https://miro.medium.com/v2/resize:fit:534/0*x80ZcJl_2zLbyvCE.jpg" alt=""></a></div>
    <p class="card-excerpt">tldr; techniques to speed up training and inference of LLMs to use large context window up to 100K input tokens during training and…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac">All You Need to Know to Build Your First LLM App</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac"><img src="https://miro.medium.com/v2/resize:fit:1200/1*njagJOgiT-VTJjQ18bugcw.png" alt=""></a></div>
    <p class="card-excerpt">A step-by-step tutorial to document loaders, embeddings, vector stores and prompt templates</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/observe-ai-unveils-30-billion-parameter-contact-center-llm-and-a-generative-ai-product-suite">Observe.ai unveils 30-billion-parameter contact center LLM and a generative</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/observe-ai-unveils-30-billion-parameter-contact-center-llm-and-a-generative-ai-product-suite"><img src="https://venturebeat.com/wp-content/uploads/2023/06/ObserveAI-Banner-Image.jpeg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">The Observe.AI contact center LLM showed a 35% increase in accuracy compared to GPT-3.5 when automatically summarizing conversations.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.mosaicml.com/blog/amd-mi250">Training LLMs with AMD MI250 GPUs and MosaicML</a></div>
    <div class="card-image"><a href="https://www.mosaicml.com/blog/amd-mi250"><img src="https://www.databricks.com/sites/default/files/2023-12/training-llms-amd-mosaicml-img-og.png" alt=""></a></div>
    <p class="card-excerpt">With the release of PyTorch 2.0 and ROCm 5.4, we are excited to announce that LLM training works out of the box on AMD MI250 accelerators with zero code changes and at high performance!</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm">Optimizing Memory Usage for Training LLMs and Vision Transformers in PyTorc</a></div>
    <div class="card-image"><a href="https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm"><img src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/pytorch-memory-hero.png" alt=""></a></div>
    <p class="card-excerpt">This article provides a series of techniques that can lower memory consumption in PyTorch (when training vision transformers and LLMs) by approximately 20x without sacrificing modeling performance and prediction accuracy.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373?source=rss----7f60cf5620c9---4">Deploying Falcon-7B Into Production</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1024/1*mJeCCGWnhNg3albw4UqCjg.png" alt=""></a></div>
    <p class="card-excerpt">Running Falcon-7B in the cloud as a microservice</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot">Anthropic releases Claude 2, its second-gen AI chatbot</a></div>
    <div class="card-image"><a href="https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot"><img src="https://techcrunch.com/wp-content/uploads/2023/05/anthropic-header.jpg?resize=1200,675" alt=""></a></div>
    <p class="card-excerpt">Anthropic, the AI startup founded by ex-OpenAI execs, has released its newest chatbot, Claude 2. It's ostensibly improved in several ways.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://tech.slashdot.org/story/23/07/12/2334234/google-launches-ai-powered-notes-app-called-notebooklm">Google Launches AI-Powered Notes App Called NotebookLM</a></div>
    <div class="card-image"><a href="https://tech.slashdot.org/story/23/07/12/2334234/google-launches-ai-powered-notes-app-called-notebooklm"><img src="https://a.fsdn.com/sd/topics/ai_64.png" alt=""></a></div>
    <p class="card-excerpt">Google is launching its AI-backed note-taking tool to "a small group of users in the US," the company said in a blog post. Formerly referred to as Project Tailwind at Google I/O earlier this year, the new app is now known as NotebookLM (the LM stands for Language Model). The Verge reports:  The core...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/meet-lmql-an-open-source-query-language">Meet LMQL: An Open Source Query Language for LLMs</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/meet-lmql-an-open-source-query-language"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb64cfd32-2483-4d99-9c2b-d4cc34017c0f_1024x1024.png" alt=""></a></div>
    <p class="card-excerpt">Developed by ETH Zürich, the language explores new paradigms for LLM programming.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table">Ecosystem Graphs for Foundation Models</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.linkedin.com/posts/lvwerra_it-crazy-how-far-the-ml-field-has-come-when-activity-7087699813009383425-Sr1y">Leandro von Werra’s Post</a></div>
    <div class="card-image"><a href="https://www.linkedin.com/posts/lvwerra_it-crazy-how-far-the-ml-field-has-come-when-activity-7087699813009383425-Sr1y"><img src="https://media.licdn.com/dms/image/v2/D4E22AQGGzP26Zn7lSg/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1689839317534?e=2147483647&v=beta&t=2-BIClj1Bq40beli2UNOE37ZSktTyTWlRXY4sFIxceg" alt=""></a></div>
    <p class="card-excerpt">It crazy how far the ML field has come when it comes to fine-tuning LLMs.   A year ago: it was challenging to fine-tune GPT-2 (1.5B) on a single GPU without… | 76 comments on LinkedIn</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now">LLaMA 2: How to access and use Meta’s versatile open-source chatbot right n</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now"><img src="https://venturebeat.com/wp-content/uploads/2023/07/nuneybits_vector_art_of_a_llama_programming_8c825672-172b-4e69-a6f1-b7c9e8bf5294.png?w=803?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">A comprehensive guide on how to use Meta's LLaMA 2, the new open-source AI model challenging OpenAI's ChatGPT and Google's Bard.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f">Beyond LLaMA: The Power of Open LLMs</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f"><img src="https://miro.medium.com/v2/resize:fit:1200/1*c3XC-3-pgvtxakXTmKubUA.jpeg" alt=""></a></div>
    <p class="card-excerpt">How LLaMA is making open-source cool again</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/facebook-parent-meta-unveils-llama-2-open-source-ai-model-for-commercial-use">Facebook parent Meta unveils LLaMA 2 open-source AI model for commercial us</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/facebook-parent-meta-unveils-llama-2-open-source-ai-model-for-commercial-use"><img src="https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_vector_art_cybernetic_llama_wearing_sunglasses_synthwav_d3f82260-2c47-4abd-9599-b91751711f5b.png?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Not only has LLaMA been trained on more data, with more parameters, the model also performs better than its predecessor, according to Meta.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/mosaicml-launches-mpt-7b-8k-a-7b-parameter-open-source-llm">MosaicML launches MPT-7B-8K, a 7B-parameter open-source LLM with 8k context</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/mosaicml-launches-mpt-7b-8k-a-7b-parameter-open-source-llm"><img src="https://venturebeat.com/wp-content/uploads/2023/07/Mosaic-ML.jpg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">MosaicML claims that the MPT-7B-8K LLM exhibits exceptional proficiency in summarization and answering tasks compared to previous models.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.thediff.co/r/a2af7311?m=5ba63d9b-6620-4051-8686-515cd8a8f374">The $1 billion gamble to ensure AI doesn’t destroy humanity</a></div>
    <div class="card-image"><a href="https://www.thediff.co/r/a2af7311?m=5ba63d9b-6620-4051-8686-515cd8a8f374"><img src="https://platform.vox.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/24788204/Vox_Anthropic_final.jpg?quality=90&strip=all&crop=0%2C3.4613147178592%2C100%2C93.077370564282&w=1200" alt=""></a></div>
    <p class="card-excerpt">The founders of Anthropic quit OpenAI to make a safe AI company. It’s easier said than done.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html">Unraveling the Power of Chain-of-Thought Prompting in Large Language Models</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html"><img src="https://www.kdnuggets.com/wp-content/uploads/cot-brain-model-chains.jpg" alt=""></a></div>
    <p class="card-excerpt">This article delves into the concept of Chain-of-Thought (CoT) prompting, a technique that enhances the reasoning capabilities of large language models (LLMs). It discusses the principles behind CoT prompting, its application, and its impact on the performance of LLMs.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/Mooler0410/LLMsPracticalGuide">GitHub - Mooler0410/LLMsPracticalGuide: A curated list of practical guide r</a></div>
    <div class="card-image"><a href="https://github.com/Mooler0410/LLMsPracticalGuide"><img src="https://opengraph.githubassets.com/4a3206398769105f4d6992be690752d89bd655e13bafcaf464ecde09cbc72a56/Mooler0410/LLMsPracticalGuide" alt=""></a></div>
    <p class="card-excerpt">A curated list of practical guide resources of LLMs (LLMs Tree, Examples, Papers) - Mooler0410/LLMsPracticalGuide</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html">Falcon LLM: The New King of Open-Source LLMs</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html"><img src="https://www.kdnuggets.com/wp-content/uploads/arya_falcon_llm_new_king_llms_3.png" alt=""></a></div>
    <p class="card-excerpt">Falcon LLM, is the new large language model that has taken the crown from LLaMA.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/introduction-to-the-open-llm-falcon-40b-performance-training-data-and-architecture-98388fa40226?source=rss----7f60cf5620c9---4">Introduction to the Open LLM Falcon-40B: Performance, Training Data, and Ar</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/introduction-to-the-open-llm-falcon-40b-performance-training-data-and-architecture-98388fa40226?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*nlOvoxsWqgObj_Jj" alt=""></a></div>
    <p class="card-excerpt">Get started using Falcon-7B, Falcon-40B, and their instruct versions</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www-marktechpost-com.cdn.ampproject.org/c/s/www.marktechpost.com/2023/06/16/meet-fingpt-an-open-source-financial-large-language-model-llms?amp=">Meet FinGPT: An Open-Source Financial Large Language Model (LLMs)</a></div>
    <div class="card-image"><a href="https://www-marktechpost-com.cdn.ampproject.org/c/s/www.marktechpost.com/2023/06/16/meet-fingpt-an-open-source-financial-large-language-model-llms?amp="><img src="https://www.marktechpost.com/wp-content/uploads/2023/06/Screenshot-2023-06-15-at-10.50.11-PM.png" alt=""></a></div>
    <p class="card-excerpt">Large language models have increased due to the ongoing development and advancement of artificial intelligence, which has profoundly impacted the state of natural language processing in various fields. The potential use of these models in the financial sector has sparked intense attention in light of this radical upheaval. However, constructing an effective and efficient open-source economic language model depends on gathering high-quality, pertinent, and current data. The use of language models in the financial sector exposes many barriers. These vary from challenges in getting data, maintaining various data forms and kinds, and coping with inconsistent data quality to the crucial</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://llm.garden">LMM Garden | Discover, search, and compare LLMs</a></div>
    <div class="card-image"><a href="https://llm.garden"><img src="https://llm.garden/wp-content/uploads/2023/05/Social-share_LLM-Garden-1024x535.png" alt=""></a></div>
    <p class="card-excerpt">Welcome to the LMM garden! A searchable list of open-source and off-the-shelf LLMs available to ML practitioners. Know of a new LLM? Add it</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/iryna-kondr/scikit-llm/issues">iryna-kondr/scikit-llm</a></div>
    <div class="card-image"><a href="https://github.com/iryna-kondr/scikit-llm/issues"><img src="https://opengraph.githubassets.com/350c1f2d6ab49a8c893e709f629e66749bf5265df96eb98a9d57ba89c89f2999/iryna-kondr/scikit-llm" alt=""></a></div>
    <p class="card-excerpt">Seamlessly integrate LLMs into scikit-learn.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://spectrum.ieee.org/ai-cpu">The Case for Running AI on CPUs Isn’t Dead Yet</a></div>
    <div class="card-image"><a href="https://spectrum.ieee.org/ai-cpu"><img src="https://spectrum.ieee.org/media-library/an-intel-xeon-processor-on-a-black-backdrop-the-processor-is-shown-from-both-above-and-below-displaying-the-thousands-of-conta.jpg?id=33743986&width=1200&height=600&coordinates=0%2C698%2C0%2C698" alt=""></a></div>
    <p class="card-excerpt">GPUs may dominate, but CPUs could be perfect for smaller AI models</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38">The Art of Prompt Design: Prompt Boundaries and Token Healing</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38"><img src="https://miro.medium.com/v2/resize:fit:1200/1*PPLOArQM0wXZ5V55VbTNYA.png" alt=""></a></div>
    <p class="card-excerpt">Learn how standard greedy tokenization introduces a subtle and powerful bias that can have all kinds of unintended consequences.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.linkedin.com/posts/sonali-pattnaik_generativeai-ai-activity-7063160223967973376-3K0P">Sonali Pattnaik on LinkedIn: #generativeai #ai | 45 comments</a></div>
    <div class="card-image"><a href="https://www.linkedin.com/posts/sonali-pattnaik_generativeai-ai-activity-7063160223967973376-3K0P"><img src="https://static.licdn.com/aero-v1/sc/h/c45fy346jw096z9pbphyyhdz7" alt=""></a></div>
    <p class="card-excerpt">AI companies are using LangChain to supercharge their LLM apps. Here is a comprehensive guide of resources to build your LangChain + LLM journey.   🔗 What is… | 45 comments on LinkedIn</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://informationisbeautiful.net/2023/the-non-silence-of-the-llms">The Non-Silence of the LLMs</a></div>
    <div class="card-image"><a href="https://informationisbeautiful.net/2023/the-non-silence-of-the-llms"><img src="https://infobeautiful4.s3.amazonaws.com/2023/05/IIB-LLM-decorative-blog-blog-1400x400-1-960x274.png" alt=""></a></div>
    <p class="card-excerpt">AI is getting very chatty! Here’s a visualisation charting the rise of Large Language Models like GPT4, LaMDA, LLaMa, PaLM and their bots...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/05/super-bard-ai-better.html">Super Bard: The AI That Can Do It All and Better</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/05/super-bard-ai-better.html"><img src="https://www.kdnuggets.com/wp-content/uploads/awan_super_bard_ai_better_1.png" alt=""></a></div>
    <p class="card-excerpt">A new AI Bard powered by PaLM V2 that can write, translate, and code better than ChatGPT.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/edge-291-reinforcement-learning-with">Edge 291: Reinforcement Learning with Human Feedback</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/edge-291-reinforcement-learning-with"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1aaa4cc-10d6-4ada-bba0-f1f2f0793427_1024x1024.png" alt=""></a></div>
    <p class="card-excerpt">1) Reinforcement Learning with Human Feedback(RLHF) 2) The RLHF paper, 3) The transformer reinforcement learning framework.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training">Google dives into the ‘supercomputer’ game by knitting together purpose-bui</a></div>
    <div class="card-image"><a href="https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training"><img src="https://venturebeat.com/wp-content/uploads/2022/12/VB_dictionary-page_romain-vignes-ywqa9IZB-dU-unsplash.jpg?w=1024?w=1200&strip=all" alt=""></a></div>
    <p class="card-excerpt">Google's new machines combine Nvidia H100 GPUs with Google’s high-speed interconnections for AI tasks like training very large language models.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2305.02301">Distilling Step-by-Step! Outperforming Larger Language Models with...</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2305.02301"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2301.00774">SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2301.00774"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">We show for the first time that large-scale generative pretrained transformer (GPT) family models can be pruned to at least 50% sparsity in one-shot, without any retraining, at minimal loss of...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/openlm-research/open_llama">openlm-research/open_llama: OpenLLaMA, a permissively licensed open source reproduction of Meta AI’s LLaMA 7B trained on the RedPajama dataset</a></div>
    <div class="card-image"><a href="https://github.com/openlm-research/open_llama"><img src="https://opengraph.githubassets.com/e7ffbff063d324707d142c5ab7f43a0491b51bf163bb2b7cb51ae1ca0f4eda81/openlm-research/open_llama" alt=""></a></div>
    <p class="card-excerpt">OpenLLaMA, a permissively licensed open source reproduction of Meta AI’s LLaMA 7B trained on the RedPajama dataset - openlm-research/open_llama</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/microsoft/guidance">guidance-ai/guidance: A guidance language for controlling large language models.</a></div>
    <div class="card-image"><a href="https://github.com/microsoft/guidance"><img src="https://opengraph.githubassets.com/40caa4be0603b938000317605dfdb2293da8c409e5cc9f3168bcd98f0b97c888/guidance-ai/guidance" alt=""></a></div>
    <p class="card-excerpt">A guidance language for controlling large language models. - guidance-ai/guidance</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.anyscale.com/blog/how-to-fine-tune-and-serve-llms-simply-quickly-and-cost-effectively-using">Blog | Anyscale</a></div>
    <p class="card-excerpt">Anyscale is the leading AI application platform. With Anyscale, developers can build, run and scale AI applications instantly.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html">Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA)</a></div>
    <div class="card-image"><a href="https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html"><img src="https://sebastianraschka.com/images/blog/2023/llm-finetuning-llama-adapter/hero.jpg" alt=""></a></div>
    <p class="card-excerpt">In the rapidly evolving field of AI, using large language models in an efficient and effective manner is becoming more and more important. In this article, y...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/edge-286-vicuna-the-llama-based-model">Edge 286: Vicuna, the LLaMA-Based Model that Matches ChatGPT Performance</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/edge-286-vicuna-the-llama-based-model"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37f4993d-660a-44f2-af55-b40a5b870e8c_1024x1024.png" alt=""></a></div>
    <p class="card-excerpt">Created by researchers from UC Berkeley, CMU, Stanford, and UC San Diego, Vicuna is part of the new wave of models that use Meta's LLaMA as its foundation.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thegradient.pub/grounding-large-language-models-in-a-cognitive-foundation">Grounding Large Language Models in a Cognitive Foundation: How to Build Som</a></div>
    <div class="card-image"><a href="https://thegradient.pub/grounding-large-language-models-in-a-cognitive-foundation"><img src="https://thegradient.pub/content/images/2023/04/header-5.svg" alt=""></a></div>
    <p class="card-excerpt">Many intelligent robots have come and gone, failing to become a commercial success. We’ve lost Aibo, Romo, Jibo, Baxter—even Alexa is reducing staff. Perhaps they failed to reach their potential because you can’t have a meaningful conversation with them. We are now at an inflection point: AI</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://datamachina.substack.com/p/data-machina-198">Data Machina #198</a></div>
    <div class="card-image"><a href="https://datamachina.substack.com/p/data-machina-198"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F212c16cd-1315-43b1-9dda-6e09235ce41d_1006x1006.png" alt=""></a></div>
    <p class="card-excerpt">Your own LLM. MiniGPT-4. WebGPT on WebGPU. Transformers from scratch. ChatGTP Plugins demo live. Whisper JAX. LLaVA. MetaAI DINO SoTA Computer Vision. Autonomous agents in LangChain. RedPajama.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/finetuning-large-language-models">Finetuning Large Language Models</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/finetuning-large-language-models"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa534808e-9284-47eb-9b4d-3e3aedc0b5da_1180x842.png" alt=""></a></div>
    <p class="card-excerpt">An introduction to the core ideas and approaches</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/the-llama-effect-how-an-accidental">The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Ope</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/the-llama-effect-how-an-accidental"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef03b36c-e5da-49d6-af96-e1ad9a078c0d_1024x1024.png" alt=""></a></div>
    <p class="card-excerpt">Sundays, The Sequence Scope brings a summary of the most important research papers, technology releases and VC funding deals in the artificial intelligence space.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Stanford CRFM</a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency">Meta has built a massive new language AI—and it’s giving it away for free</a></div>
    <div class="card-image"><a href="https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency"><img src="https://wp.technologyreview.com/wp-content/uploads/2022/05/tiles2-1.jpeg?resize=1200,600" alt=""></a></div>
    <p class="card-excerpt">Facebook’s parent company is inviting researchers to pore over and pick apart the flaws in its version of GPT-3</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2304.00612">Eight Things to Know about Large Language Models</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2304.00612"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">The widespread public deployment of large language models (LLMs) in recent months has prompted a wave of new attention and engagement from advocates, policymakers, and scholars from many fields....</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.kdnuggets.com/2023/04/baby-agi-birth-fully-autonomous-ai.html">Baby AGI: The Birth of a Fully Autonomous AI</a></div>
    <div class="card-image"><a href="https://www.kdnuggets.com/2023/04/baby-agi-birth-fully-autonomous-ai.html"><img src="https://www.kdnuggets.com/wp-content/uploads/arya_baby_agi_birth_fully_autonomous_ai_3.png" alt=""></a></div>
    <p class="card-excerpt">Introducing the new fully autonomous task manager that can create, track and prioritize your company's projects using artificial intelligence.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://magazine.sebastianraschka.com/p/understanding-large-language-models">Hacker News</a></div>
    <div class="card-image"><a href="https://magazine.sebastianraschka.com/p/understanding-large-language-models"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9a0766d-2e52-4af0-96c5-3e07a30d6ecb_1868x1130.png" alt=""></a></div>
    <p class="card-excerpt">A Cross-Section of the Most Relevant Literature To Get Up to Speed</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/guest-post-how-to-enhance-the-usefulness">📝 Guest Post: How to Enhance the Usefulness of Large Language Models*</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/guest-post-how-to-enhance-the-usefulness"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F644b606d-622a-4a15-acb7-02b97ad843a9_3200x1454.png" alt=""></a></div>
    <p class="card-excerpt">In this guest post, Filip Haltmayer, a Software Engineer at Zilliz, explains how LangChain and Milvus can enhance the usefulness of Large Language Models (LLMs) by allowing for the storage and retrieval of relevant documents. By integrating Milvus, a vector database, with LangChain, LLMs can process more tokens and improve their conversational abilities.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering">Prompt Engineering</a></div>
    <p class="card-excerpt">Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics. This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://arxiv.org/abs/2303.18223">A Survey of Large Language Models</a></div>
    <div class="card-image"><a href="https://arxiv.org/abs/2303.18223"><img src="https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" alt=""></a></div>
    <p class="card-excerpt">Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and...</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook">New Ebook: A Beginner’s Guide to Large Language Models</a></div>
    <div class="card-image"><a href="https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook"><img src="https://www.nvidia.com/content/dam/en-zz/Solutions/lp/large-language-models-ebook/nvidia-llm-ebook-og.jpg" alt=""></a></div>
    <p class="card-excerpt">Explore what LLMs are, how they work, and gain insights into real-world examples, use cases, and best practices.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms">Maximizing the Potential of LLMs: A Guide to Prompt Engineering</a></div>
    <div class="card-image"><a href="https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms"><img src="https://ruxu.devassets/images/openai.png" alt=""></a></div>
    <p class="card-excerpt"></p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=rss----7f60cf5620c9---4">The Magic of LLMs — Prompt Engineering</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*ri0kB_t9WfNZtpLe" alt=""></a></div>
    <p class="card-excerpt">Garbage in, garbage out has never been more true.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://thesequence.substack.com/p/guest-post-caching-llm-queries-for">📝 Guest Post: Caching LLM Queries for Improved Performance and Cost Savings*</a></div>
    <div class="card-image"><a href="https://thesequence.substack.com/p/guest-post-caching-llm-queries-for"><img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1763eb47-236b-4dfd-851c-2a388c7a5671_3200x1454.png" alt=""></a></div>
    <p class="card-excerpt">If you're looking for a way to improve the performance of your large language model (LLM) application while reducing costs, consider utilizing a semantic cache to store LLM responses.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://platform.openai.com/overview">OpenAI Platform</a></div>
    <div class="card-image"><a href="https://platform.openai.com/overview"><img src="https://cdn.openai.com/API/images/opengraph.png" alt=""></a></div>
    <p class="card-excerpt">Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.</p>
  </div>
</div>
</body></html>
