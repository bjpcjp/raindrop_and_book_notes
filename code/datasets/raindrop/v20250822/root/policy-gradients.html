<html><head><meta charset="utf-8"><title>policy-gradients</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">‚üµ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>policy-gradients</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/policy-gradient-methods-in-reinforcement-learning-31f8a9659398">Policy Gradient Methods in Reinforcement Learning</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/policy-gradient-methods-in-reinforcement-learning-31f8a9659398"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*5jXzqt5c443Fay5c" alt=""></a></div>
    <p class="card-excerpt">Teaching a Car to Cross a Mountain using Policy Gradient Methods in Python: A Mathematical Deep Dive into Reinforcement Learning</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/policy-gradients-the-foundation-of-rlhf-337346beef40">Policy Gradients: The Foundation of RLHF</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/policy-gradients-the-foundation-of-rlhf-337346beef40"><img src="https://miro.medium.com/v2/resize:fit:1200/1*voPcx38gcf1rwmm-j12Mcw.jpeg" alt=""></a></div>
    <p class="card-excerpt">Understanding policy optimization and how it is used in reinforcement learning</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/MrSyee/pg-is-all-you-need">MrSyee/pg-is-all-you-need: Policy Gradient is all you need! A step-by-step</a></div>
    <div class="card-image"><a href="https://github.com/MrSyee/pg-is-all-you-need"><img src="https://opengraph.githubassets.com/6c86590cafa4ff4f1514af38d05f63369532553bb7ec3c8e4e27c5d049d36961/MrSyee/pg-is-all-you-need" alt=""></a></div>
    <p class="card-excerpt">Policy Gradient is all you need! A step-by-step tutorial for well-known PG methods. - MrSyee/pg-is-all-you-need</p>
  </div>
</div>
</body></html>
