<html><head><meta charset="utf-8"><title>gradients</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">⟵ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>gradients</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://poonai.xyz/posts/simplest-backpropagation-explainer-without-chain-rule/">Simplest backpropagation explainer without chain rule</a></div>
    <p class="card-excerpt">Neural Networks learn to predict by backpropagation. This article aims to help you, build a solid intuition about the concept using a simple example. The ideas we learn here can be expanded for bigger nerual network. I assume that you already know how feed forward neural network works.
Before reading the article further, take a pen and paper. The calculation used in this article can be done in the head. But I still want you to do by hand.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://machinelearningmastery.com/exploding-gradients-in-neural-networks">A Gentle Introduction to Exploding Gradients in Neural Networks</a></div>
    <div class="card-image"><a href="https://machinelearningmastery.com/exploding-gradients-in-neural-networks"><img src="https://machinelearningmastery.com/wp-content/uploads/2017/12/A-Gentle-Introduction-to-Exploding-Gradients-in-Recurrent-Neural-Networks.jpg" alt=""></a></div>
    <p class="card-excerpt">Exploding gradients are a problem where large error gradients accumulate and result in very large updates to neural network model weights during training. This has the effect of your model being unstable and unable to learn from your training data. In this post, you will discover the problem of exploding gradients with deep artificial neural networks. After completing this post,…</p>
  </div>
</div>
</body></html>
