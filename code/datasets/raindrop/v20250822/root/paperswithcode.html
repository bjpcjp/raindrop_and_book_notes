<html><head><meta charset="utf-8"><title>paperswithcode</title>
<style>.cards { display:block; }
.card {
  border: 1px solid #e2e2e2;
  border-radius: 12px;
  padding: 12px 14px;
  margin: 10px 0;
  box-shadow: 0 1px 2px rgba(0,0,0,0.04);
}
.card-title {
  margin: 0 0 6px 0;
  font-weight: 600;
  font-size: 1.05rem;
  line-height: 1.3;
}
.card-title a { text-decoration: none; }
.card-image { margin: 6px 0 8px 0; }
.card-image img { display:block; max-width:100%; height:auto; border-radius: 8px; }
.card-excerpt {
  margin: 0;
  font-size: .9rem;
  color: #444;
}
.nav {
  margin: 0 0 12px 0;
  font-size: .9rem;
}
.nav a { text-decoration: none; }
</style></head><body>
<div class="nav">⟵ <a href="index.html">Up</a> &nbsp;|&nbsp; <a href="index.html">Index</a></div>
<h1>paperswithcode</h1>
<div class="cards">
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4">How To Build an LLM-Powered App To Chat with PapersWithCode</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*0AW3FGe41K7h3E0p" alt=""></a></div>
    <p class="card-excerpt">Keep up with the latest ML research</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning">ArXiv.org Reaches a Milestone and a Reckoning</a></div>
    <div class="card-image"><a href="https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning"><img src="https://static.scientificamerican.com/sciam/cache/file/AFD5B975-B600-4C35-AA8B265090FFE58E_source.jpg?w=1200" alt=""></a></div>
    <p class="card-excerpt">Runaway success and underfunding have led to growing pains for the preprint server</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022">PyTorch vs TensorFlow in 2023</a></div>
    <div class="card-image"><a href="https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022"><img src="https://www.assemblyai.com/blog/content/images/size/w1200/2023/01/pytorch_vs_tensorflow_2023.png" alt=""></a></div>
    <p class="card-excerpt">Should you use PyTorch vs TensorFlow in 2023? This guide walks through the major pros and cons of PyTorch vs TensorFlow, and how you can pick the right framework.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://github.com/louisfb01/best_AI_papers_2021">louisfb01/best_AI_papers_2021: A curated list of the latest breakthroughs in AI (in 2021) by release date with a clear video explanation, link to a more in-depth article, and code.</a></div>
    <div class="card-image"><a href="https://github.com/louisfb01/best_AI_papers_2021"><img src="https://opengraph.githubassets.com/4ddf0f05bcc43ff97da72ed99caa033c5b6740257f8a08e1a985e8785441c523/louisfb01/best_AI_papers_2021" alt=""></a></div>
    <p class="card-excerpt">A  curated list of the latest breakthroughs in AI (in 2021) by release date with a clear video explanation, link to a more in-depth article, and code. - louisfb01/best_AI_papers_2021</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://towardsdatascience.com/four-deep-learning-papers-to-read-in-december-2021-e28f31e6aab4?source=rss----7f60cf5620c9---4">Four Deep Learning Papers to Read in December 2021</a></div>
    <div class="card-image"><a href="https://towardsdatascience.com/four-deep-learning-papers-to-read-in-december-2021-e28f31e6aab4?source=rss----7f60cf5620c9---4"><img src="https://miro.medium.com/v2/resize:fit:1200/1*Z5toROiPiwNvvpwOXywFoA.png" alt=""></a></div>
    <p class="card-excerpt">From Sensory Substitution to Decision Transformers, Persistent Evolution Strategies and Sharpness-Aware Minimization</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/newsletter">Papers with Code - Paper with Code Newsletter</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/newsletter"><img src="https://paperswithcode.com/static/logo.png" alt=""></a></div>
    <p class="card-excerpt">Papers With Code highlights trending Machine Learning research and the code to implement it.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/methods">The Methods Corpus | Papers With Code</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/methods"><img src="https://paperswithcode.com/static/methods.jpeg" alt=""></a></div>
    <p class="card-excerpt">2284 methods • 143838 papers with code.</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658">Papers with Code 2020 Review</a></div>
    <div class="card-image"><a href="https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658"><img src="https://miro.medium.com/v2/resize:fit:1200/1*rErHDsF_8dtSYWjs0rpcTQ.png" alt=""></a></div>
    <p class="card-excerpt">Papers with Code indexes various machine learning artifacts — papers, code, results — to facilitate discovery and comparison. Using this…</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/task/representation-learning">Methodology | Papers With Code</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/task/representation-learning"><img src="https://production-media.paperswithcode.com/tasks/representation-learning_Rkb0arA.jpeg" alt=""></a></div>
    <p class="card-excerpt">**Representation Learning**  is a process in machine learning where algorithms extract meaningful patterns from raw data to create representations that are easier to understand and process. These representations can be designed for interpretability, reveal hidden features, or be used for transfer learning. They are valuable across many fundamental machine learning tasks like [image classification](/task/image-classification) and [retrieval](/task/image-retrieval).  Deep neural networks can be considered representation learning models that typically encode information which is projected into a different subspace. These representations are then usually passed on to a linear classifier to, for instance, train a classifier.   Representation learning can be divided into:  -  **Supervised representation learning**: learning representations on task A using annotated data and used to solve task B - **Unsupervised representation learning**: learning representations on a task in an unsupervised way (label-free data). These are then used to address downstream tasks and reducing the need for annotated data when learning news tasks. Powerful models like [GPT](/method/gpt) and [BERT](/method/bert) leverage unsupervised representation learning to tackle language tasks.    More recently, [self-supervised learning (SSL)](/task/self-supervised-learning) is one of the main drivers behind unsupervised representation learning in fields like computer vision and NLP.   Here are some additional readings to go deeper on the task:  - [Representation Learning: A Review and New Perspectives](/paper/representation-learning-a-review-and-new) - Bengio et al. (2012) - [A Few Words on Representation Learning](https://sthalles.github.io/a-few-words-on-representation-learning/) - Thalles Silva  ( Image credit: [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf) )</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/task/image-retrieval">Computer Vision | Papers With Code</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/task/image-retrieval"><img src="https://production-media.paperswithcode.com/tasks/4f7e5080-e315-4357-9918-7169df9995db.png" alt=""></a></div>
    <p class="card-excerpt">**Image Retrieval** is a fundamental and long-standing computer vision task that involves finding images similar to a provided query from a large database. It's often considered as a form of fine-grained, instance-level classification. Not just integral to image recognition alongside [classification](/task/image-classification) and [detection](/task/image-detection), it also holds substantial business value by helping users discover images aligning with their interests or requirements, guided by visual similarity or other parameters.  ( Image credit: [DELF](https://github.com/tensorflow/models/tree/master/research/delf) )</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/task/denoising">Computer Vision | Papers With Code</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/task/denoising"><img src="https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-28_at_22.38.38_yCcs3qr.png" alt=""></a></div>
    <p class="card-excerpt">**Denoising** is a task in image processing and computer vision that aims to remove or reduce noise from an image. Noise can be introduced into an image due to various reasons, such as camera sensor limitations, lighting conditions, and compression artifacts. The goal of denoising is to recover the original image, which is considered to be noise-free, from a noisy observation.  ( Image credit: [Beyond a Gaussian Denoiser](https://arxiv.org/pdf/1608.03981v1.pdf) )</p>
  </div>
  <div class="card">
    <div class="card-title"><a href="https://paperswithcode.com/task/domain-adaptation">Computer Vision | Papers With Code</a></div>
    <div class="card-image"><a href="https://paperswithcode.com/task/domain-adaptation"><img src="https://production-media.paperswithcode.com/tasks/Webp.net-resizeimage_2_ioK1H9H.png" alt=""></a></div>
    <p class="card-excerpt">**Domain Adaptation** is the task of adapting models across domains. This is motivated by the challenge where the test and training datasets fall from different data distributions due to some factor. Domain adaptation aims to build machine learning models that can be generalized into a target domain and dealing with the discrepancy across domain distributions.   Further readings:  - [A Brief Review of Domain Adaptation](https://paperswithcode.com/paper/a-brief-review-of-domain-adaptation)  ( Image credit: [Unsupervised Image-to-Image Translation Networks](https://arxiv.org/pdf/1703.00848v6.pdf) )</p>
  </div>
</div>
</body></html>
