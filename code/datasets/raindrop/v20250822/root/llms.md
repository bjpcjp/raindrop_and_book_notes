<div class="nav">

⟵ [Up](index.html)  \|  [Index](index.html)

</div>

# llms

<div class="cards">

<div class="card">

<div class="card-title">

[Chatbot Arena (formerly LMSYS): Free AI Chat to Compare & Test Best AI
Chatbots](https://lmarena.ai/)

</div>

<div class="card-image">

[![](https://storage.googleapis.com/public-arena-asset/lmsys.jpg)](https://lmarena.ai/)

</div>

</div>

<div class="card">

<div class="card-title">

[Ollama commands: How to use Ollama in the command line \[Part
2\]](https://geshan.com.np/blog/2025/02/ollama-commands/)

</div>

<div class="card-image">

[![](https://geshan.com.np/images/ollama-commands/01ollama-commands.jpg)](https://geshan.com.np/blog/2025/02/ollama-commands/)

</div>

Learn about the important Ollama commands to run Ollama on your local
machine with Smollm2 and Qwen 2.5 models

</div>

<div class="card">

<div class="card-title">

[What is Ollama and how to use it: a quick guide \[part
1\]](https://geshan.com.np/blog/2025/02/what-is-ollama/)

</div>

<div class="card-image">

[![](https://geshan.com.np/images/what-is-ollama/01what-is-ollama.jpg)](https://geshan.com.np/blog/2025/02/what-is-ollama/)

</div>

Learn what Ollama is, its features and how to run it on your local
machine with DeepSeek R1 and Smollm2 models

</div>

<div class="card">

<div class="card-title">

[ollama APIs](https://geshan.com.np/blog/2025/02/ollama-api/)

</div>

<div class="card-image">

[![](https://geshan.com.np/images/ollama-api/01ollama-api.jpg)](https://geshan.com.np/blog/2025/02/ollama-api/)

</div>

Learn how to use Ollama APIs like generate, chat and more like list
model, pull model, etc with cURL and Jq with useful examples

</div>

<div class="card">

<div class="card-title">

[ollama with docker
compose](https://geshan.com.np/blog/2025/02/ollama-docker-compose/)

</div>

<div class="card-image">

[![](https://geshan.com.np/images/ollama-docker-compose/01ollama-docker-compose.jpg)](https://geshan.com.np/blog/2025/02/ollama-docker-compose/)

</div>

Learn how to use Ollama and Open WebUI inside Docker with Docker compose
to run any open LLM and create your own mini ChatGPT.

</div>

<div class="card">

<div class="card-title">

[ngafar/llama-scan: Transcribe PDFs with local
LLMs](https://github.com/ngafar/llama-scan)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/f7016f297dce503eb4904222bbdfb962ceb0e1e800f42fb30795657063161bba/ngafar/llama-scan)](https://github.com/ngafar/llama-scan)

</div>

Transcribe PDFs with local LLMs

</div>

<div class="card">

<div class="card-title">

[What is AI Inference? A Technical Deep Dive and Top 9 AI Inference
Providers (2025
Edition)](https://www.marktechpost.com/2025/08/17/what-is-ai-inference-a-technical-deep-dive-and-top-9-ai-inference-providers-2025-edition/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/08/a-digital-illustration-depicting-a-futur_kHJfZ0DdQFy84zMxLs-haQ_Q46Pe7dUTEOD6R6_oApdsQ.png)](https://www.marktechpost.com/2025/08/17/what-is-ai-inference-a-technical-deep-dive-and-top-9-ai-inference-providers-2025-edition/)

</div>

What is Artificial Intelligence AI Inference? A Technical Deep Dive and
Top 9 AI Inference Providers (2025 Edition)

</div>

<div class="card">

<div class="card-title">

[What Is AI Red Teaming? Top 18 AI Red Teaming Tools
(2025)](https://www.marktechpost.com/2025/08/17/what-is-ai-red-teaming-top-18-ai-red-teaming-tools-2025/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/08/a-futuristic-digital-art-poster-illustra_2cHW7BOFS8-GQ3WAnqSv7g_G5_b_kHJSM6ZSCzvGzkJHg.png)](https://www.marktechpost.com/2025/08/17/what-is-ai-red-teaming-top-18-ai-red-teaming-tools-2025/)

</div>

Discover top AI red teaming tools for robust AI security. Learn how
adversarial testing protects machine learning models

</div>

<div class="card">

<div class="card-title">

[The Timmy Trap – Scott Jenson](https://jenson.org/timmy/)

</div>

</div>

<div class="card">

<div class="card-title">

[That ‘cheap’ open-source AI model is actually burning through your
compute
budget](https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2025/08/nuneybits_Vector_art_of_dollar_bills_burning_blue_halftone_phot_64f22ade-4971-4234-822b-ba7dab7461de.webp?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/)

</div>

New research reveals open-source AI models use up to 10 times more
computing resources than closed alternatives, potentially negating cost
advantages for enterprise deployments.

</div>

<div class="card">

<div class="card-title">

[AI Model & API Providers Analysis \| Artificial
Analysis](https://artificialanalysis.ai/)

</div>

<div class="card-image">

[![](https://artificialanalysis.ai/img/open-graph/og-image.png)](https://artificialanalysis.ai/)

</div>

Comparison and analysis of AI models and API hosting providers.
Independent benchmarks across key performance metrics including quality,
price, output speed & latency.

</div>

<div class="card">

<div class="card-title">

[google/langextract: A Python library for extracting structured
information from unstructured text using LLMs with precise source
grounding and interactive
visualization.](https://github.com/google/langextract)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/198b1893e0a9faa86b2e32b94efb8e8d9f0e1027da73c36fc618f749f937ac9b/google/langextract)](https://github.com/google/langextract)

</div>

A Python library for extracting structured information from unstructured
text using LLMs with precise source grounding and interactive
visualization. - google/langextract

</div>

<div class="card">

<div class="card-title">

[From 100,000 to Under 500 Labels: How Google AI Cuts LLM Training Data
by Orders of
Magnitude](https://www.marktechpost.com/2025/08/10/from-100000-to-under-500-labels-how-google-ai-cuts-llm-training-data-by-orders-of-magnitude/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/08/CurationStrategies_ProcessHero.png)](https://www.marktechpost.com/2025/08/10/from-100000-to-under-500-labels-how-google-ai-cuts-llm-training-data-by-orders-of-magnitude/)

</div>

Google’s active learning method fine-tunes LLMs with 10,000x less data
using high-fidelity expert-labeled examples

</div>

<div class="card">

<div class="card-title">

[LLM Embeddings Explained: A Visual and Intuitive
Guide](https://huggingface.co/spaces/hesamation/primer-llm-embedding)

</div>

<div class="card-image">

[![](https://cdn-uploads.huggingface.co/production/uploads/647f805de9c81260ff8881ee/8v52lNo2sFtNySUlVnXF4.png)](https://huggingface.co/spaces/hesamation/primer-llm-embedding)

</div>

How Language Models Turn Text into Meaning, From Traditional

</div>

<div class="card">

<div class="card-title">

[New ‘persona vectors’ from Anthropic let you decode and direct an LLM’s
personality](https://venturebeat.com/ai/new-persona-vectors-from-anthropic-let-you-decode-and-direct-an-llms-personality/)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2025/08/model-behavior.jpg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/new-persona-vectors-from-anthropic-let-you-decode-and-direct-an-llms-personality/)

</div>

A new study from Anthropic introduces "persona vectors," a technique for
developers to monitor, predict and control unwanted LLM behaviors.

</div>

<div class="card">

<div class="card-title">

[A Technical Roadmap to Context Engineering in LLMs: Mechanisms,
Benchmarks, and Open
Challenges](https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.21.48-PM.png)](https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/)

</div>

Context engineering for large language models—frameworks, architectures,
and strategies to optimize AI reasoning, and scalability

</div>

<div class="card">

<div class="card-title">

[Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2506.21734)

</div>

Reasoning, the process of devising and executing complex goal-oriented
action sequences, remains a critical challenge in AI. Current large
language models (LLMs) primarily employ Chain-of-Thought (CoT)
techniques, which suffer from brittle task decomposition, extensive data
requirements, and high latency. Inspired by the hierarchical and
multi-timescale processing in the human brain, we propose the
Hierarchical Reasoning Model (HRM), a novel recurrent architecture that
attains significant computational depth while maintaining both training
stability and efficiency. HRM executes sequential reasoning tasks in a
single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level
module responsible for slow, abstract planning, and a low-level module
handling rapid, detailed computations. With only 27 million parameters,
HRM achieves exceptional performance on complex reasoning tasks using
only 1000 training samples. The model operates without pre-training or
CoT data, yet achieves nearly perfect performance on challenging tasks
including complex Sudoku puzzles and optimal path finding in large
mazes. Furthermore, HRM outperforms much larger models with
significantly longer context windows on the Abstraction and Reasoning
Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and
general-purpose reasoning systems.

</div>

<div class="card">

<div class="card-title">

[The Complete LLM Tech
Stack](https://amanxai.com/2025/07/25/the-complete-llm-tech-stack/)

</div>

<div class="card-image">

[![](https://i0.wp.com/amanxai.com/wp-content/uploads/2025/07/The-Complete-LLM-Tech-Stack-You-Should-Know.png?fit=2436%2C1200&ssl=1)](https://amanxai.com/2025/07/25/the-complete-llm-tech-stack/)

</div>

In this article, I'll take you through the complete LLM tech stack you
should know to develop & deploy real-world LLM applications.

</div>

<div class="card">

<div class="card-title">

[How OpenAI’s red team made ChatGPT agent into an AI
fortress](https://venturebeat.com/security/openais-red-team-plan-make-chatgpt-agent-an-ai-fortress/)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2025/07/hero-image.jpg?w=624?w=1200&strip=all)](https://venturebeat.com/security/openais-red-team-plan-make-chatgpt-agent-an-ai-fortress/)

</div>

Discover OpenAI's red team blueprint: How 110 coordinated attacks and 7
exploit fixes created ChatGPT Agent's revolutionary 95% security defense
system.

</div>

<div class="card">

<div class="card-title">

[Shirin Khosravi Jam on
Substack](https://substack.com/@shirinkjam/note/c-133160958?r=oc5d&utm_medium=ios&utm_source=notes-share-action)

</div>

<div class="card-image">

[![](https://substack-post-media.s3.amazonaws.com/public/images/1abc67af-38cf-4cdc-bd70-3d897e8cac30_1200x1599.jpeg)](https://substack.com/@shirinkjam/note/c-133160958?r=oc5d&utm_medium=ios&utm_source=notes-share-action)

</div>

I taught myself how to build RAG + AI Agents in production. Been running
them live for over a year now. Here are 4 steps + the only resources you
really need to do the same. … Ugly truth: most “AI Engineers” shouting
on social media haven’t built a single real production AI Agent or RAG
system. If you want to be different - actually build and ship these
systems: here’s a laser-focused roadmap from my own journey. .. 🚀 𝗦𝘁𝗮𝗿𝘁
𝘄𝗶𝘁𝗵 𝗳𝘂𝗻𝗱𝗮𝗺𝗲𝗻𝘁𝗮𝗹𝘀 Because no matter how fast LLM/GenAI evolves, your ML
& software foundations keep you relevant. ✅ Hands-On ML with TensorFlow
& Keras: https://lnkd.in/dWrf5pbS ✅ ISLR: https://lnkd.in/djGPVVwJ ✅
Machine Learning for Beginners by Microsoft (free curriculum):
https://lnkd.in/d8kZA3es … 1️⃣ 𝗠𝗮𝘀𝘁𝗲𝗿 𝗟𝗟𝗠𝘀 & 𝗚𝗲𝗻𝗔𝗜 𝗦𝘆𝘀𝘁𝗲𝗺𝘀 → Learn to
build & deploy LLMs, understand system design tradeoffs, and handle real
constraints. 📚 Must-reads: ✅ Designing ML Systems – Chip Huyen:
https://lnkd.in/guN-UhXA ✅ The LLM Engineering Handbook – Iusztin &
Labonne: https://lnkd.in/gyA4vFXz ✅ Build a LLM (From Scratch) –
Raschka: https://lnkd.in/gXNa-SPb ✅ Hands-On LLMs GitHub:
https://lnkd.in/eV4qrgNW … 2️⃣ 𝗚𝗼 𝗯𝗲𝘆𝗼𝗻𝗱 𝘁𝗵𝗲 𝗵𝘆𝗽𝗲 𝗼𝗻 𝗔𝗜 𝗔𝗴𝗲𝗻𝘁𝘀 → Most
demos = “if user says hello, return hello.” Actual agents? Handle
memory, tools, workflows, costs. ✅ AI Agents for Beginners (GitHub):
https://lnkd.in/eik2btmq ✅ GenAI Agents – build step by step:
https://lnkd.in/dnhwk75V ✅ OpenAI’s guide to agents:
https://lnkd.in/guRfXsFK ✅ Anthropic’s Building Effective Agents:
https://lnkd.in/gRWKANS4 … 3️⃣ 𝗥𝗔𝗚 𝗶𝘀 𝗻𝗼𝘁 𝗷𝘂𝘀𝘁 𝗮 𝘃𝗲𝗰𝘁𝗼𝗿 𝗗𝗕 Real
Retrieval-Augmented Generation requires: → Chunking, hybrid BM25 +
vectors, reranking → Query routing & fallback → Evaluating retrieval
quality, not just LLM output ✅ RAG Techniques repo:
https://lnkd.in/dD4S8Cq2 ✅ Advanced RAG: https://lnkd.in/g2ZHwZ3w ✅
Cost-efficient retrieval with Postgres/OpenSearch/Qdrant ✅ Monitoring
with Langfuse / Comet … 4️⃣ 𝗚𝗲𝘁 𝘀𝗲𝗿𝗶𝗼𝘂𝘀 𝗼𝗻 𝗦𝗼𝗳𝘁𝘄𝗮𝗿𝗲 & 𝗜𝗻𝗳𝗿𝗮 → FastAPI,
async Python, Pydantic → Docker, CI/CD, blue-green deploys → ETL
orchestration (Airflow, Step Functions) → Logs + metrics (CloudWatch,
Prometheus) ✅ Move to production: https://lnkd.in/dnnkrJbE ✅ Made with
ML (full ML+infra): https://lnkd.in/e-XQwXqS ✅ AWS GenAI path:
https://lnkd.in/dmhR3uPc … 5️⃣ 𝗪𝗵𝗲𝗿𝗲 𝗱𝗼 𝗜 𝗹𝗲𝗮𝗿𝗻 𝗳𝗿𝗼𝗺? → Stanford CS336 /
CS236 / CS229 (Google it) → MIT 6.S191, Karpathy’s Zero to Hero:
https://lnkd.in/dT7vqqQ5 → Google Kaggle GenAI sprint:
https://lnkd.in/ga5X7tVJ → NVIDIA’s end-to-end LLM stack:
https://lnkd.in/gCtDnhni → DeepLearning.AI’s short courses:
https://lnkd.in/gAYmJqS6 … 💥 𝗞𝗲𝗲𝗽 𝗶𝘁 𝗿𝗲𝗮𝗹: Don’t fall for “built in 5
min, dead in 10 min” demos. In prod, it’s about latency, cost,
maintainability, guardrails. ♻️ Let's repost to help more people on this
journey 💚

</div>

<div class="card">

<div class="card-title">

[Gemini
CLI](https://simonwillison.net/2025/Jun/25/gemini-cli/#atom-everything)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/gemini-cli-card.jpg)](https://simonwillison.net/2025/Jun/25/gemini-cli/#atom-everything)

</div>

First there was Claude Code in February, then OpenAI Codex (CLI) in
April, and now Gemini CLI in June. All three of the largest AI labs now
have their own …

</div>

<div class="card">

<div class="card-title">

[Usage](https://llm.datasette.io/en/stable/usage.html?utm_source=substack&utm_medium=email)

</div>

</div>

<div class="card">

<div class="card-title">

[ChatGPT agent System Card \|
OpenAI](https://openai.com/index/chatgpt-agent-system-card/)

</div>

<div class="card-image">

[![](https://images.ctfassets.net/kftzwdyauwt9/4MBcZnnZGYlsr4Ev1eHT9j/a8556ef6251e5a968dd00ade958f1192/Agent_System_Card_SEO_Image.png?w=1600&h=900&fit=fill)](https://openai.com/index/chatgpt-agent-system-card/)

</div>

ChatGPT agent System Card: OpenAI’s agentic model unites research,
browser automation, and code tools with safeguards under the
Preparedness Framework.

</div>

<div class="card">

<div class="card-title">

[I sent ChatGPT Agent out to shop for
me](https://www.theverge.com/ai-artificial-intelligence/710020/openai-review-test-new-release-chatgpt-agent-operator-deep-research-pro-200-subscription)

</div>

<div class="card-image">

[![](https://platform.theverge.com/wp-content/uploads/sites/2/2025/07/chatgptagent.jpg?quality=90&strip=all&crop=0%2C10.722908076692%2C100%2C78.554183846616&w=1200)](https://www.theverge.com/ai-artificial-intelligence/710020/openai-review-test-new-release-chatgpt-agent-operator-deep-research-pro-200-subscription)

</div>

We tested OpenAI’s ChatGPT Agent, currently only available via its
\$200-per-month Pro subscription.

</div>

<div class="card">

<div class="card-title">

[LLM Research Papers: The 2025 List (January to
June)](https://sebastianraschka.com/blog/2025/llm-research-papers-the-2025-list-january-to-june.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/llm-research-papers-the-2025-list-january-to-june/hero.jpeg)](https://sebastianraschka.com/blog/2025/llm-research-papers-the-2025-list-january-to-june.html)

</div>

The latest in LLM research with a hand-curated, topic-organized list of
over 200 research papers from 2025.

</div>

<div class="card">

<div class="card-title">

[Become a command-line superhero with Simon Willison’s llm
tool](https://simonwillison.net/2025/Jul/7/become-a-command-line-superhero-with-simon-willisons-llm-tool/#atom-everything)

</div>

<div class="card-image">

[![](https://simonwillison.net/card/2025/Jul/7/become-a-command-line-superhero-with-simon-willisons-llm-tool/)](https://simonwillison.net/2025/Jul/7/become-a-command-line-superhero-with-simon-willisons-llm-tool/#atom-everything)

</div>

Christopher Smith ran a mini hackathon in Albany New York at the weekend
around uses of my LLM - the first in-person event I'm aware of dedicated
to that project! …

</div>

<div class="card">

<div class="card-title">

[🔍 Perplexity 101: Ultimate Guide to Deep Search, Labs, Templates & 53
Pro
Prompts](https://sidsaladi.substack.com/p/perplexity-101-ultimate-guide-to)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/$s_!iGr0!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676afdba-22cb-4812-a8a8-d13ede1e5365_3000x2250.jpeg)](https://sidsaladi.substack.com/p/perplexity-101-ultimate-guide-to)

</div>

Your complete playbook for transforming how you research with AI's most
powerful search engine

</div>

<div class="card">

<div class="card-title">

[Introduction \| LLM Inference in Production](https://bentoml.com/llm/)

</div>

<div class="card-image">

[![](https://bentoml.com/llm/img/handbook-cover-image.png)](https://bentoml.com/llm/)

</div>

A practical handbook for engineers building, optimizing, scaling and
operating LLM inference systems in production.

</div>

<div class="card">

<div class="card-title">

[Emergent Price-Fixing by LLM Auction
Agents](https://www.lesswrong.com/posts/yqhy3zBmpeFuGFLxX/emergent-price-fixing-by-llm-auction-agents)

</div>

<div class="card-image">

[![](https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg)](https://www.lesswrong.com/posts/yqhy3zBmpeFuGFLxX/emergent-price-fixing-by-llm-auction-agents)

</div>

An inquiry into emergent collusion in Large Language Models. Agent S2 to
Agent S3: “Let's set all asks at 63 next cycle… No undercutting ensur…

</div>

<div class="card">

<div class="card-title">

[Inside India’s scramble for AI
independence](https://www.technologyreview.com/2025/07/04/1119705/inside-indias-scramble-for-ai-independence/)

</div>

<div class="card-image">

[![](https://wp.technologyreview.com/wp-content/uploads/2025/07/india-ai-sovreignity-c.jpg?resize=854,569)](https://www.technologyreview.com/2025/07/04/1119705/inside-indias-scramble-for-ai-independence/)

</div>

Structural challenges and the nation’s many languages have made it tough
to develop foundational AI models. But the government is keen not to be
left behind.

</div>

<div class="card">

<div class="card-title">

[Coders' Colaboratory mini-hackathon on \`llm\` by
simonw](https://gist.github.com/chriscarrollsmith/4670b8466e19e77723327cb555f638e6)

</div>

<div class="card-image">

[![](https://github.githubassets.com/assets/gist-og-image-54fd7dc0713e.png)](https://gist.github.com/chriscarrollsmith/4670b8466e19e77723327cb555f638e6)

</div>

Coders' Colaboratory mini-hackathon on \`llm\` by simonw -
llm-hackathon.md

</div>

<div class="card">

<div class="card-title">

[What is Ollama? Running Local LLMs Made
Simple](https://www.youtube.com/watch?v=5RIOQuHOihY)

</div>

<div class="card-image">

[![](https://i.ytimg.com/vi/5RIOQuHOihY/maxresdefault.jpg)](https://www.youtube.com/watch?v=5RIOQuHOihY)

</div>

Ready to become a certified watsonx AI Assistant Engineer? Register now
and use code IBMTechYT20 for 20% off of your exam →
https://ibm.biz/Bdnd3dLearn more ...

</div>

<div class="card">

<div class="card-title">

[Building software on top of Large Language
Models](https://simonwillison.net/2025/May/15/building-on-llms/)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/building-apps-on-llms/llm-tutorial-intro.001.jpeg)](https://simonwillison.net/2025/May/15/building-on-llms/)

</div>

I presented a three hour workshop at PyCon US yesterday titled Building
software on top of Large Language Models. The goal of the workshop was
to give participants everything they …

</div>

<div class="card">

<div class="card-title">

[Large Language Models can run tools in your terminal with LLM
0.26](https://simonwillison.net/2025/May/27/llm-tools/#atom-everything)

</div>

LLM 0.26 is out with the biggest new feature since I started the
project: support for tools. You can now use the LLM CLI tool—and Python
library—to grant LLMs from …

</div>

<div class="card">

<div class="card-title">

[Getting started with Gemini Command Line Interface
(CLI)](https://www.marktechpost.com/2025/06/28/getting-started-with-gemini-command-line-interface-cli/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/06/Screenshot-2025-06-28-at-1.12.52%E2%80%AFPM.png)](https://www.marktechpost.com/2025/06/28/getting-started-with-gemini-command-line-interface-cli/)

</div>

</div>

<div class="card">

<div class="card-title">

[7 Popular LLMs Explained in 7 Minutes -
KDnuggets](https://www.kdnuggets.com/7-popular-llms-explained-in-7-minutes)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/kdn-mehreen-7-llms-explained-7-minutes.png)](https://www.kdnuggets.com/7-popular-llms-explained-in-7-minutes)

</div>

Get a quick overview of GPT, BERT, LLaMA, and more!

</div>

<div class="card">

<div class="card-title">

[why AI language models like chatGPT can’t understand
flowers](https://www.designboom.com/technology/ai-language-models-chatgpt-gemini-understand-flowers-ohio-state-university-06-04-2025/)

</div>

<div class="card-image">

[![](https://www.designboom.com/wp-content/uploads/2025/06/AI-language-models-chatGPT-gemini-flowers-designboom-1.jpg)](https://www.designboom.com/technology/ai-language-models-chatgpt-gemini-understand-flowers-ohio-state-university-06-04-2025/)

</div>

a study by ohio state university investigates whether large language
models can represent human concepts without physically experiencing
them.

</div>

<div class="card">

<div class="card-title">

[What I learned trying seven coding
agents](https://www.understandingai.org/p/what-i-learned-trying-seven-coding)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/$s_!JUwd!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc40039-abfd-4a4e-9562-9c92a0b4fcfa_4032x2688.jpeg)](https://www.understandingai.org/p/what-i-learned-trying-seven-coding)

</div>

There's still room for improvement, but don't underestimate this
technology.

</div>

<div class="card">

<div class="card-title">

[Building Effective AI
Agents](https://www.anthropic.com/engineering/building-effective-agents)

</div>

<div class="card-image">

[![](https://cdn.sanity.io/images/4zrzovbb/website/76b5733c669f0dfb9c7aa7fc512a495867cf12e6-2400x1260.png)](https://www.anthropic.com/engineering/building-effective-agents)

</div>

Discover how Anthropic approaches the development of reliable AI agents.
Learn about our research on agent capabilities, safety considerations,
and technical framework for building trustworthy AI.

</div>

<div class="card">

<div class="card-title">

[32 MCP Servers You Need To Check Out Now -
KDnuggets](https://www.kdnuggets.com/32-mcp-servers-you-need-to-check-out-now)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/awan_top_30_mcp_servers_missing_1.png)](https://www.kdnuggets.com/32-mcp-servers-you-need-to-check-out-now)

</div>

Explore list of top MCP servers that enable seamless integration of LLMs
with tools like databases, APIs, communication platforms, and more,
helping you automate workflows and enhance AI applications.

</div>

<div class="card">

<div class="card-title">

[Highlights from the Claude 4 system
prompt](https://simonwillison.net/2025/May/25/claude-4-system-prompt/)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/opus-sonnet-diff.jpg)](https://simonwillison.net/2025/May/25/claude-4-system-prompt/)

</div>

Anthropic publish most of the system prompts for their chat models as
part of their release notes. They recently shared the new prompts for
both Claude Opus 4 and Claude …

</div>

<div class="card">

<div class="card-title">

[System Card: Claude Opus 4 & Claude Sonnet
4](https://simonwillison.net/2025/May/25/claude-4-system-card/)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/claude-social-bliss.jpg)](https://simonwillison.net/2025/May/25/claude-4-system-card/)

</div>

Direct link to a PDF on Anthropic's CDN because they don't appear to
have a landing page anywhere for this document. Anthropic's system cards
are always worth a look, and …

</div>

<div class="card">

<div class="card-title">

[The Ultimate Guide to Learning Anything with NotebookLM -
KDnuggets](https://www.kdnuggets.com/the-ultimate-guide-to-learning-anything-with-notebooklm)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/cover_photo.jpeg)](https://www.kdnuggets.com/the-ultimate-guide-to-learning-anything-with-notebooklm)

</div>

Learn about turning your notes and sources into a personalized,
AI-powered tutor with NotebookLM.

</div>

<div class="card">

<div class="card-title">

[llm-anthropic
0.16](https://simonwillison.net/2025/May/22/llm-anthropic-016/#atom-everything)

</div>

New release of my LLM plugin for Anthropic adding the new Claude 4 Opus
and Sonnet models. You can see pelicans on bicycles generated using the
new plugin at the …

</div>

<div class="card">

<div class="card-title">

[Insights into DeepSeek-V3: Scaling Challenges and Reflections on
Hardware for AI Architectures \|
alphaXiv](https://www.alphaxiv.org/abs/2505.09343)

</div>

<div class="card-image">

[![](https://paper-assets.alphaxiv.org/image/2505.09343v1.png)](https://www.alphaxiv.org/abs/2505.09343)

</div>

View recent discussion. Abstract: The rapid scaling of large language
models (LLMs) has unveiled critical limitations in current hardware
architectures, including constraints in memory capacity, computational
efficiency, and interconnection bandwidth. DeepSeek-V3, trained on 2,048
NVIDIA H800 GPUs, demonstrates how hardware-aware model co-design can
effectively address these challenges, enabling cost-efficient training
and inference at scale. This paper presents an in-depth analysis of the
DeepSeek-V3/R1 model architecture and its AI infrastructure,
highlighting key innovations such as Multi-head Latent Attention (MLA)
for enhanced memory efficiency, Mixture of Experts (MoE) architectures
for optimized computation-communication trade-offs, FP8 mixed-precision
training to unlock the full potential of hardware capabilities, and a
Multi-Plane Network Topology to minimize cluster-level network overhead.
Building on the hardware bottlenecks encountered during DeepSeek-V3's
development, we engage in a broader discussion with academic and
industry peers on potential future hardware directions, including
precise low-precision computation units, scale-up and scale-out
convergence, and innovations in low-latency communication fabrics. These
insights underscore the critical role of hardware and model co-design in
meeting the escalating demands of AI workloads, offering a practical
blueprint for innovation in next-generation AI systems.

</div>

<div class="card">

<div class="card-title">

[Meta Introduces KernelLLM: An 8B LLM that Translates PyTorch Modules
into Efficient Triton GPU
Kernels](https://www.marktechpost.com/2025/05/20/meta-introduces-kernelllm-an-8b-llm-that-translates-pytorch-modules-into-efficient-triton-gpu-kernels/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/05/llm_performance_comparison-scaled.png)](https://www.marktechpost.com/2025/05/20/meta-introduces-kernelllm-an-8b-llm-that-translates-pytorch-modules-into-efficient-triton-gpu-kernels/)

</div>

</div>

<div class="card">

<div class="card-title">

[Building AI Agents? A2A vs. MCP Explained Simply -
KDnuggets](https://www.kdnuggets.com/building-ai-agents-a2a-vs-mcp-explained-simply)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/Building-AI-Agents-A2A-vs.-MCP-Explained-Simply.png)](https://www.kdnuggets.com/building-ai-agents-a2a-vs-mcp-explained-simply)

</div>

Confused by AI agent frameworks? This article makes sense of A2A and
MCP.

</div>

<div class="card">

<div class="card-title">

[mendableai/firecrawl: 🔥 Turn entire websites into LLM-ready markdown
or structured data. Scrape, crawl and extract with a single
API.](https://github.com/mendableai/firecrawl)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/ec5c8370b1c6cf9e156235583592eaee1b7b9ba07fade23af876778e255ace6d/mendableai/firecrawl)](https://github.com/mendableai/firecrawl)

</div>

🔥 Turn entire websites into LLM-ready markdown or structured data.
Scrape, crawl and extract with a single API. - mendableai/firecrawl

</div>

<div class="card">

<div class="card-title">

[Alibaba’s Qwen3 topples DeepSeek’s R1 as world’s highest-ranked
open-source AI
model](https://www.scmp.com/tech/tech-trends/article/3309298/alibabas-qwen3-topples-deepseeks-r1-worlds-highest-ranked-open-source-ai-model?utm_source=feedly_feed)

</div>

<div class="card-image">

[![](https://cdn.i-scmp.com/sites/default/files/styles/og_image_scmp_generic/public/d8/images/canvas/2025/05/06/2ae3cc07-8aac-4a86-bd1b-da62b9cbf94b_4f2fd00a.jpg?itok=zWIAmbHa&v=1746532811)](https://www.scmp.com/tech/tech-trends/article/3309298/alibabas-qwen3-topples-deepseeks-r1-worlds-highest-ranked-open-source-ai-model?utm_source=feedly_feed)

</div>

Qwen3 surpassed R1 in LiveBench tests that gauge open-source AI models’
capabilities including coding, maths and data analysis.

</div>

<div class="card">

<div class="card-title">

[22365_3_Prompt Engineering_v7
(1).pdf](https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view)

</div>

</div>

<div class="card">

<div class="card-title">

[Prompt Engineering \|
Kaggle](https://www.kaggle.com/whitepaper-prompt-engineering)

</div>

<div class="card-image">

[![](https://www.kaggle.com/static/images/logos/kaggle-logo-opengraph.png)](https://www.kaggle.com/whitepaper-prompt-engineering)

</div>

Kaggle is the world’s largest data science community with powerful tools
and resources to help you achieve your data science goals.

</div>

<div class="card">

<div class="card-title">

[Introducing 4o Image
Generation](https://openai.com/index/introducing-4o-image-generation)

</div>

<div class="card-image">

[![](https://images.ctfassets.net/kftzwdyauwt9/7c9f18hYL29IcnVw1Gl2xN/e8f302e2cc7cd012a93c78043dfbd5b0/oai_image-generation_seo.png?w=1600&h=900&fit=fill)](https://openai.com/index/introducing-4o-image-generation)

</div>

At OpenAI, we have long believed image generation should be a primary
capability of our language models. That’s why we’ve built our most
advanced image generator yet into GPT‑4o. The result—image generation
that is not only beautiful, but useful.

</div>

<div class="card">

<div class="card-title">

[Putting Gemini 2.5 Pro through its
paces](https://simonwillison.net/2025/Mar/25/gemini/)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/gemini-pelicans-bbox.jpg)](https://simonwillison.net/2025/Mar/25/gemini/)

</div>

There’s a new release from Google Gemini this morning: the first in the
Gemini 2.5 series. Google call it “a thinking model, designed to tackle
increasingly complex problems”. It’s already …

</div>

<div class="card">

<div class="card-title">

[How To Build An Agent \|
Amp](https://ampcode.com/how-to-build-an-agent)

</div>

<div class="card-image">

[![](https://ampcode.com/og-how-to-build-an-agent.jpg)](https://ampcode.com/how-to-build-an-agent)

</div>

Building a fully functional, code-editing agent in less than 400 lines.

</div>

<div class="card">

<div class="card-title">

[DeepSeek R2 AI Model Rumors Begin to Swirl Online; Reported to Feature
97% Lower Costs Compared to
GPT-4…](https://wccftech.com/deepseek-r2-ai-model-rumors-begin-to-swirl-online/)

</div>

<div class="card-image">

[![](https://cdn.wccftech.com/wp-content/uploads/2025/04/DeepSeek-2.jpg)](https://wccftech.com/deepseek-r2-ai-model-rumors-begin-to-swirl-online/)

</div>

DeepSeek is set to drop another model pretty soon, as details about
their next DeepSeek R2 model have surfaced on the internet

</div>

<div class="card">

<div class="card-title">

[XiaomiMiMo/MiMo: MiMo: Unlocking the Reasoning Potential of Language
Model – From Pretraining to
Posttraining](https://github.com/XiaomiMiMo/MiMo)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/fb08ce94b0e0c8e759a908b39e9c9553d09e88b112b5f752ae10934db8c5233c/XiaomiMiMo/MiMo)](https://github.com/XiaomiMiMo/MiMo)

</div>

MiMo: Unlocking the Reasoning Potential of Language Model – From
Pretraining to Posttraining - XiaomiMiMo/MiMo

</div>

<div class="card">

<div class="card-title">

[LLM Projects with
Python](https://thecleverprogrammer.com/2025/05/03/llm-projects-with-python/)

</div>

<div class="card-image">

[![](https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2025/05/10-Projects-to-Master-LLMs-with-Python.png?fit=1200%2C628&ssl=1)](https://thecleverprogrammer.com/2025/05/03/llm-projects-with-python/)

</div>

In this article, I'll take you through a list of 10 hands-on LLM
projects with Python you should try to master LLMs. LLM Projects with
Python.

</div>

<div class="card">

<div class="card-title">

[Creating an MCP Server Using
Go](https://eltonminetto.dev/en/post/2025-05-01-mcp-server-golang/)

</div>

In November 2024, Anthropic published a blog post announcing what may be
its most significant contribution to the AI ecosystem so far: the Model
Context Protocol.

</div>

<div class="card">

<div class="card-title">

[Physics of Language Models: Part 4.1, Architecture Design and the Magic
of Canon
Layers](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5240330)

</div>

<div class="card-image">

[![](https://cdn.ssrn.com/ssrn-global-header/11589acb53bc518aa22929bf19add113.svg)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5240330)

</div>

Understanding architectural differences between large language models
(LLMs) remains challenging, particularly at academic-scale pretraining
(e.g., 1.3B

</div>

<div class="card">

<div class="card-title">

[Dummy’s Guide to Modern LLM
Sampling](https://simonwillison.net/2025/May/4/llm-sampling/#atom-everything)

</div>

This is an extremely useful, detailed set of explanations by
\[@AlpinDale\](https://x.com/AlpinDale) covering the various different
sampling strategies used by modern LLMs. LLMs return a set of next-token
probabilities for every …

</div>

<div class="card">

<div class="card-title">

[The Leaderboard Illusion](https://arxiv.org/abs/2504.20879)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2504.20879)

</div>

Measuring progress is fundamental to the advancement of any scientific
field. As benchmarks play an increasingly central role, they also grow
more susceptible to distortion. Chatbot Arena has emerged as the go-to
leaderboard for ranking the most capable AI systems. Yet, in this work
we identify systematic issues that have resulted in a distorted playing
field. We find that undisclosed private testing practices benefit a
handful of providers who are able to test multiple variants before
public release and retract scores if desired. We establish that the
ability of these providers to choose the best score leads to biased
Arena scores due to selective disclosure of performance results. At an
extreme, we identify 27 private LLM variants tested by Meta in the
lead-up to the Llama-4 release. We also establish that proprietary
closed models are sampled at higher rates (number of battles) and have
fewer models removed from the arena than open-weight and open-source
alternatives. Both these policies lead to large data access asymmetries
over time. Providers like Google and OpenAI have received an estimated
19.2% and 20.4% of all data on the arena, respectively. In contrast, a
combined 83 open-weight models have only received an estimated 29.7% of
the total data. We show that access to Chatbot Arena data yields
substantial benefits; even limited additional data can result in
relative performance gains of up to 112% on the arena distribution,
based on our conservative estimates. Together, these dynamics result in
overfitting to Arena-specific dynamics rather than general model
quality. The Arena builds on the substantial efforts of both the
organizers and an open community that maintains this valuable evaluation
platform. We offer actionable recommendations to reform the Chatbot
Arena's evaluation framework and promote fairer, more transparent
benchmarking for the field

</div>

<div class="card">

<div class="card-title">

[Topic 33: Slim Attention, KArAt, XAttention and Multi-Token Attention
Explained – What’s Really Changing in
Transformers?](https://huggingface.co/blog/Kseniase/attentions?fbclid=IwY2xjawJgrQhleHRuA2FlbQIxMQABHjZ2_OJkyTAVEb-K0wkUoq4VLTCrgIWQ4125yvu1GyuwHh6iHTCmJVAMstBF_aem_advNV4bDfVovH5jPMetwpQ)

</div>

<div class="card-image">

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/blog/Kseniase/attentions.png)](https://huggingface.co/blog/Kseniase/attentions?fbclid=IwY2xjawJgrQhleHRuA2FlbQIxMQABHjZ2_OJkyTAVEb-K0wkUoq4VLTCrgIWQ4125yvu1GyuwHh6iHTCmJVAMstBF_aem_advNV4bDfVovH5jPMetwpQ)

</div>

A Blog post by Ksenia Se on Hugging Face

</div>

<div class="card">

<div class="card-title">

[Model Context Protocol (MCP) an
overview](https://www.philschmid.de/mcp-introduction)

</div>

<div class="card-image">

[![](https://www.philschmid.de/static/blog/mcp-introduction/thumbnail.jpg)](https://www.philschmid.de/mcp-introduction)

</div>

Overview of the Model Context Protocol (MCP) how it works, what are MCP
servers and clients, and how to use it.

</div>

<div class="card">

<div class="card-title">

[An LLM Query Understanding
Service](https://simonwillison.net/2025/Apr/9/an-llm-query-understanding-service/#atom-everything)

</div>

Doug Turnbull recently wrote about how \[all search is structured
now\](https://softwaredoug.com/blog/2025/04/02/all-search-structured-now):
Many times, even a small open source LLM will be able to turn a search
query into reasonable …

</div>

<div class="card">

<div class="card-title">

[A Code Implementation to Building a Context-Aware AI Assistant in
Google Colab Using LangChain, LangGraph, Gemini Pro, and Model Context
Protocol (MCP) Principles with Tool Integration
Support](https://www.marktechpost.com/2025/04/04/a-code-implementation-to-building-a-context-aware-ai-assistant-in-google-colab-using-langchain-langgraph-gemini-pro-and-model-context-protocol-mcp-principles-with-tool-integration-support/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/04/Screenshot-2025-04-04-at-10.45.12%E2%80%AFPM.png)](https://www.marktechpost.com/2025/04/04/a-code-implementation-to-building-a-context-aware-ai-assistant-in-google-colab-using-langchain-langgraph-gemini-pro-and-model-context-protocol-mcp-principles-with-tool-integration-support/)

</div>

</div>

<div class="card">

<div class="card-title">

[To Make Language Models Work Better, Researchers Sidestep Language \|
Quanta
Magazine](https://www.quantamagazine.org/to-make-language-models-work-better-researchers-sidestep-language-20250414/)

</div>

<div class="card-image">

[![](https://www.quantamagazine.org/wp-content/uploads/2025/04/LLMNativeLanguage-crMyriamWares-Social.jpg)](https://www.quantamagazine.org/to-make-language-models-work-better-researchers-sidestep-language-20250414/)

</div>

We insist that large language models repeatedly translate their
mathematical processes into words. There may be a better way.

</div>

<div class="card">

<div class="card-title">

[The State of Reinforcement Learning for LLM
Reasoning](https://sebastianraschka.com/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning/hero.jpg)](https://sebastianraschka.com/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning.html)

</div>

A lot has happened this month, especially with the releases of new
flagship models like GPT-4.5 and Llama 4. But you might have noticed
that reactions to these releases were relatively muted. Why? One reason
could be that GPT-4.5 and Llama 4 remain conventional models, which
means they were trained without explicit reinforcement learning for
reasoning. However, OpenAI's recent release of the o3 reasoning model
demonstrates there is still considerable room for improvement when
investing compute strategically, specifically via reinforcement learning
methods tailored for reasoning tasks. While reasoning alone isn't a
silver bullet, it reliably improves model accuracy and problem-solving
capabilities on challenging tasks (so far). And I expect
reasoning-focused post-training to become standard practice in future
LLM pipelines. So, in this article, let's explore the latest
developments in reasoning via reinforcement learning.

</div>

<div class="card">

<div class="card-title">

[First Look at Reasoning From Scratch: Chapter
1](https://sebastianraschka.com/blog/2025/first-look-at-reasoning-from-scratch.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/first-look-at-reasoning-from-scratch/hero.jpg)](https://sebastianraschka.com/blog/2025/first-look-at-reasoning-from-scratch.html)

</div>

As you know, I've been writing a lot lately about the latest research on
reasoning in LLMs. Before my next research-focused blog post, I wanted
to offer something special to my paid subscribers as a thank-you for
your ongoing support. So, I've started writing a new book on how
reasoning works in LLMs, and here I'm sharing the first Chapter 1 with
you. This ~15-page chapter is an introduction reasoning in the context
of LLMs and provides an overview of methods like inference-time scaling
and reinforcement learning. Thanks for your support! I hope you enjoy
the chapter, and stay tuned for my next blog post on reasoning research!

</div>

<div class="card">

<div class="card-title">

[Function calling with
Gemma](https://simonwillison.net/2025/Mar/26/function-calling-with-gemma/)

</div>

Google's Gemma 3 model (the 27B variant is particularly capable, I've
been trying it out \[via Ollama\](https://ollama.com/library/gemma3))
supports function calling exclusively through prompt engineering. The
official documentation describes two recommended …

</div>

<div class="card">

<div class="card-title">

[Quickstart \| Mistral AI Large Language
Models](https://docs.mistral.ai/getting-started/quickstart/)

</div>

<div class="card-image">

[![](https://docs.mistral.ai/img/mistral-social-banner.jpg)](https://docs.mistral.ai/getting-started/quickstart/)

</div>

\[platform_url\]//console.mistral.ai/

</div>

<div class="card">

<div class="card-title">

[12-factor-agents: Principles to build LLM-powered software good enough
to put in the hands of production customers](https://lobste.rs/s/seuxei)

</div>

<div class="card-image">

[![](https://lobste.rs/touch-icon-144.png)](https://lobste.rs/s/seuxei)

</div>

0 comments

</div>

<div class="card">

<div class="card-title">

[How to use NotebookLM for personalized knowledge
synthesis](https://open.substack.com/pub/aisupremacy/p/how-to-use-notebooklm-for-personalized?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff23e8588-91f1-47a3-b5cf-8bb46da33ef8_1200x750.webp)](https://open.substack.com/pub/aisupremacy/p/how-to-use-notebooklm-for-personalized?r=oc5d&utm_medium=ios)

</div>

Two powerful workflows that unlock everything else. Intro: Golden Age of
AI Tools and AI agent frameworks begins in 2025.

</div>

<div class="card">

<div class="card-title">

[LLM Research Papers: The 2024
List](https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_campaign=post&utm_medium=web)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba1c2ab-7ae7-4f22-86df-f116f2914cd5_1272x1232.png)](https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_campaign=post&utm_medium=web)

</div>

A curated list of interesting LLM-related research papers from 2024,
shared for those looking for something to read over the holidays.

</div>

<div class="card">

<div class="card-title">

[How LLMs Store and Use Knowledge? This AI Paper Introduces Knowledge
Circuits: A Framework for Understanding and Improving Knowledge Storage
in Transformer-Based
LLMs](https://www.marktechpost.com/2024/12/14/how-llms-store-and-use-knowledge-this-ai-paper-introduces-knowledge-circuits-a-framework-for-understanding-and-improving-knowledge-storage-in-transformer-based-llms/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-14-at-8.35.53%E2%80%AFPM.png)](https://www.marktechpost.com/2024/12/14/how-llms-store-and-use-knowledge-this-ai-paper-introduces-knowledge-circuits-a-framework-for-understanding-and-improving-knowledge-storage-in-transformer-based-llms/)

</div>

Large language models (LLMs) can understand and generate human-like text
by encoding vast knowledge repositories within their parameters. This
capacity enables them to perform complex reasoning tasks, adapt to
various applications, and interact effectively with humans. However,
despite their remarkable achievements, researchers continue to
investigate the mechanisms underlying the storage and utilization of
knowledge in these systems, aiming to enhance their efficiency and
reliability further. A key challenge in using large language models is
their propensity to generate inaccurate, biased, or hallucinatory
outputs. These problems arise from a limited understanding of how such
models organize and access knowledge. Without clear

</div>

<div class="card">

<div class="card-title">

[A look at the ARC-AGI exam designed by French computer scientist
François Chollet to show the gulf between AI models' memorized answers
and “fluid intelligence”](http://www.techmeme.com/250407/p2#a250407p2)

</div>

<div class="card-image">

[![](https://i.imgur.com/q0p1thB.jpg)](http://www.techmeme.com/250407/p2#a250407p2)

</div>

By Matteo Wong / The Atlantic. View the full context on Techmeme.

</div>

<div class="card">

<div class="card-title">

[Topic 31: How to Reduce Memory Use in Reasoning
Models](https://www.turingpost.com/p/mlalightthinker)

</div>

<div class="card-image">

[![](https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/318273c0-c61b-486b-969c-2c4b6e4e425a/LightThinker_MLA__1_.png?t=1741805639)](https://www.turingpost.com/p/mlalightthinker)

</div>

we explore how combining LightThinker and Multi-Head Latent Attention
cuts memory and boosts performance

</div>

<div class="card">

<div class="card-title">

[OpenAI Releases a Practical Guide to Building LLM Agents for Real-World
Applications](https://www.marktechpost.com/2025/04/17/openai-releases-a-practical-guide-to-building-llm-agents-for-real-world-applications/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/04/a-digital-illustration-of-an-open-book-w_8QSSNEMdQx-4WmKW4sVoOA__ZIxHjjXTFSXziTaC-K5Kg.jpeg)](https://www.marktechpost.com/2025/04/17/openai-releases-a-practical-guide-to-building-llm-agents-for-real-world-applications/)

</div>

</div>

<div class="card">

<div class="card-title">

[LLM Post-Training: A Deep Dive into Reasoning Large Language
Models](https://arxiv.org/html/2502.21321?fbclid=IwY2xjawJtMIRleHRuA2FlbQIxMQABHtJFOZyM1YENbtAyJPt3Tu4AwMLLtXMWUkanORsu4qZWoDfwikg1UiegOAkK_aem_4SsqZCqR6ngkPHdizAPnEw)

</div>

</div>

<div class="card">

<div class="card-title">

[humanlayer/12-factor-agents](https://github.com/humanlayer/12-factor-agents)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/e579fb0260b1b42e47d176d09f37c29ed4f131b61d25b5a123b635ca5212f7fc/humanlayer/12-factor-agents)](https://github.com/humanlayer/12-factor-agents)

</div>

What are the principles we can use to build LLM-powered software that is
actually good enough to put in the hands of production customers? -
humanlayer/12-factor-agents

</div>

<div class="card">

<div class="card-title">

[The Rise of Slopsquatting: How AI Hallucinations Are
Fueling...](https://socket.dev/blog/slopsquatting-how-ai-hallucinations-are-fueling-a-new-class-of-supply-chain-attacks)

</div>

<div class="card-image">

[![](https://cdn.sanity.io/images/cgdhsj6q/production/e41299999742507d0c00b344ca3b52e3b1b67b1d-1024x1024.webp?w=1000&fit=max&auto=format)](https://socket.dev/blog/slopsquatting-how-ai-hallucinations-are-fueling-a-new-class-of-supply-chain-attacks)

</div>

Slopsquatting is a new supply chain threat where AI-assisted code
generators recommend hallucinated packages that attackers register and
weaponize.

</div>

<div class="card">

<div class="card-title">

[The Man Out to Prove How Dumb AI Still
Is](https://www.theatlantic.com/technology/archive/2025/04/arc-agi-chollet-test/682295/?gift=2iIN4YrefPjuvZ5d2Kh3089M3DxlABplHmODO9XssmE&utm_source=copy-link&utm_medium=social&utm_campaign=share)

</div>

<div class="card-image">

[![](https://cdn.theatlantic.com/thumbor/TQ7unWwrL3WWTg13JHKKLeS9j1w=/0x43:2000x1085/1200x625/filters:watermark(https://cdn.theatlantic.com/media/files/badge_2x.png,-20,20,0,33)/media/img/mt/2025/04/THE_ATLANTIC_ANIMATION_V2/original.gif)](https://www.theatlantic.com/technology/archive/2025/04/arc-agi-chollet-test/682295/?gift=2iIN4YrefPjuvZ5d2Kh3089M3DxlABplHmODO9XssmE&utm_source=copy-link&utm_medium=social&utm_campaign=share)

</div>

François Chollet has constructed the ultimate test for the bots.

</div>

<div class="card">

<div class="card-title">

[The “S” in MCP Stands for Security - Elena Cross -
Medium](https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*RtOk34kJQCS9hQjg)](https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b)

</div>

MCP, short for Model Context Protocol, is the hot new standard behind
how Large Language Models (LLMs) like Claude, GPT, or Cursor integrate
with tools and data. It’s been described as the “USB-C for…

</div>

<div class="card">

<div class="card-title">

[10 Must-Know Python Libraries for LLMs in
2025](https://machinelearningmastery.com/10-must-know-python-libraries-for-llms-in-2025/)

</div>

<div class="card-image">

[![](https://machinelearningmastery.com/wp-content/uploads/2025/03/mlm-blast-off-10-llm-python-libs.png)](https://machinelearningmastery.com/10-must-know-python-libraries-for-llms-in-2025/)

</div>

In this article, we explore 10 of the Python libraries every developer
should know in 2025.

</div>

<div class="card">

<div class="card-title">

[Anthropic can now track the bizarre inner workings of a large language
model](https://www.technologyreview.com/2025/03/27/1113916/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/)

</div>

<div class="card-image">

[![](https://wp.technologyreview.com/wp-content/uploads/2025/03/anthropic-rabbit-hole.jpg?resize=854,569)](https://www.technologyreview.com/2025/03/27/1113916/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/)

</div>

What they found challenges some basic assumptions about how this
technology really works.

</div>

<div class="card">

<div class="card-title">

[LLM Benchmarking: Fundamental Concepts \| NVIDIA Technical
Blog](https://developer.nvidia.com/blog/llm-benchmarking-fundamental-concepts/)

</div>

<div class="card-image">

[![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/03/data-center.png)](https://developer.nvidia.com/blog/llm-benchmarking-fundamental-concepts/)

</div>

The past few years have witnessed the rise in popularity of generative
AI and large language models (LLMs), as part of a broad AI revolution.

</div>

<div class="card">

<div class="card-title">

[The Llama 4 herd: The beginning of a new era of natively multimodal AI
innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)

</div>

<div class="card-image">

[![](https://scontent-ber1-1.xx.fbcdn.net/v/t39.2365-6/488639590_2182781778834283_7341615399691839509_n.png?_nc_cat=107&ccb=1-7&_nc_sid=e280be&_nc_ohc=9buYuGUTUwMQ7kNvwGtzUMi&_nc_oc=AdkN3SnJ11eSLEUJlk4ya4OUL7KaIj2j0TnxIsboqdpW3969c7_L8tK24zlT4Og1jfg&_nc_zt=14&_nc_ht=scontent-ber1-1.xx&_nc_gid=O7pjMcOm63OU1lqMXrq3Zg&oh=00_AYEQyK79iiih-1eagCAdYCNZR346qSKGGzOYg-Mlp3NBdQ&oe=680BDB60)](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)

</div>

We’re introducing Llama 4 Scout and Llama 4 Maverick, the first
open-weight natively multimodal models with unprecedented context
support and our first built using a mixture-of-experts (MoE)
architecture.

</div>

<div class="card">

<div class="card-title">

[Use MCP servers in VS Code
(Preview)](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)

</div>

<div class="card-image">

[![](https://code.visualstudio.com/assets/docs/copilot/shared/github-copilot-social.png)](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)

</div>

Learn how to configure and use Model Context Protocol (MCP) servers with
GitHub Copilot in Visual Studio Code.

</div>

<div class="card">

<div class="card-title">

[If Anthropic Succeeds, a Nation of Benevolent AI Geniuses Could Be
Born](https://www.wired.com/story/anthropic-benevolent-artificial-intelligence/)

</div>

<div class="card-image">

[![](https://media.wired.com/photos/67dc466ffa0c3a77d4f8f567/16:9/w_2496,h_1404,c_limit/WIRED_ANTHROPIC_002-V2_web.jpg)](https://www.wired.com/story/anthropic-benevolent-artificial-intelligence/)

</div>

The brother goes on vision quests. The sister is a former English major.
Together, they defected from OpenAI, started Anthropic, and built (they
say) AI’s most upstanding citizen, Claude.

</div>

<div class="card">

<div class="card-title">

[A Comprehensive Guide to LLM Routing: Tools and
Frameworks](https://www.marktechpost.com/2025/04/01/a-comprehensive-guide-to-llm-routing-tools-and-frameworks/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/04/a-technical-image-of-a-neural-network-di_tmx_npS1R8yb9IaVjwNgyA_3MR4BRKNRJWs2SRcefBz7g.png)](https://www.marktechpost.com/2025/04/01/a-comprehensive-guide-to-llm-routing-tools-and-frameworks/)

</div>

Deploying LLMs presents challenges, particularly in optimizing
efficiency, managing computational costs, and ensuring high-quality
performance. LLM routing has emerged as a strategic solution to these
challenges, enabling intelligent task allocation to the most suitable
models or tools. Let’s delve into the intricacies of LLM routing,
explore various tools and frameworks designed for its implementation,
and \[…\]

</div>

<div class="card">

<div class="card-title">

[How DeepSeek Rewrote the Transformer
\[MLA\]](https://www.youtube.com/watch?v=0VLAoVGf_74)

</div>

<div class="card-image">

[![](https://i.ytimg.com/vi/0VLAoVGf_74/maxresdefault.jpg)](https://www.youtube.com/watch?v=0VLAoVGf_74)

</div>

Thanks to KiwiCo for sponsoring today’s video! Go to
https://www.kiwico.com/welchlabs and use code WELCHLABS for 50% off your
first monthly club crate or for...

</div>

<div class="card">

<div class="card-title">

[Tracing the thoughts of a large language
model](https://simonwillison.net/2025/Mar/27/tracing-the-thoughts-of-a-large-language-model/#atom-everything)

</div>

In a follow-up to the research that brought us the \[delightful Golden
Gate Claude\](https://simonwillison.net/2024/May/24/golden-gate-claude/)
last year, Anthropic have published two new papers about LLM
interpretability: - \[Circuit Tracing: Revealing Computational …

</div>

<div class="card">

<div class="card-title">

[What is the hallucination
index?](https://dataconomy.com/2025/03/25/what-is-the-hallucination-index/)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png)](https://dataconomy.com/2025/03/25/what-is-the-hallucination-index/)

</div>

The Hallucination Index is a benchmark that measures the frequency of
inaccuracies in large language models, indicating their reliability and
contextual understanding.

</div>

<div class="card">

<div class="card-title">

[Improving Recommender Systems & Search in the Age of
LLMs](https://eugeneyan.com/writing/recsys-llm/)

</div>

<div class="card-image">

[![](https://eugeneyan.com/assets/og_image/recsys-llm.jpg)](https://eugeneyan.com/writing/recsys-llm/)

</div>

Model architectures, data generation, training paradigms, and unified
frameworks inspired by LLMs.

</div>

<div class="card">

<div class="card-title">

[Anthropic just gave Claude a superpower: real-time web search. Here’s
why it changes
everything](https://venturebeat.com/ai/anthropic-just-gave-claude-a-superpower-real-time-web-search-heres-why-it-changes-everything/)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2025/03/website-hero-websearch.jpg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/anthropic-just-gave-claude-a-superpower-real-time-web-search-heres-why-it-changes-everything/)

</div>

Anthropic launches real-time web search for Claude AI, challenging
ChatGPT's dominance while securing \$3.5 billion in funding at a \$61.5
billion valuation.

</div>

<div class="card">

<div class="card-title">

[Mistral OCR \| Mistral AI](https://mistral.ai/fr/news/mistral-ocr)

</div>

<div class="card-image">

[![](https://cms.mistral.ai/assets/060bdeb1-fbff-419c-b2ae-b32b5e441864)](https://mistral.ai/fr/news/mistral-ocr)

</div>

Introducing the world’s best document understanding API.

</div>

<div class="card">

<div class="card-title">

[Mistral
OCR](https://simonwillison.net/2025/Mar/7/mistral-ocr/#atom-everything)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/mixtral-as-html.jpg)](https://simonwillison.net/2025/Mar/7/mistral-ocr/#atom-everything)

</div>

New closed-source specialist OCR model by Mistral - you can feed it
images or a PDF and it produces Markdown with optional embedded images.
It's available \[via their API\](https://docs.mistral.ai/api/#tag/ocr),
or …

</div>

<div class="card">

<div class="card-title">

[Mistral Small 3.1 runs on a MacBook and beats giants -
Dataconomy](https://dataconomy.com/2025/03/18/mistral-small-3-1-runs-on-a-macbook-and-beats-giants/)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png)](https://dataconomy.com/2025/03/18/mistral-small-3-1-runs-on-a-macbook-and-beats-giants/)

</div>

Paris-based artificial intelligence startup Mistral AI has announced the
open-source release of its lightweight AI model, Mistral Small 3.1,
which the company

</div>

<div class="card">

<div class="card-title">

[Mistral Small
3.1](https://simonwillison.net/2025/Mar/17/mistral-small-31/#atom-everything)

</div>

Mistral Small 3 \[came out in
January\](https://simonwillison.net/2025/Jan/30/mistral-small-3/) and
was a notable, genuinely excellent local model that used an Apache 2.0
license. Mistral Small 3.1 offers a significant improvement: it's
multi-modal …

</div>

<div class="card">

<div class="card-title">

[What are model cards? -
Dataconomy](https://dataconomy.com/2025/03/12/what-are-model-cards/)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png)](https://dataconomy.com/2025/03/12/what-are-model-cards/)

</div>

Model cards are documentation tools in machine learning that provide
essential information about models, promoting transparency, trust, and
ethical considerations in AI systems.

</div>

<div class="card">

<div class="card-title">

[A Step-by-Step Guide to Setting Up a Custom BPE Tokenizer with Tiktoken
for Advanced NLP Applications in
Python](https://www.marktechpost.com/2025/02/16/a-step-by-step-guide-to-setting-up-a-custom-bpe-tokenizer-with-tiktoken-for-advanced-nlp-applications-in-python/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/02/Screenshot-2025-02-16-at-10.17.33%E2%80%AFPM.png)](https://www.marktechpost.com/2025/02/16/a-step-by-step-guide-to-setting-up-a-custom-bpe-tokenizer-with-tiktoken-for-advanced-nlp-applications-in-python/)

</div>

A Step-by-Step Guide to Setting Up a Custom BPE Tokenizer with Tiktoken
for Advanced NLP Applications in Python

</div>

<div class="card">

<div class="card-title">

[The State of LLM Reasoning
Models](https://open.substack.com/pub/sebastianraschka/p/state-of-llm-reasoning-and-inference-scaling?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf9e2677-652a-4af1-9f57-dc0c253d2198_1448x1260.png)](https://open.substack.com/pub/sebastianraschka/p/state-of-llm-reasoning-and-inference-scaling?r=oc5d&utm_medium=ios)

</div>

Part 1: Inference-Time Compute Scaling Methods

</div>

<div class="card">

<div class="card-title">

<https://www.r-bloggers.com/2025/03/the-ellmer-package-for-using-llms-with-r-is-a-game-changer-for-scientists-2/>

</div>

<div class="card-image">

[![](https://www.r-bloggers.com/wp-content/uploads/2016/08/R_single_01-200-1.png)](https://www.r-bloggers.com/2025/03/the-ellmer-package-for-using-llms-with-r-is-a-game-changer-for-scientists-2/)

</div>

The ellmer package for using LLMs with R is a game changer for
scientists Why is ellmer a game changer for scientists? In this tutorial
we’ll look at how we can access LLM agents through API calls. We’ll use
this skill for created structued data fro...

</div>

<div class="card">

<div class="card-title">

[What is catastrophic forgetting? -
Dataconomy](https://dataconomy.com/2025/03/13/what-is-catastrophic-forgetting/)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2022/12/DC-logo-emblem_multicolor.png)](https://dataconomy.com/2025/03/13/what-is-catastrophic-forgetting/)

</div>

Catastrophic Forgetting is a phenomenon where neural networks lose
previously learned information when trained on new data, similar to
human memory loss.

</div>

<div class="card">

<div class="card-title">

[Top 7 Open-Source LLMs in 2025 -
KDnuggets](https://www.kdnuggets.com/top-7-open-source-llms-in-2025)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/awan_top_7_opensource_llms_2025_1.png)](https://www.kdnuggets.com/top-7-open-source-llms-in-2025)

</div>

These models are free to use, can be fine-tuned, and offer enhanced
privacy and security since they can run directly on your machine, and
match the performance of proprietary solutions like o3-min and Gemini
2.0.

</div>

<div class="card">

<div class="card-title">

[How I use LLMs to help me write
code](https://open.substack.com/pub/simonw/p/how-i-use-llms-to-help-me-write-code?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5eb20c0-d125-480c-92f4-e927d0a12872_1600x1200.jpeg)](https://open.substack.com/pub/simonw/p/how-i-use-llms-to-help-me-write-code?r=oc5d&utm_medium=ios)

</div>

Plus CSS view transitions and a major update to llm-openrouter

</div>

<div class="card">

<div class="card-title">

[On GPT-4.5](https://thezvi.substack.com/p/on-gpt-45?ref=thediff.co)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f8cdc5b-2574-43d9-9af3-15c1a5b9a8a4_300x168.jpeg)](https://thezvi.substack.com/p/on-gpt-45?ref=thediff.co)

</div>

It’s happening.

</div>

<div class="card">

<div class="card-title">

[llm-ollama 0.9.0](https://simonwillison.net/2025/Mar/4/llm-ollama-090/)

</div>

This release of the \`llm-ollama\` plugin adds support for
\[schemas\](https://simonwillison.net/2025/Feb/28/llm-schemas/), thanks
to a \[PR by Adam
Compton\](https://github.com/taketwo/llm-ollama/pull/36). Ollama
provides very robust support for this pattern thanks to their
\[structured outputs\](https://ollama.com/blog/structured-outputs) …

</div>

<div class="card">

<div class="card-title">

[Claude 3.7 Sonnet and Claude
Code](https://www.anthropic.com/news/claude-3-7-sonnet)

</div>

<div class="card-image">

[![](https://cdn.sanity.io/images/4zrzovbb/website/9b52e961f8f275e21e75c477c99672abd13fe66b-2400x1260.png)](https://www.anthropic.com/news/claude-3-7-sonnet)

</div>

Today, we’re announcing Claude 3.7 Sonnet, our most intelligent model to
date and the first hybrid reasoning model generally available on the
market.

</div>

<div class="card">

<div class="card-title">

[The Deep Research problem — Benedict
Evans](https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem)

</div>

<div class="card-image">

[![](http://static1.squarespace.com/static/50363cf324ac8e905e7df861/5055cb1de4b0a751cabaedd5/67b3931718a8632b064c937c/1739890282987/Screenshot%2B2025-02-17%2Bat%2B4.27.52%E2%80%AFpm.png?format=1500w)](https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem)

</div>

OpenAI’s Deep Research is built for me, and I can’t use it. It’s another
amazing demo, until it breaks. But it breaks in really interesting ways.

</div>

<div class="card">

<div class="card-title">

[5 Principles for Writing Effective Prompts (2025
Update)](https://blog.tobiaszwingmann.com/p/5-principles-for-writing-effective-prompts)

</div>

<div class="card-image">

[![](https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/8fe61654-58ef-4d09-8b20-eae84bb194fa/Prompt_Principles_Infographic.png?t=1738815077)](https://blog.tobiaszwingmann.com/p/5-principles-for-writing-effective-prompts)

</div>

Solid techniques to get really good results from any LLM

</div>

<div class="card">

<div class="card-title">

[Greg Brockman shared this template for
prompting](https://www.linkedin.com/posts/tobias-zwingmann_openais-president-greg-brockman-recently-activity-7298713328556691458-VRM_?utm_source=share&utm_medium=member_ios&rcm=ACoAAAAQ_oABqroJaYAjd1pLSvoVsTKPWFYPcIQ)

</div>

<div class="card-image">

[![](https://media.licdn.com/dms/image/v2/D4E22AQGOS-pw8GvRdw/feedshare-shrink_800/B4EZUos180GwAk-/0/1740144599715?e=2147483647&v=beta&t=D_i5Vk3L2tOFUqK76RU2suKXd2qByYWYfwgOg7hUraU)](https://www.linkedin.com/posts/tobias-zwingmann_openais-president-greg-brockman-recently-activity-7298713328556691458-VRM_?utm_source=share&utm_medium=member_ios&rcm=ACoAAAAQ_oABqroJaYAjd1pLSvoVsTKPWFYPcIQ)

</div>

OpenAI's president Greg Brockman recently shared this cool template for
prompting their reasoning models o1/o3. Turns out, this is great for ANY
reasoning… \| 32 comments on LinkedIn

</div>

<div class="card">

<div class="card-title">

[LLM Leaderboard](https://artificialanalysis.ai/leaderboards/models)

</div>

<div class="card-image">

[![](https://artificialanalysis.ai/img/open-graph/og-image.png)](https://artificialanalysis.ai/leaderboards/models)

</div>

Comparison and ranking the performance of over 30 AI models (LLMs)
across key metrics including quality, price, performance and speed
(output speed - tokens per second & latency - TTFT), context window &
others.

</div>

<div class="card">

<div class="card-title">

[Why AI language models choke on too much
text](https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/)

</div>

<div class="card-image">

[![](https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg)](https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/)

</div>

Compute costs scale with the square of the input size. That’s not great.

</div>

<div class="card">

<div class="card-title">

[Here Are My Go-To AI
Tools](https://open.substack.com/pub/whytryai/p/my-go-to-ai-tools?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc12a80fa-e1a0-458a-ae0f-e9e8e6d38bdb_1344x896.png)](https://open.substack.com/pub/whytryai/p/my-go-to-ai-tools?r=oc5d&utm_medium=ios)

</div>

I share my preferences for LLMs, image models, AI video, AI music,
AI-powered research, and more. These are the AI tools I regularly use or
recommend to others.

</div>

<div class="card">

<div class="card-title">

[We Were Wrong About GPUs](https://fly.io/blog/wrong-about-gpu/)

</div>

<div class="card-image">

[![](https://fly.io/blog/wrong-about-gpu/assets/choices-choices-cover.webp)](https://fly.io/blog/wrong-about-gpu/)

</div>

Do my tears surprise you? Strong CEOs also cry.

</div>

<div class="card">

<div class="card-title">

[Using pip to install a Large Language Model that’s under
100MB](https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/smol-card.jpg)](https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/)

</div>

I just released llm-smollm2, a new plugin for LLM that bundles a
quantized copy of the SmolLM2-135M-Instruct LLM inside of the Python
package. This means you can now pip install …

</div>

<div class="card">

<div class="card-title">

[Creating an AI Agent-Based System with LangGraph: Adding Persistence
and Streaming (Step by Step
Guide)](https://www.marktechpost.com/2025/02/01/creating-an-ai-agent-based-system-with-langgraph-adding-persistence-and-streaming-step-by-step-guide/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/02/Screenshot-2025-02-01-at-10.53.44%E2%80%AFPM.png)](https://www.marktechpost.com/2025/02/01/creating-an-ai-agent-based-system-with-langgraph-adding-persistence-and-streaming-step-by-step-guide/)

</div>

In our previous tutorial, we built an AI agent capable of answering
queries by surfing the web. However, when building agents for
longer-running tasks, two critical concepts come into play: persistence
and streaming. Persistence allows you to save the state of an agent at
any given point, enabling you to resume from that state in future
interactions. This is crucial for long-running applications. On the
other hand, streaming lets you emit real-time signals about what the
agent is doing at any moment, providing transparency and control over
its actions. In this tutorial, we’ll enhance our agent by adding these
powerful

</div>

<div class="card">

<div class="card-title">

[How to Build a Graph RAG
App](https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*fsYI8Riyq2lAsH8wTCuKhw.png)](https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=rss----7f60cf5620c9---4)

</div>

Using knowledge graphs and AI to retrieve, filter, and summarize medical
journal articles

</div>

<div class="card">

<div class="card-title">

[Understanding Reasoning
LLMs](https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/understanding-reasoning-llms/hero.jpg)](https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html)

</div>

In this article, I will describe the four main approaches to building
reasoning models, or how we can enhance LLMs with reasoning
capabilities. I hope this p...

</div>

<div class="card">

<div class="card-title">

[5 AI Agent Frameworks Compared -
KDnuggets](https://www.kdnuggets.com/5-ai-agent-frameworks-compared)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/5-AI-Agent-Frameworks-Compared_1.jpeg)](https://www.kdnuggets.com/5-ai-agent-frameworks-compared)

</div>

Check out this comparison of 5 AI frameworks to determine which you
should choose.

</div>

<div class="card">

<div class="card-title">

[Qwen AI Introduces Qwen2.5-Max: A large MoE LLM Pretrained on Massive
Data and Post-Trained with Curated SFT and RLHF
Recipes](https://www.marktechpost.com/2025/01/28/qwen-ai-introduces-qwen2-5-max-a-large-moe-llm-pretrained-on-massive-data-and-post-trained-with-curated-sft-and-rlhf-recipes/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/01/Screenshot-2025-01-28-at-11.14.09%E2%80%AFPM-1.png)](https://www.marktechpost.com/2025/01/28/qwen-ai-introduces-qwen2-5-max-a-large-moe-llm-pretrained-on-massive-data-and-post-trained-with-curated-sft-and-rlhf-recipes/)

</div>

The field of artificial intelligence is evolving rapidly, with
increasing efforts to develop more capable and efficient language
models. However, scaling these models comes with challenges,
particularly regarding computational resources and the complexity of
training. The research community is still exploring best practices for
scaling extremely large models, whether they use a dense or
Mixture-of-Experts (MoE) architecture. Until recently, many details
about this process were not widely shared, making it difficult to refine
and improve large-scale AI systems. Qwen AI aims to address these
challenges with Qwen2.5-Max, a large MoE model pretrained on over 20
trillion tokens and further refined

</div>

<div class="card">

<div class="card-title">

[DeepSeek-R1 vs. OpenAI’s o1: A New Step in Open Source and Proprietary
Models](https://www.marktechpost.com/2025/01/25/deepseek-r1-vs-openais-o1-a-new-step-in-open-source-and-proprietary-models/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/01/Screenshot-2025-01-25-at-6.05.44%E2%80%AFPM.png)](https://www.marktechpost.com/2025/01/25/deepseek-r1-vs-openais-o1-a-new-step-in-open-source-and-proprietary-models/)

</div>

AI has entered an era of the rise of competitive and groundbreaking
large language models and multimodal models. The development has two
sides, one with open source and the other being propriety models.
DeepSeek-R1, an open-source AI model developed by DeepSeek-AI, a Chinese
research company, exemplifies this trend. Its emergence has challenged
the dominance of proprietary models such as OpenAI’s o1, sparking
discussions on cost efficiency, open-source innovation, and global
technological leadership in AI. Let’s delve into the development,
capabilities, and implications of DeepSeek-R1 while comparing it with
OpenAI’s o1 system, considering the contributions of both spaces.
DeepSeek-R1 DeepSeek-R1 is

</div>

<div class="card">

<div class="card-title">

[(WIP) A Little Bit of Reinforcement Learning from Human
Feedback](https://rlhfbook.com/)

</div>

<div class="card-image">

[![](https://github.com/natolambert/rlhf-book/blob/main/images/rlhf-book-share)](https://rlhfbook.com/)

</div>

The Reinforcement Learning from Human Feedback Book

</div>

<div class="card">

<div class="card-title">

[aidanmclaughlin/AidanBench: Aidan Bench attempts to measure in
LLMs.](https://github.com/aidanmclaughlin/AidanBench)

</div>

<div class="card-image">

[![](https://repository-images.githubusercontent.com/838396720/3107078a-5021-424f-a295-6306de266b1e)](https://github.com/aidanmclaughlin/AidanBench)

</div>

Aidan Bench attempts to measure in LLMs. - aidanmclaughlin/AidanBench

</div>

<div class="card">

<div class="card-title">

[Noteworthy LLM Research Papers of
2024](https://sebastianraschka.com/blog/2025/llm-research-2024.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2025/llm-research-2024/hero.jpg)](https://sebastianraschka.com/blog/2025/llm-research-2024.html)

</div>

This article covers 12 influential AI research papers of 2024, ranging
from mixture-of-experts models to new LLM scaling laws for precision..

</div>

<div class="card">

<div class="card-title">

[OpenAI o3-mini, now available in
LLM](https://simonwillison.net/2025/Jan/31/o3-mini/#atom-everything)

</div>

o3-mini is out today. As with other o-series models it’s a slightly
difficult one to evaluate—we now need to decide if a prompt is best run
using GPT-4o, o1, o3-mini …

</div>

<div class="card">

<div class="card-title">

[On MLA](https://planetbanatt.net/articles/mla.html)

</div>

<div class="card-image">

[![](https://planetbanatt.net/images/mla/manifold_perturbation.png)](https://planetbanatt.net/articles/mla.html)

</div>

</div>

<div class="card">

<div class="card-title">

[Multi-Head Latent Attention and Other KV Cache
Tricks](https://www.pyspur.dev/blog/multi-head-latent-attention-kv-cache-paper-list)

</div>

<div class="card-image">

[![](http://localhost:3000/blog/kv-cache/mla.png)](https://www.pyspur.dev/blog/multi-head-latent-attention-kv-cache-paper-list)

</div>

How a Key-Value (KV) cache reduces Transformer inference time by trading
memory for computation

</div>

<div class="card">

<div class="card-title">

[Alibaba releases AI model it says surpasses
DeepSeek](https://www.reuters.com/technology/artificial-intelligence/alibaba-releases-ai-model-it-claims-surpasses-deepseek-v3-2025-01-29/)

</div>

<div class="card-image">

[![](https://www.reuters.com/resizer/v2/GVHN3TRO5ZPMLCO5XG6ELFQC7E.jpg?auth=501e317e4440056dc491fe5a4ec8d53025386511cb2c10ee1ec72c99e2afe0e4&height=1005&width=1920&quality=80&smart=true)](https://www.reuters.com/technology/artificial-intelligence/alibaba-releases-ai-model-it-claims-surpasses-deepseek-v3-2025-01-29/)

</div>

The unusual timing of the Qwen 2.5-Max's release points to the pressure
DeepSeek's meteoric rise in the past three weeks has placed on overseas
rivals and domestic competition.

</div>

<div class="card">

<div class="card-title">

[Scaling Laws – O1 Pro Architecture, Reasoning Training Infrastructure,
Orion and Claude 3.5 Opus
“Failures”](https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/)

</div>

<div class="card-image">

[![](https://i0.wp.com/semianalysis.com/wp-content/uploads/2024/12/foolallthetime_A_timeline_depicted_as_a_rising_staircase_leadin_60a51d3b-d96b-461a-8ae1-afb20c02dcc7.webp?fit=1200%2C800&ssl=1)](https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/)

</div>

There has been an increasing amount of fear, uncertainty and doubt (FUD)
regarding AI Scaling laws. A cavalcade of part-time AI industry
prognosticators have latched on to any bearish narrative the…

</div>

<div class="card">

<div class="card-title">

[AI hallucinations can’t be stopped — but these techniques can limit
their damage](https://www.nature.com/articles/d41586-025-00068-5)

</div>

<div class="card-image">

[![](https://media.nature.com/lw1200/magazine-assets/d41586-025-00068-5/d41586-025-00068-5_50471802.jpg)](https://www.nature.com/articles/d41586-025-00068-5)

</div>

Developers have tricks to stop artificial intelligence from making
things up, but large language models are still struggling to tell the
truth, the whole truth and nothing but the truth.

</div>

<div class="card">

<div class="card-title">

[The Illustrated
DeepSeek-R1](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1?utm_campaign=post&utm_medium=web)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png)](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1?utm_campaign=post&utm_medium=web)

</div>

A recipe for reasoning LLMs

</div>

<div class="card">

<div class="card-title">

[How Chinese A.I. Start-Up DeepSeek Is Competing With OpenAI and
Google](https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html?unlocked_article_code=1.rU4.B5dI.rZuqL149Jok_&smid=url-share)

</div>

<div class="card-image">

[![](https://static01.nyt.com/images/2025/01/17/multimedia/CHINA-AI-vjfl/CHINA-AI-vjfl-largeHorizontalJumbo.jpg)](https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html?unlocked_article_code=1.rU4.B5dI.rZuqL149Jok_&smid=url-share)

</div>

The company built a cheaper, competitive chatbot with fewer high-end
computer chips than U.S. behemoths like Google and OpenAI, showing the
limits of chip export control.

</div>

<div class="card">

<div class="card-title">

[LLM
0.20](https://simonwillison.net/2025/Jan/23/llm-020/#atom-everything)

</div>

New release of my \[LLM\](https://llm.datasette.io/) CLI tool and Python
library. A bunch of accumulated fixes and features since the start of
December, most notably: - Support for OpenAI's \[o1
model\](https://platform.openai.com/docs/models#o1) …

</div>

<div class="card">

<div class="card-title">

[DeepSeek-R1 and exploring
DeepSeek-R1-Distill-Llama-8B](https://simonwillison.net/2025/Jan/20/deepseek-r1/#atom-everything)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2025/r1-card.jpg)](https://simonwillison.net/2025/Jan/20/deepseek-r1/#atom-everything)

</div>

DeepSeek are the Chinese AI lab who dropped the best currently available
open weights LLM on Christmas day, DeepSeek v3. That model was trained
in part using their unreleased R1 …

</div>

<div class="card">

<div class="card-title">

[An Opinionated Evals Reading List — Apollo
Research](https://www.apolloresearch.ai/blog/an-opinionated-evals-reading-list?utm_source=chatgpt.com)

</div>

<div class="card-image">

[![](http://static1.squarespace.com/static/6593e7097565990e65c886fd/65940f02f1fcb826ed2a7229/670e662d065b1f4ab82aab5e/1734295113640/Screenshot+2024-10-15+at+15.25.10.png?format=1500w)](https://www.apolloresearch.ai/blog/an-opinionated-evals-reading-list?utm_source=chatgpt.com)

</div>

A long reading list of evals papers with recommendations and comments by
the evals team.

</div>

<div class="card">

<div class="card-title">

[Agents](https://huyenchip.com/2025/01/07/agents.html)

</div>

<div class="card-image">

[![](https://huyenchip.com/assets/pics/agents/2-agent-pattern.png)](https://huyenchip.com/2025/01/07/agents.html)

</div>

Intelligent agents are considered by many to be the ultimate goal of AI.
The classic book by Stuart Russell and Peter Norvig, Artificial
Intelligence: A Modern Approach (Prentice Hall, 1995), defines the field
of AI research as “the study and design of rational agents.”

</div>

<div class="card">

<div class="card-title">

[The 2025 AI Engineering Reading
List](https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242370c-229f-453d-924a-7a5aa4d20a4c_1090x502.png)](https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web)

</div>

We picked 50 paper/models/blogs across 10 fields in AI Eng: LLMs,
Benchmarks, Prompting, RAG, Agents, CodeGen, Vision, Voice, Diffusion,
Finetuning. If you're starting from scratch, start here.

</div>

<div class="card">

<div class="card-title">

[100 Must-Read Generative AI Papers from
2024](https://open.substack.com/pub/thenuancedperspective/p/100-must-read-generative-ai-papers?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcfe5315-38ae-475d-9b8a-05df56910378_1800x829.png)](https://open.substack.com/pub/thenuancedperspective/p/100-must-read-generative-ai-papers?r=oc5d&utm_medium=ios)

</div>

A comprehensive list of some of the most impactful generative papers
from last year

</div>

<div class="card">

<div class="card-title">

[7 Next-Generation Prompt Engineering Techniques -
MachineLearningMastery.com](https://machinelearningmastery.com/7-next-generation-prompt-engineering-techniques/)

</div>

<div class="card-image">

[![](https://machinelearningmastery.com/wp-content/uploads/2025/01/mlm-7-next-gen-prompting-techniques.png)](https://machinelearningmastery.com/7-next-generation-prompt-engineering-techniques/)

</div>

\[caption align=

</div>

<div class="card">

<div class="card-title">

[Implementing A Byte Pair Encoding (BPE) Tokenizer From
Scratch](https://sebastianraschka.com/blog/2025/bpe-from-scratch.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/bpe-from-scratch/bpe-overview.jpg)](https://sebastianraschka.com/blog/2025/bpe-from-scratch.html)

</div>

This is a standalone notebook implementing the popular byte pair
encoding (BPE) tokenization algorithm, which is used in models like
GPT-2 to GPT-4, Llama 3,...

</div>

<div class="card">

<div class="card-title">

[This Rumor About GPT-5 Changes
Everything](https://open.substack.com/pub/thealgorithmicbridge/p/this-rumor-about-gpt-5-changes-everything?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F61d7c2f7-6d0d-4624-9498-e006d3b5bc96_1792x1024.webp)](https://open.substack.com/pub/thealgorithmicbridge/p/this-rumor-about-gpt-5-changes-everything?r=oc5d&utm_medium=ios)

</div>

Let’s start the year on an exciting note

</div>

<div class="card">

<div class="card-title">

[Microsoft Presents a Comprehensive Framework for Securing Generative AI
Systems Using Lessons from Red Teaming 100 Generative AI
Products](https://www.marktechpost.com/2025/01/18/microsoft-presents-a-comprehensive-framework-for-securing-generative-ai-systems-using-lessons-from-red-teaming-100-generative-ai-products/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-10.12.05%E2%80%AFAM.png)](https://www.marktechpost.com/2025/01/18/microsoft-presents-a-comprehensive-framework-for-securing-generative-ai-systems-using-lessons-from-red-teaming-100-generative-ai-products/)

</div>

The rapid advancement and widespread adoption of generative AI systems
across various domains have increased the critical importance of AI red
teaming for evaluating technology safety and security. While AI red
teaming aims to evaluate end-to-end systems by simulating real-world
attacks, current methodologies face significant challenges in
effectiveness and implementation. The complexity of modern AI systems,
with their expanding capabilities across multiple modalities including
vision and audio, has created an unprecedented array of potential
vulnerabilities and attack vectors. Moreover, integrating agentic
systems that grant AI models higher privileges and access to external
tools has substantially increased the attack surface and

</div>

<div class="card">

<div class="card-title">

[Lessons From Red Teaming 100 Generative AI
Products](https://simonwillison.net/2025/Jan/18/lessons-from-red-teaming/)

</div>

New paper from Microsoft describing their top eight lessons learned red
teaming (deliberately seeking security vulnerabilities in) 100 different
generative AI models and products over the past few years. …

</div>

<div class="card">

<div class="card-title">

[rasbt/LLMs-from-scratch: Implement a ChatGPT-like LLM in PyTorch from
scratch, step by
step](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material)

</div>

<div class="card-image">

[![](https://repository-images.githubusercontent.com/669879380/79da1d51-4ef9-4733-a61c-1d7851020d9a)](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material)

</div>

Implement a ChatGPT-like LLM in PyTorch from scratch, step by step -
rasbt/LLMs-from-scratch

</div>

<div class="card">

<div class="card-title">

[Things we learned out about LLMs in
2024](https://simonwillison.net/2024/Dec/31/llms-in-2024/)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2024/arena-dec-2024.jpg)](https://simonwillison.net/2024/Dec/31/llms-in-2024/)

</div>

A lot has happened in the world of Large Language Models over the course
of 2024. Here’s a review of things we figured out about the field in the
past …

</div>

<div class="card">

<div class="card-title">

[CPU-GPU I/O-Aware LLM Inference Reduces Latency in GPUs by Optimizing
CPU-GPU
Interactions](https://www.marktechpost.com/2024/12/06/cpu-gpu-i-o-aware-llm-inference-reduces-latency-in-gpus-by-optimizing-cpu-gpu-interactions/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-06-at-10.42.41%E2%80%AFPM.png)](https://www.marktechpost.com/2024/12/06/cpu-gpu-i-o-aware-llm-inference-reduces-latency-in-gpus-by-optimizing-cpu-gpu-interactions/)

</div>

LLMs are driving major advances in research and development today. A
significant shift has been observed in research objectives and
methodologies toward an LLM-centric approach. However, they are
associated with high expenses, making LLMs for large-scale utilization
inaccessible to many. It is, therefore, a significant challenge to
reduce the latency of operations, especially in dynamic applications
that demand responsiveness. KV cache is used for autoregressive decoding
in LLMs. It stores key-value pairs in multi-headed attention during the
pre-filling phase of inference. During the decoding stage, new KV pairs
get appended to the memory. KV cache stores the intermediate key and

</div>

<div class="card">

<div class="card-title">

[Gemini 2.0 Flash "Thinking
Mode"](https://open.substack.com/pub/simonw/p/gemini-20-flash-thinking-mode?r=oc5d&utm_medium=ios)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd37da74d-4508-4b1d-b1cd-5e61852b5522_936x906.png)](https://open.substack.com/pub/simonw/p/gemini-20-flash-thinking-mode?r=oc5d&utm_medium=ios)

</div>

Plus building Python tools with a one-shot prompt using uv run and
Claude Projects

</div>

<div class="card">

<div class="card-title">

[Meta AI Proposes Large Concept Models (LCMs): A Semantic Leap Beyond
Token-based Language
Modeling](https://www.marktechpost.com/2024/12/15/meta-ai-proposes-large-concept-models-lcms-a-semantic-leap-beyond-token-based-language-modeling/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-15-at-4.39.41%E2%80%AFPM.png)](https://www.marktechpost.com/2024/12/15/meta-ai-proposes-large-concept-models-lcms-a-semantic-leap-beyond-token-based-language-modeling/)

</div>

Large Language Models (LLMs) have achieved remarkable advancements in
natural language processing (NLP), enabling applications in text
generation, summarization, and question-answering. However, their
reliance on token-level processing—predicting one word at a
time—presents challenges. This approach contrasts with human
communication, which often operates at higher levels of abstraction,
such as sentences or ideas. Token-level modeling also struggles with
tasks requiring long-context understanding and may produce outputs with
inconsistencies. Moreover, extending these models to multilingual and
multimodal applications is computationally expensive and data-intensive.
To address these issues, researchers at Meta AI have proposed a new
approach: Large Concept Models (LCMs). Large Concept

</div>

<div class="card">

<div class="card-title">

[Slim-Llama: An Energy-Efficient LLM ASIC Processor Supporting 3-Billion
Parameters at Just
4.69mW](https://www.marktechpost.com/2024/12/20/slim-llama-an-energy-efficient-llm-asic-processor-supporting-3-billion-parameters-at-just-4-69mw/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-20-at-4.36.50%E2%80%AFPM.png)](https://www.marktechpost.com/2024/12/20/slim-llama-an-energy-efficient-llm-asic-processor-supporting-3-billion-parameters-at-just-4-69mw/)

</div>

Large Language Models (LLMs) have become a cornerstone of artificial
intelligence, driving advancements in natural language processing and
decision-making tasks. However, their extensive power demands, resulting
from high computational overhead and frequent external memory access,
significantly hinder their scalability and deployment, especially in
energy-constrained environments such as edge devices. This escalates the
cost of operation while also limiting accessibility to these LLMs, which
therefore calls for energy-efficient approaches designed to handle
billion-parameter models. Current approaches to reduce the computational
and memory needs of LLMs are based either on general-purpose processors
or on GPUs, with a combination of weight quantization and

</div>

<div class="card">

<div class="card-title">

[OpenAI Unveils o3 System That Reasons Through Math, Science
Problems](https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-science.html)

</div>

<div class="card-image">

[![](https://static01.nyt.com/images/2024/12/20/multimedia/20openai-bplz/20openai-bplz-largeHorizontalJumbo.jpg)](https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-science.html)

</div>

The artificial intelligence start-up said the new system, OpenAI o3,
outperformed leading A.I. technologies on tests that rate skills in
math, science, coding and logic.

</div>

<div class="card">

<div class="card-title">

[Building effective agents \\
Anthropic](https://www.anthropic.com/research/building-effective-agents)

</div>

<div class="card-image">

[![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75)](https://www.anthropic.com/research/building-effective-agents)

</div>

A post for developers with advice and workflows for building effective
AI agents

</div>

<div class="card">

<div class="card-title">

[Blt patches scale better than
tokens](https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf)

</div>

</div>

<div class="card">

<div class="card-title">

[LangChain vs OpenAI API: When Simplicity Meets Scalability \| Aditya
Bhattacharya \| Blogs
Website](https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/)

</div>

<div class="card-image">

[![](https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-api-when-simplicity-meets-scalability.png)](https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/)

</div>

This blog explores a detailed comparison between the OpenAI API and
LangChain, highlighting key differences in performance and developer
experience and the low level code for why these differences exist.

</div>

<div class="card">

<div class="card-title">

[Transformers Key-Value (KV) Caching
Explained](https://towardsdatascience.com/transformers-key-value-kv-caching-explained-4d71de62d22d?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*ub2DQhz0aHT0-Tyaw3hGkQ.png)](https://towardsdatascience.com/transformers-key-value-kv-caching-explained-4d71de62d22d?source=rss----7f60cf5620c9---4)

</div>

Speed up your LLM inference

</div>

<div class="card">

<div class="card-title">

[Treemap](https://aiworld.eu/embed/model/model/treemap)

</div>

<div class="card-image">

[![](https://aiworld.eu/open-graph-1.png)](https://aiworld.eu/embed/model/model/treemap)

</div>

Navigate Tomorrow's Intelligence Today

</div>

<div class="card">

<div class="card-title">

[The AI Researchers Pushing Computers to Launch Nightmare
Scenarios](https://www.wsj.com/tech/ai/ai-safety-testing-red-team-anthropic-1b31b21b?st=o5kvwf&reflink=desktopwebshare_permalink)

</div>

<div class="card-image">

[![](https://images.wsj.net/im-81826050/social)](https://www.wsj.com/tech/ai/ai-safety-testing-red-team-anthropic-1b31b21b?st=o5kvwf&reflink=desktopwebshare_permalink)

</div>

It’s largely up to companies to test whether their AI is capable of
superhuman harm. At Anthropic, the Frontier Red Team assesses the risk
of catastrophe.

</div>

<div class="card">

<div class="card-title">

[What are Hallucinations in LLMs and 6 Effective Strategies to Prevent
Them](https://www.marktechpost.com/2024/12/08/what-are-hallucinations-in-llms-and-6-effective-strategies-to-prevent-them/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/12/artificial-intelligence-7328587_1280.jpg)](https://www.marktechpost.com/2024/12/08/what-are-hallucinations-in-llms-and-6-effective-strategies-to-prevent-them/)

</div>

In large language models (LLMs), “hallucination” refers to instances
where models generate semantically or syntactically plausible outputs
but are factually incorrect or nonsensical. For example, a hallucination
occurs when a model provides erroneous information, such as stating that
Addison's disease causes “bright yellow skin” when, in fact, it causes
fatigue and low blood pressure. This phenomenon is a significant concern
in AI, as it can lead to the spread of false or misleading information.
The issue of AI hallucinations has been explored in various research
studies. A survey in “ACM Computing Surveys” describes hallucinations as
“unreal perceptions that feel real.”

</div>

<div class="card">

<div class="card-title">

[Countless.dev \| AI Model Comparison](https://countless.dev/)

</div>

<div class="card-image">

[![](https://countless.dev/preview.png)](https://countless.dev/)

</div>

Compare AI models easily! All providers in one place.

</div>

<div class="card">

<div class="card-title">

[AI Hallucinations: Why Large Language Models Make Things Up (And How to
Fix It) - kapa.ai - Instant AI answers to technical
questions](https://www.kapa.ai/blog/ai-hallucination)

</div>

<div class="card-image">

[![](https://framerusercontent.com/images/f4igsQq4o21p1I7eSKhe53nWNIQ.png)](https://www.kapa.ai/blog/ai-hallucination)

</div>

Kapa.ai turns your knowledge base into a reliable and production-ready
LLM-powered AI assistant that answers technical questions instantly.
Trusted by 100+ startups and enterprises incl. OpenAI, Docker, Mapbox,
Mixpanel and NextJS.

</div>

<div class="card">

<div class="card-title">

[How to Build a General-Purpose LLM
Agent](https://towardsdatascience.com/build-a-general-purpose-ai-agent-c40be49e7400?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*KKKdVTkdU_39D7lrlw4Ugw.png)](https://towardsdatascience.com/build-a-general-purpose-ai-agent-c40be49e7400?source=rss----7f60cf5620c9---4)

</div>

A Step-by-Step Guide

</div>

<div class="card">

<div class="card-title">

[Four Cutting-Edge Methods for Evaluating AI Agents and Enhancing LLM
Performance](https://www.marktechpost.com/2024/11/28/four-cutting-edge-methods-for-evaluating-ai-agents-and-enhancing-llm-performance/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/11/ai-6767497_1280.jpg)](https://www.marktechpost.com/2024/11/28/four-cutting-edge-methods-for-evaluating-ai-agents-and-enhancing-llm-performance/)

</div>

The advent of LLMs has propelled advancements in AI for decades. One
such advanced application of LLMs is Agents, which replicate human
reasoning remarkably. An agent is a system that can perform complicated
tasks by following a reasoning process similar to humans: think
(solution to the problem), collect (context from past information),
analyze(the situations and data), and adapt (based on the style and
feedback). Agents encourage the system through dynamic and intelligent
activities, including planning, data analysis, data retrieval, and
utilizing the model's past experiences.  A typical agent has four
components: Brain: An LLM with advanced processing capabilities, such as

</div>

<div class="card">

<div class="card-title">

[llama.cpp guide - Running LLMs locally, on any hardware, from
scratch](https://steelph0enix.github.io/posts/llama-cpp-guide/)

</div>

<div class="card-image">

[![](https://steelph0enix.github.io/og-image.png)](https://steelph0enix.github.io/posts/llama-cpp-guide/)

</div>

Psst, kid, want some cheap and small LLMs?

</div>

<div class="card">

<div class="card-title">

[eugeneyan/llm-paper-notes: Notes from the Latent Space paper club.
Follow along or start your
own!](https://github.com/eugeneyan/llm-paper-notes)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/9c85f10ad2727a21d7a3aa7d87a46809444643e5d716c492825f63c34d60b7bd/eugeneyan/llm-paper-notes)](https://github.com/eugeneyan/llm-paper-notes)

</div>

Notes from the Latent Space paper club. Follow along or start your
own! - eugeneyan/llm-paper-notes

</div>

<div class="card">

<div class="card-title">

[Understanding Multimodal
LLMs](https://magazine.sebastianraschka.com/p/understanding-multimodal-llms)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc534f387-f776-41eb-9c65-f0032b91daee_1988x1430.png)](https://magazine.sebastianraschka.com/p/understanding-multimodal-llms)

</div>

An introduction to the main techniques and latest models

</div>

<div class="card">

<div class="card-title">

[Something weird is happening with LLMs and
chess](https://open.substack.com/pub/dynomight/p/chess?utm_campaign=post&utm_medium=web)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12c6f36a-6e5b-41fa-91d9-563757f83964_1440x900.jpeg)](https://open.substack.com/pub/dynomight/p/chess?utm_campaign=post&utm_medium=web)

</div>

Are they good or bad?

</div>

<div class="card">

<div class="card-title">

[Analyzing the homerun year for LLMs: the top-100 most cited AI papers
in 2023, with all medals for open
models.](https://www.zeta-alpha.com/post/analyzing-the-homerun-year-for-llms-the-top-100-most-cited-ai-papers-in-2023-with-all-medals-for-o)

</div>

9 October 2024, Mathias Parisot, Jakub Zavrel.Even in the red hot global
race for AI dominance, you publish and you perish, unless your peers
pick up your work, build further on it, and you manage to drive real
progress in the field. And of course, we are all very curious who is
currently having that kind of impact. Are the billions of dollars spent
on AI R&D paying off in the long run? So here is, in continuation of our
popular publication impact analysis of last year, Zeta Alpha's ranking
of t

</div>

<div class="card">

<div class="card-title">

[LLM Chunking, Indexing, Scoring and Agents, in a Nutshell -
DataScienceCentral.com](https://www.datasciencecentral.com/llm-chunking-indexing-scoring-and-agents-in-a-nutshell/)

</div>

<div class="card-image">

[![](https://www.datasciencecentral.com/wp-content/uploads/2024/10/xllm-diagram6.png)](https://www.datasciencecentral.com/llm-chunking-indexing-scoring-and-agents-in-a-nutshell/)

</div>

LLM Chunking, Indexing, Scoring and Agents, in a Nutshell. The new
PageRank of RAG/LLM. With details on building relevancy scores.

</div>

<div class="card">

<div class="card-title">

[Developing a computer use
model](https://www.anthropic.com/research/developing-computer-use?ref=thediff.co)

</div>

<div class="card-image">

[![](https://cdn.sanity.io/images/4zrzovbb/website/393cf77dd5c15761c47f2db9f80e30b4f6309708-2880x1620.png)](https://www.anthropic.com/research/developing-computer-use?ref=thediff.co)

</div>

A discussion of how Anthropic's researchers developed Claude's new
computer use skill, along with some relevant safety considerations

</div>

<div class="card">

<div class="card-title">

[Nvidia just dropped a new AI model that crushes OpenAI’s GPT-4—no big
launch, just big
results](https://venturebeat.com/ai/nvidia-just-dropped-a-new-ai-model-that-crushes-openais-gpt-4-no-big-launch-just-big-results/)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_a_brilliant_sunrise_but_instead_of_a_natural_landscap_2765f9f2-d796-4207-977a-b27e6281faf3.webp?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/nvidia-just-dropped-a-new-ai-model-that-crushes-openais-gpt-4-no-big-launch-just-big-results/)

</div>

Nvidia quietly launched a groundbreaking AI model that surpasses
OpenAI’s GPT-4 and Anthropic’s Claude 3.5, signaling a major shift in
the competitive landscape of artificial intelligence.

</div>

<div class="card">

<div class="card-title">

[Claude: Everything you need to know about Anthropic's AI \|
TechCrunch](https://techcrunch.com/2024/10/19/claude-everything-you-need-to-know-about-anthropics-ai/)

</div>

<div class="card-image">

[![](https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675)](https://techcrunch.com/2024/10/19/claude-everything-you-need-to-know-about-anthropics-ai/)

</div>

Anthropic, the AI vendor second in size only to OpenAI, has a powerful
family of generative AI models called Claude. These models can perform a
range of

</div>

<div class="card">

<div class="card-title">

[LightLLM: A Lightweight Scalable and High-Speed Python Framework for
LLM Inference and
Serving](https://www.marktechpost.com/2024/10/02/lightllm-a-lightweight-scalable-and-high-speed-python-framework-for-llm-inference-and-serving)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/10/Screenshot-2024-10-01-at-7.55.06-PM.png)](https://www.marktechpost.com/2024/10/02/lightllm-a-lightweight-scalable-and-high-speed-python-framework-for-llm-inference-and-serving)

</div>

Large language models (LLMs) have advanced significantly in recent
years. However, its real-world applications are restricted due to
substantial processing power and memory requirements. The need to make
LLMs more accessible on smaller and resource-limited devices drives the
development of more efficient frameworks for model inference and
deployment. Existing methods for running LLMs include hardware
acceleration techniques and optimizations like quantization and pruning.
However, these methods often fail to provide a balance between model
size, performance, and usability in constrained environments. 
Researchers developed an efficient, scalable, and lightweight framework
for LLM inference, LightLLM, to address the challenge of efficiently
deploying

</div>

<div class="card">

<div class="card-title">

[Nvidia just dropped a bombshell: Its new AI model is open massive and
ready to rival
GPT-4](https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_a_human_brain_rendered_in_a_semi-transp_907d536c-6a14-4c28-8c81-3d144ea0de3e.webp?w=986?w=1200&strip=all)](https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4)

</div>

Nvidia has released NVLM 1.0, a powerful open-source AI model that
rivals GPT-4 and Google’s systems, marking a major breakthrough in
multimodal language models for vision and text tasks.

</div>

<div class="card">

<div class="card-title">

[Ten Effective Strategies to Lower Large Language Model (LLM) Inference
Costs](https://www.marktechpost.com/2024/10/01/ten-effective-strategies-to-lower-large-language-model-llm-inference-costs)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-10.05.05-PM-1024x798.png)](https://www.marktechpost.com/2024/10/01/ten-effective-strategies-to-lower-large-language-model-llm-inference-costs)

</div>

Large Language Models (LLMs) have become a cornerstone in artificial
intelligence, powering everything from chatbots and virtual assistants
to advanced text generation and translation systems. Despite their
prowess, one of the most pressing challenges associated with these
models is the high cost of inference. This cost includes computational
resources, time, energy consumption, and hardware wear. Optimizing these
costs is paramount for businesses and researchers aiming to scale their
AI operations without breaking the bank. Here are ten proven strategies
to reduce LLM inference costs while maintaining performance and
accuracy: Quantization Quantization is a technique that decreases the
precision of model

</div>

<div class="card">

<div class="card-title">

[5 LLM Tools I Can’t Live
Without](https://www.kdnuggets.com/5-llm-tools-i-cant-live-without)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/kdn-5-llm-tools-cant-live-without.png)](https://www.kdnuggets.com/5-llm-tools-i-cant-live-without)

</div>

In this article, I share the five essential LLM tools that I currently
find indispensable, and which have the potential to help revolutionize
the way you work.

</div>

<div class="card">

<div class="card-title">

[FlashSigmoid: A Hardware-Aware and Memory-Efficient Implementation of
Sigmoid Attention Yielding a
1](https://www.marktechpost.com/2024/09/13/flashsigmoid-a-hardware-aware-and-memory-efficient-implementation-of-sigmoid-attention-yielding-a-17-inference-kernel-speed-up-over-flashattention-2-on-h100-gpus)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-13-at-5.26.21-PM.png)](https://www.marktechpost.com/2024/09/13/flashsigmoid-a-hardware-aware-and-memory-efficient-implementation-of-sigmoid-attention-yielding-a-17-inference-kernel-speed-up-over-flashattention-2-on-h100-gpus)

</div>

Large Language Models (LLMs) have gained significant prominence in
modern machine learning, largely due to the attention mechanism. This
mechanism employs a sequence-to-sequence mapping to construct
context-aware token representations. Traditionally, attention relies on
the softmax function (SoftmaxAttn) to generate token representations as
data-dependent convex combinations of values. However, despite its
widespread adoption and effectiveness, SoftmaxAttn faces several
challenges. One key issue is the tendency of the softmax function to
concentrate attention on a limited number of features, potentially
overlooking other informative aspects of the input data. Also, the
application of SoftmaxAttn necessitates a row-wise reduction along the
input sequence length,

</div>

<div class="card">

<div class="card-title">

[Top 9 Different Types of Retrieval-Augmented Generation
(RAGs)](https://www.marktechpost.com/2024/09/14/top-9-different-types-of-retrieval-augmented-generation-rags)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/09/P0z9zxKgRaSehlAFs0QzfQ.jpg)](https://www.marktechpost.com/2024/09/14/top-9-different-types-of-retrieval-augmented-generation-rags)

</div>

Retrieval-Augmented Generation (RAG) is a machine learning framework
that combines the advantages of both retrieval-based and
generation-based models. The RAG framework is highly regarded for its
ability to handle large amounts of information and produce coherent,
contextually accurate responses. It leverages external data sources by
retrieving relevant documents or facts and then generating an answer or
output based on the retrieved information and the user query. This blend
of retrieval and generation leads to better-informed outputs that are
more accurate and comprehensive than models that rely solely on
generation. The evolution of RAG has led to various types and
approaches,

</div>

<div class="card">

<div class="card-title">

[Graphiti: A Python Library for Building Temporal Knowledge Graphs Using
LLMs](https://www.marktechpost.com/2024/09/14/graphiti-a-python-library-for-building-temporal-knowledge-graphs-using-llms)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-13-at-10.36.15-PM.png)](https://www.marktechpost.com/2024/09/14/graphiti-a-python-library-for-building-temporal-knowledge-graphs-using-llms)

</div>

The challenge of managing and recalling facts from complex, evolving
conversations is a key problem for many AI-driven applications. As
information grows and changes over time, maintaining accurate context
becomes increasingly difficult. Current systems often struggle to handle
the evolving nature of relationships and facts, leading to incomplete or
irrelevant results when retrieving information. This can affect the
effectiveness of AI agents, especially when dealing with user memories
and context in real-time applications. Some existing solutions have
attempted to address this problem. One common approach is using a
Retrieval-Augmented Generation (RAG) pipeline, which involves storing
extracted facts and using techniques

</div>

<div class="card">

<div class="card-title">

[LlamaIndex : LlamaIndex](https://docs.llamaindex.ai/en/stable)

</div>

</div>

<div class="card">

<div class="card-title">

[Why GPU Utilization Falls Short: Understanding Streaming Multiprocessor
(SM) Efficiency for Better
L](https://www.marktechpost.com/2024/09/03/why-gpu-utilization-falls-short-understanding-streaming-multiprocessor-sm-efficiency-for-better-llm-performance)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/09/Screenshot-2024-09-03-at-6.18.46-PM.png)](https://www.marktechpost.com/2024/09/03/why-gpu-utilization-falls-short-understanding-streaming-multiprocessor-sm-efficiency-for-better-llm-performance)

</div>

Large Language Models (LLMs) have gained significant prominence in
recent years, driving the need for efficient GPU utilization in machine
learning tasks. However, researchers face a critical challenge in
accurately assessing GPU performance. The commonly used metric, GPU
Utilization, accessed through nvidia-smi or integrated observability
tools, has proven to be an unreliable indicator of actual computational
efficiency. Surprisingly, 100% GPU utilization can be achieved merely by
reading and writing to memory without performing any computations. This
revelation has sparked a reevaluation of performance metrics and
methodologies in the field of machine learning, prompting researchers to
seek more accurate ways to

</div>

<div class="card">

<div class="card-title">

[Building a Simple RAG Application Using LlamaIndex -
MachineLearningMastery.com](https://machinelearningmastery.com/building-a-simple-rag-application-using-llamaindex)

</div>

<div class="card-image">

[![](https://machinelearningmastery.com/wp-content/uploads/2024/08/mlm-awan-rag-applications-llamaindex.png)](https://machinelearningmastery.com/building-a-simple-rag-application-using-llamaindex)

</div>

\[caption align=

</div>

<div class="card">

<div class="card-title">

[Firecrawl: A Powerful Web Scraping Tool for Turning Websites into Large
Lan](https://www.marktechpost.com/2024/06/20/firecrawl-a-powerful-web-scraping-tool-for-turning-websites-into-large-language-model-llm-ready-markdown-or-structured-data)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-20-at-9.54.36-AM.png)](https://www.marktechpost.com/2024/06/20/firecrawl-a-powerful-web-scraping-tool-for-turning-websites-into-large-language-model-llm-ready-markdown-or-structured-data)

</div>

In the rapidly advancing field of Artificial Intelligence (AI),
effective use of web data can lead to unique applications and insights.
A recent tweet has brought attention to Firecrawl, a potent tool in this
field created by the Mendable AI team. Firecrawl is a state-of-the-art
web scraping program made to tackle the complex problems involved in
getting data off the internet. Web scraping is useful, but it frequently
requires overcoming various challenges like proxies, caching, rate
limitations, and material generated with JavaScript. Firecrawl is a
vital tool for data scientists because it addresses these issues
head-on. Even without a sitemap,

</div>

<div class="card">

<div class="card-title">

[What We Learned from a Year of Building with LLMs (Part
I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i)

</div>

<div class="card-image">

[![](https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/na-synapse-2a-1400x950-1.jpg)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i)

</div>

</div>

<div class="card">

<div class="card-title">

[dpo-from-scratch.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb)

</div>

<div class="card-image">

[![](https://repository-images.githubusercontent.com/669879380/79da1d51-4ef9-4733-a61c-1d7851020d9a)](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb)

</div>

Implementing a ChatGPT-like LLM in PyTorch from scratch, step by step -
rasbt/LLMs-from-scratch

</div>

<div class="card">

<div class="card-title">

[Towards Monosemanticity: A step towards understanding large language
models](https://towardsdatascience.com/towards-monosemanticity-a-step-towards-understanding-large-language-models-e7b88380d7b3?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:724/0*fxI8N7ewAnL8r14A)](https://towardsdatascience.com/towards-monosemanticity-a-step-towards-understanding-large-language-models-e7b88380d7b3?source=rss----7f60cf5620c9---4)

</div>

Understanding the mechanistic interpretability research problem and
reverse-engineering these large language models

</div>

<div class="card">

<div class="card-title">

[Meta unleashes its most powerful AI model, Llama 3.1, with 405B
parameters](https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2024/04/nuneybits_Vector_art_of_a_llama_in_a_blazing_fast_racecar_7f670485-6ad6-482b-ae36-c52aa0cf61a6-transformed-1.webp?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters)

</div>

Llama 3.1 is the latest version of Meta's large language models, with a
new model weight, 405 billion parameters, the biggest model it's
trained.

</div>

<div class="card">

<div class="card-title">

[Customize Generative AI Models for Enterprise Applications with Llama
3.1](https://developer.nvidia.com/blog/customize-generative-ai-models-for-enterprise-applications-with-llama-3-1)

</div>

<div class="card-image">

[![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/04/dev-llama3-blog-1920x1080-1.png)](https://developer.nvidia.com/blog/customize-generative-ai-models-for-enterprise-applications-with-llama-3-1)

</div>

The newly unveiled Llama 3.1 collection of 8B, 70B, and 405B large
language models (LLMs) is narrowing the gap between proprietary and
open-source models. Their open nature is attracting more…

</div>

<div class="card">

<div class="card-title">

[Llama 3.1 Released: Meta’s New Open-Source AI Model that You can
Fine-Tune,](https://www.marktechpost.com/2024/07/23/llama-3-1-released-metas-new-open-source-ai-model-that-you-can-fine-tune-distill-and-deploy-anywhere-and-available-in-8b-70b-and-405b)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/07/Screenshot-2024-07-23-at-5.29.09-PM.png)](https://www.marktechpost.com/2024/07/23/llama-3-1-released-metas-new-open-source-ai-model-that-you-can-fine-tune-distill-and-deploy-anywhere-and-available-in-8b-70b-and-405b)

</div>

Meta announced the release of Llama 3.1, the most capable model in the
LLama Series. This latest iteration of the Llama series, particularly
the 405B model, represents a substantial advancement in open-source AI
capabilities, positioning Meta at the forefront of AI innovation.  Meta
has long advocated for open-source AI, a stance underscored by Mark
Zuckerberg’s assertion that open-source benefits developers, Meta, and
society. Llama 3.1 embodies this philosophy by offering state-of-the-art
capabilities in an openly accessible model. The release aims to
democratize AI, making cutting-edge technology available to various
users and applications. The Llama 3.1 405B model stands out for

</div>

<div class="card">

<div class="card-title">

[Meta Llama 3.1 405b is outperforming private models with open
access](https://dataconomy.com/2024/07/24/meta-llama-3-1-405b-comparison-features)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2024/07/meta-llama-3.1-405b_3.jpg)](https://dataconomy.com/2024/07/24/meta-llama-3-1-405b-comparison-features)

</div>

Meta llama 3.1 405b kicks off a fresh chapter for open-source language
models. This breakthrough brings unmatched skills to AI

</div>

<div class="card">

<div class="card-title">

[Understanding Positional Embeddings in Transformers: From Absolute to
Rotar](https://towardsdatascience.com/understanding-positional-embeddings-in-transformers-from-absolute-to-rotary-31c082e16b26)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*EWz8ImltNHpDjMB8bOq_tQ.png)](https://towardsdatascience.com/understanding-positional-embeddings-in-transformers-from-absolute-to-rotary-31c082e16b26)

</div>

A deep dive into absolute, relative, and rotary positional embeddings
with code examples

</div>

<div class="card">

<div class="card-title">

[Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)

</div>

<div class="card-image">

[![](https://cdn.sanity.io/images/4zrzovbb/website/8a4eb6c412e5e7ffa38f07233344f4b7e6644994-2400x1200.png)](https://www.anthropic.com/news/claude-3-5-sonnet)

</div>

Introducing Claude 3.5 Sonnet—our most intelligent model yet. Sonnet now
outperforms competitor models and Claude 3 Opus on key evaluations, at
twice the speed.

</div>

<div class="card">

<div class="card-title">

[Do large language models understand the
world?](https://www.amazon.science/blog/do-large-language-models-understand-the-world)

</div>

<div class="card-image">

[![](https://assets.amazon.science/dims4/default/a919bc2/2147483647/strip/true/crop/1920x1008+0+36/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F17%2F0b%2Ff4768ae249509d4697b1c705457a%2Fmultimodal-projection.png)](https://www.amazon.science/blog/do-large-language-models-understand-the-world)

</div>

In addition to its practical implications, recent work on “meaning
representations” could shed light on some old philosophical questions.

</div>

<div class="card">

<div class="card-title">

[Building an LLM Router for High-Quality and Cost-Effective
Responses](https://www.anyscale.com/blog/building-an-llm-router-for-high-quality-and-cost-effective-responses)

</div>

<div class="card-image">

[![](https://images.ctfassets.net/xjan103pcp94/jYOVHq6FxnQ2vocwXPAbn/02aa8be5b68f2a7585ae375d5b38b015/Anyscale_-_LLM_Router.png)](https://www.anyscale.com/blog/building-an-llm-router-for-high-quality-and-cost-effective-responses)

</div>

Anyscale is the leading AI application platform. With Anyscale,
developers can build, run and scale AI applications instantly.

</div>

<div class="card">

<div class="card-title">

[From bare metal to a 70B model: infrastructure set-up and scripts -
imbue](https://imbue.com/research/70b-infrastructure)

</div>

<div class="card-image">

[![](https://generallyintelligent.com/preview/70b-infra-social.png)](https://imbue.com/research/70b-infrastructure)

</div>

We would like to thank Voltage Park, Dell, H5, and NVIDIA for their
invaluable partnership and help with setting up our cluster. A special…

</div>

<div class="card">

<div class="card-title">

[StarCoder2-15B: A Powerful LLM for Code Generation, Summarization, and
Docu](https://nvda.ws/3XJa8l9#new_tab)

</div>

<div class="card-image">

[![](https://build.nvidia.com/opengraph-image.jpg?6ec102a0470b935b)](https://nvda.ws/3XJa8l9#new_tab)

</div>

Experience the leading models to build enterprise generative AI apps
now.

</div>

<div class="card">

<div class="card-title">

[How Gradient created an open LLM with a million-token context
window](https://venturebeat.com/ai/how-gradient-created-an-open-llm-with-a-million-token-context-window)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2024/06/inifinite-tokens.jpg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/how-gradient-created-an-open-llm-with-a-million-token-context-window)

</div>

AI startup Gradient and cloud platform Crusoe teamed up to extend the
context window of Meta's Llama 3 models to 1 million tokens.

</div>

<div class="card">

<div class="card-title">

[Some Commonly Used Advanced Prompt Engineering Techniques Explained
Using
S](https://www.marktechpost.com/2024/06/21/some-commonly-used-advanced-prompt-engineering-techniques-explained-using-simple-human-analogies)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-21-at-9.14.00-PM.png)](https://www.marktechpost.com/2024/06/21/some-commonly-used-advanced-prompt-engineering-techniques-explained-using-simple-human-analogies)

</div>

In the developing field of Artificial Intelligence (AI), the ability to
think quickly has become increasingly significant. The necessity of
communicating with AI models efficiently becomes critical as these
models get more complex. In this article we will explain a number of
sophisticated prompt engineering strategies, simplifying these difficult
ideas through straightforward human metaphors. The techniques and their
examples have been discussed to see how they resemble human approaches
to problem-solving. Chaining Methods Analogy: Solving a problem
step-by-step. Chaining techniques are similar to solving an issue one
step at a time. Chaining techniques include directing the AI via a
systematic

</div>

<div class="card">

<div class="card-title">

[Key Metrics for Evaluating Large Language Models
(LLMs)](https://www.marktechpost.com/2024/06/19/key-metrics-for-evaluating-large-language-models-llms)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-19-at-7.20.10-PM-1024x906.png)](https://www.marktechpost.com/2024/06/19/key-metrics-for-evaluating-large-language-models-llms)

</div>

Evaluating Large Language Models (LLMs) is a challenging problem in
language modeling, as real-world problems are complex and variable.
Conventional benchmarks frequently fail to fully represent LLMs'
all-encompassing performance. A recent LinkedIn post has emphasized a
number of important measures that are essential to comprehend how well
new models function, which are as follows. MixEval Achieving a balance
between thorough user inquiries and effective grading systems is
necessary for evaluating LLMs. Conventional standards based on ground
truth and LLM-as-judge benchmarks encounter difficulties such as biases
in grading and possible contamination over time.  MixEval solves these
problems by combining real-world user

</div>

<div class="card">

<div class="card-title">

[Let's reproduce GPT-2
(124M)](https://m.youtube.com/watch?feature=youtu.be&v=l8pRSuU81PU)

</div>

<div class="card-image">

[![](https://i.ytimg.com/vi/l8pRSuU81PU/maxresdefault.jpg)](https://m.youtube.com/watch?feature=youtu.be&v=l8pRSuU81PU)

</div>

We reproduce the GPT-2 (124M) from scratch. This video covers the whole
process: First we build the GPT-2 network, then we optimize its training
to be really fast, then we set up the training run following the GPT-2
and GPT-3 paper and their hyperparameters, then we hit run, and come
back the next morning to see our results, and enjoy some amusing model
generations. Keep in mind that in some places this video builds on the
knowledge from earlier videos in the Zero to Hero Playlist (see my
channel). You could also see this video as building my nanoGPT repo,
which by the end is about 90% similar. Links: - build-nanogpt GitHub
repo, with all the changes in this video as individual commits:
https://github.com/karpathy/build-nanogpt - nanoGPT repo:
https://github.com/karpathy/nanoGPT - llm.c repo:
https://github.com/karpathy/llm.c - my website: https://karpathy.ai - my
twitter: https://twitter.com/karpathy - our Discord channel:
https://discord.gg/3zy8kqD9Cp Supplementary links: - Attention is All
You Need paper: https://arxiv.org/abs/1706.03762 - OpenAI GPT-3 paper:
https://arxiv.org/abs/2005.14165 - OpenAI GPT-2 paper:
https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf-
The GPU I'm training the model on is from Lambda GPU Cloud, I think the
best and easiest way to spin up an on-demand GPU instance in the cloud
that you can ssh to: https://lambdalabs.com Chapters: 00:00:00 intro:
Let’s reproduce GPT-2 (124M) 00:03:39 exploring the GPT-2 (124M) OpenAI
checkpoint 00:13:47 SECTION 1: implementing the GPT-2 nn.Module 00:28:08
loading the huggingface/GPT-2 parameters 00:31:00 implementing the
forward pass to get logits 00:33:31 sampling init, prefix tokens,
tokenization 00:37:02 sampling loop 00:41:47 sample, auto-detect the
device 00:45:50 let’s train: data batches (B,T) → logits (B,T,C)
00:52:53 cross entropy loss 00:56:42 optimization loop: overfit a single
batch 01:02:00 data loader lite 01:06:14 parameter sharing wte and
lm_head 01:13:47 model initialization: std 0.02, residual init 01:22:18
SECTION 2: Let’s make it fast. GPUs, mixed precision, 1000ms 01:28:14
Tensor Cores, timing the code, TF32 precision, 333ms 01:39:38 float16,
gradient scalers, bfloat16, 300ms 01:48:15 torch.compile, Python
overhead, kernel fusion, 130ms 02:00:18 flash attention, 96ms 02:06:54
nice/ugly numbers. vocab size 50257 → 50304, 93ms 02:14:55 SECTION 3:
hyperpamaters, AdamW, gradient clipping 02:21:06 learning rate
scheduler: warmup + cosine decay 02:26:21 batch size schedule, weight
decay, FusedAdamW, 90ms 02:34:09 gradient accumulation 02:46:52
distributed data parallel (DDP) 03:10:21 datasets used in GPT-2, GPT-3,
FineWeb (EDU) 03:23:10 validation data split, validation loss, sampling
revive 03:28:23 evaluation: HellaSwag, starting the run 03:43:05 SECTION
4: results in the morning! GPT-2, GPT-3 repro 03:56:21 shoutout to
llm.c, equivalent but faster code in raw C/CUDA 03:59:39 summary, phew,
build-nanogpt github repo Corrections: I will post all errata and
followups to the build-nanogpt GitHub repo (link above) SuperThanks: I
experimentally enabled them on my channel yesterday. Totally optional
and only use if rich. All revenue goes to to supporting my work in AI +
Education.

</div>

<div class="card">

<div class="card-title">

[How to use an open source LLM model locally and
remotely](https://thoughtbot.com/blog/how-to-use-open-source-LLM-model-locally)

</div>

<div class="card-image">

[![](https://images.prismic.io/thoughtbot-website/Zn0Q2JbWFbowe7qY_default-article-background.png?auto=format%2Ccompress&mark-x=356&mark-y=100&mark64=aHR0cHM6Ly9hc3NldHMuaW1naXgubmV0L350ZXh0Lz90eHQtbGVhZD0wJnR4dC10cmFjaz0wJnR4dDY0PVNHOTNJSFJ2SUhWelpTQmhiaUJ2Y0dWdUlITnZkWEpqWlNCTVRFMGdiVzlrWld3Z2JHOWpZV3hzZVNCaGJtUWdjbVZ0YjNSbGJIayUzRCZ0eHRjbHI9ZjVmNWY1JnR4dGZvbnQ9SUJNUGxleFNhbnNKUC1TZW1pQm9sZCZ0eHRwYWQ9MCZ0eHRzaXplPTY0Jnc9ODAw&txt-align=center%2Cmiddle&txt-color=f5f5f5&txt-fit=max&txt-font=IBMPlexSansJP-SemiBold&txt-size=24&txt-x=391&txt-y=526&txt=Jose+Blanco)](https://thoughtbot.com/blog/how-to-use-open-source-LLM-model-locally)

</div>

Run an open source language model in your local machine and remotely.

</div>

<div class="card">

<div class="card-title">

[“The” Midjourney model personalization
guide](https://dataconomy.com/2024/06/12/midjourney-model-personalization-guide)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2024/06/How-to-use-Midjourney-model-personalization_09.jpg)](https://dataconomy.com/2024/06/12/midjourney-model-personalization-guide)

</div>

Midjourney model personalization is now live, offering you a more
tailored image generation experience by teaching the AI your
preferences.

</div>

<div class="card">

<div class="card-title">

[How to use Perplexity in your PM
work](https://www.lennysnewsletter.com/p/how-to-use-perplexity-in-your-pm)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1fde139e-dc49-4a91-ae41-7e757873532b_1920x1440.png)](https://www.lennysnewsletter.com/p/how-to-use-perplexity-in-your-pm)

</div>

27 examples (with actual prompts) of how product managers are using
Perplexity today

</div>

<div class="card">

<div class="card-title">

[\[2406.01506\] The Geometry of Categorical and Hierarchical Concepts in
Large](https://arxiv.org/abs/2406.01506)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2406.01506)

</div>

The linear representation hypothesis is the informal idea that semantic
concepts are encoded as linear directions in the representation spaces
of large language models (LLMs). Previous work has...

</div>

<div class="card">

<div class="card-title">

[What We Learned from a Year of Building with LLMs (Part
II)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii)

</div>

<div class="card-image">

[![](https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/na-synapse-1a-1400x950-1.jpg)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii)

</div>

</div>

<div class="card">

<div class="card-title">

[Sharpening LLMs: The Sharpest Tools and Essential Techniques for
Precision](https://www.marktechpost.com/2024/06/07/sharpening-llms-the-sharpest-tools-and-essential-techniques-for-precision-and-clarity)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-07-at-11.04.45-PM-1024x825.png)](https://www.marktechpost.com/2024/06/07/sharpening-llms-the-sharpest-tools-and-essential-techniques-for-precision-and-clarity)

</div>

The ability to discern relevant and essential information from noise is
paramount in AI, particularly within large language models (LLMs). With
the surge of information and the complexity of tasks, there's a need for
efficient mechanisms to enhance the performance and reliability of these
models. Let’s explore the essential tools & techniques for refining LLMs
and delivering precise, actionable insights. The focus will be on
Retrieval-Augmented Generation (RAG), agentic functions, Chain of
Thought (CoT) prompting, few-shot learning, prompt engineering, and
prompt optimization. Retrieval-Augmented Generation (RAG): Providing
Relevant Context RAG combines the power of retrieval mechanisms with
generative models, ensuring that

</div>

<div class="card">

<div class="card-title">

[List of Activities and Their Corresponding Suitable LLMs in the
Artificial](https://www.marktechpost.com/2024/06/08/list-of-activities-and-their-corresponding-suitable-llms-in-the-artificial-intelligence-ai-world-right-now-a-comprehensive-guide)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/06/Screenshot-2024-06-07-at-11.35.01-PM-1024x1005.png)](https://www.marktechpost.com/2024/06/08/list-of-activities-and-their-corresponding-suitable-llms-in-the-artificial-intelligence-ai-world-right-now-a-comprehensive-guide)

</div>

Choosing large language models (LLMs) tailored for specific tasks is
crucial for maximizing efficiency and accuracy. With natural language
processing (NLP) advancements, different models have emerged, each
excelling in unique domains. Here is a comprehensive guide to the most
suitable LLMs for various activities in the AI world. Hard Document
Understanding: Claude Opus Claude Opus excels at tasks requiring deep
understanding and interpretation of complex documents. This model excels
in parsing dense legal texts, scientific papers, and intricate technical
manuals. Claude Opus is designed to handle extensive context windows,
ensuring it captures nuanced details and complicated relationships
within the text.

</div>

<div class="card">

<div class="card-title">

[Three Things to Know About Prompting
LLMs](https://sloanreview.mit.edu/article/three-things-to-know-about-prompting-llms)

</div>

<div class="card-image">

[![](https://sloanreview.mit.edu/wp-content/uploads/2024/06/2024SUM_Radar_3Things-2400x1260-1-1200x630.jpg)](https://sloanreview.mit.edu/article/three-things-to-know-about-prompting-llms)

</div>

Apply these techniques when crafting prompts for large language models
to elicit more relevant responses.

</div>

<div class="card">

<div class="card-title">

[Perplexity goes beyond AI search, launches publishing platform
‘Pages’](https://venturebeat.com/ai/perplexity-goes-beyond-ai-search-launches-publishing-platform-pages)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2024/05/a-robot-with-perplexity-written-on-its-torso-writi-2zEVq32AQdS313p_LPegMg-P4QVESWwSYKx383_3HyEAA.jpeg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/perplexity-goes-beyond-ai-search-launches-publishing-platform-pages)

</div>

In most cases, Perplexity produced the desired Pages, but what we found
missing was the option to edit the content manually.

</div>

<div class="card">

<div class="card-title">

[The Great AI Chatbot Challenge: ChatGPT vs. Gemini vs. Copilot vs.
Perplexi](https://www.wsj.com/tech/personal-tech/ai-chatbots-chatgpt-gemini-copilot-perplexity-claude-f9e40d26?reflink=desktopwebshare_permalink&st=qr25rixxk1o73s6)

</div>

<div class="card-image">

[![](https://images.wsj.net/im-963856/social)](https://www.wsj.com/tech/personal-tech/ai-chatbots-chatgpt-gemini-copilot-perplexity-claude-f9e40d26?reflink=desktopwebshare_permalink&st=qr25rixxk1o73s6)

</div>

We tested OpenAI’s ChatGPT against Microsoft’s Copilot and Google’s
Gemini, along with Perplexity and Anthropic’s Claude. Here’s how they
ranked.

</div>

<div class="card">

<div class="card-title">

[The future of foundation models is
closed-source](https://www.thediff.co/r/8f054236?m=5ba63d9b-6620-4051-8686-515cd8a8f374)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F583eeedb-53b8-40b5-8f47-9520bc7b8037_1600x1600.png)](https://www.thediff.co/r/8f054236?m=5ba63d9b-6620-4051-8686-515cd8a8f374)

</div>

if the centralizing forces of data and compute hold, open and
closed-source AI cannot both dominate long-term

</div>

<div class="card">

<div class="card-title">

[Demystifying Vision-Language Models: An In-Depth
Exploration](https://www.marktechpost.com/2024/05/23/demystifying-vision-language-models-an-in-depth-exploration)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-16-at-12.00.13-AM.png)](https://www.marktechpost.com/2024/05/23/demystifying-vision-language-models-an-in-depth-exploration)

</div>

Vision-language models (VLMs), capable of processing both images and
text, have gained immense popularity due to their versatility in solving
a wide range of tasks, from information retrieval in scanned documents
to code generation from screenshots. However, the development of these
powerful models has been hindered by a lack of understanding regarding
the critical design choices that truly impact their performance. This
knowledge gap makes it challenging for researchers to make meaningful
progress in this field. To address this issue, a team of researchers
from Hugging Face and Sorbonne Université conducted extensive
experiments to unravel the factors that matter the

</div>

<div class="card">

<div class="card-title">

[AI Is a Black Box. Anthropic Figured Out a Way to Look
Inside](https://www.wired.com/story/anthropic-black-box-ai-research-neurons-features)

</div>

<div class="card-image">

[![](https://media.wired.com/photos/664baa1664e0ebc8ca8bea4f/191:100/w_1280,c_limit/AI-Black-Box-Business-Site-921311988.jpg)](https://www.wired.com/story/anthropic-black-box-ai-research-neurons-features)

</div>

What goes on in artificial neural networks work is largely a mystery,
even to their creators. But researchers from Anthropic have caught a
glimpse.

</div>

<div class="card">

<div class="card-title">

[naklecha/llama3-from-scratch](https://github.com/naklecha/llama3-from-scratch)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/8d2e244aeba16103152d524e2782f1a003e33ae090eae093973ff64f742be56b/naklecha/llama3-from-scratch)](https://github.com/naklecha/llama3-from-scratch)

</div>

llama3 implementation one matrix multiplication at a time -
naklecha/llama3-from-scratch

</div>

<div class="card">

<div class="card-title">

[Abacus AI Releases Smaug-Llama-3-70B-Instruct: The New Benchmark in
Open-So](https://www.marktechpost.com/2024/05/20/abacus-ai-releases-smaug-llama-3-70b-instruct-the-new-benchmark-in-open-source-conversational-ai-rivaling-gpt-4-turbo)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/05/Blog-Banner-3.png)](https://www.marktechpost.com/2024/05/20/abacus-ai-releases-smaug-llama-3-70b-instruct-the-new-benchmark-in-open-source-conversational-ai-rivaling-gpt-4-turbo)

</div>

Artificial intelligence (AI) has revolutionized various fields by
introducing advanced models for natural language processing (NLP). NLP
enables computers to understand, interpret, and respond to human
language in a valuable way. This field encompasses text generation,
translation, and sentiment analysis applications, significantly
impacting industries like healthcare, finance, and customer service. The
evolution of NLP models has driven these advancements, continually
pushing the boundaries of what AI can achieve in understanding and
generating human language. Despite these advancements, developing models
that can effectively handle complex multi-turn conversations remains a
persistent challenge. Existing models often fail to maintain context and
coherence over

</div>

<div class="card">

<div class="card-title">

[Do Enormous LLM Context Windows Spell the End of
RAG?](https://thenewstack.io/do-enormous-llm-context-windows-spell-the-end-of-rag)

</div>

<div class="card-image">

[![](https://cdn.thenewstack.io/media/2024/05/3724b60a-enormous-llm-context-windows-end-of-rag.jpg)](https://thenewstack.io/do-enormous-llm-context-windows-spell-the-end-of-rag)

</div>

Now that LLMs can retrieve 1 million tokens at once, how long will it be
until we don’t need retrieval augmented generation for accurate AI
responses?

</div>

<div class="card">

<div class="card-title">

[How Good Are the Latest Open LLMs? And Is DPO Better Than
PPO?](https://sebastianraschka.com/blog/2024/how-good-open-llm.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2024/how-good-open-llm/hero.jpg)](https://sebastianraschka.com/blog/2024/how-good-open-llm.html)

</div>

What a month! We had four major open LLM releases: Mixtral, Meta AI's
Llama 3, Microsoft's Phi-3, and Apple's OpenELM. In my new article, I
review and discus...

</div>

<div class="card">

<div class="card-title">

[ChuXin: A Fully Open-Sourced Language Model with a Size of 1.6 Billion
Para](https://www.marktechpost.com/2024/05/11/chuxin-a-fully-open-sourced-language-model-with-a-size-of-1-6-billion-parameters)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-11-at-5.09.31-PM.png)](https://www.marktechpost.com/2024/05/11/chuxin-a-fully-open-sourced-language-model-with-a-size-of-1-6-billion-parameters)

</div>

The capacity of large language models (LLMs) to produce adequate text in
various application domains has caused a revolution in natural language
creation. These models are essentially two types: 1) Most model weights
and data sources are open source. 2) All model-related information is
publicly available, including training data, data sampling ratios,
training logs, intermediate checkpoints, and assessment methods
(Tiny-Llama, OLMo, and StableLM 1.6B). Full access to open language
models for the research community is vital for thoroughly investigating
these models' capabilities and limitations and understanding their
inherent biases and potential risks. This is necessary despite the
continued breakthroughs in

</div>

<div class="card">

<div class="card-title">

[Title:You Only Cache Once: Decoder-Decoder Architectures for Language
Model](https://arxiv.org/abs/2405.05254)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2405.05254)

</div>

We introduce a decoder-decoder architecture, YOCO, for large language
models, which only caches key-value pairs once. It consists of two
components, i.e., a cross-decoder stacked upon a...

</div>

<div class="card">

<div class="card-title">

[Anthropic AI Launches a Prompt Engineering Tool that Generates
Production-R](https://www.marktechpost.com/2024/05/10/anthropic-ai-launches-a-prompt-engineering-tool-that-generates-production-ready-prompts-in-the-anthropic-console)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/05/Anthropic-Gif-1024x576.gif)](https://www.marktechpost.com/2024/05/10/anthropic-ai-launches-a-prompt-engineering-tool-that-generates-production-ready-prompts-in-the-anthropic-console)

</div>

Generative AI (GenAI) tools have come a long way. Believe it or not, the
first generative AI tools were introduced in the 1960s in a Chatbot.
Still, it was only in 2014 that generative adversarial networks (GANs)
were introduced, a type of Machine Learning (ML) algorithm that allowed
generative AI to finally create authentic images, videos, and audio of
real people. In 2024, we can create anything imaginable using generative
AI tools like ChatGPT, DALL-E, and others.  However, there is a problem.
We can use those AI tools but can not get the most out of them or use
them

</div>

<div class="card">

<div class="card-title">

[Cleaning](https://docs.unstructured.io/open-source/core-functionality/cleaning)

</div>

<div class="card-image">

[![](https://mintlify.com/docs/api/og?division=Documentation&mode=dark&title=Cleaning&description=As+part+of+data+preparation+for+an+NLP+model%2C+it%E2%80%99s+common+to+need+to+clean+up+your+data+prior+to+passing+it+into+the+model.+If+there%E2%80%99s+unwanted+content+in+your+output%2C+for+example%2C+it+could+impact+the+quality+of+your+NLP+model.+To+help+with+this%2C+the+%60unstructured%60+library+includes+cleaning+functions+to+help+users+sanitize+output+before+sending+it+to+downstream+applications.&logoLight=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Funstructured-53%2Flogo%2Flight.png&logoDark=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Funstructured-53%2Flogo%2Fdark.png&primaryColor=%2309C6DE&lightColor=%2309C6DE&darkColor=%2309C6DE)](https://docs.unstructured.io/open-source/core-functionality/cleaning)

</div>

As part of data preparation for an NLP model, it’s common to need to
clean up your data prior to passing it into the model. If there’s
unwanted content in your output, for example, it could impact the
quality of your NLP model. To help with this, the \`unstructured\`
library includes cleaning functions to help users sanitize output before
sending it to downstream applications.

</div>

<div class="card">

<div class="card-title">

[\[2404.19737\] Better & Faster Large Language Models via Multi-token
Predicti](https://arxiv.org/abs/2404.19737)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2404.19737)

</div>

Large language models such as GPT and Llama are trained with a
next-token prediction loss. In this work, we suggest that training
language models to predict multiple future tokens at once results...

</div>

<div class="card">

<div class="card-title">

[Researchers at NVIDIA AI Introduce ‘VILA’: A Vision Language Model that
can](https://www.marktechpost.com/2024/05/04/researchers-at-nvidia-ai-introduce-vila-a-vision-language-model-that-can-reason-among-multiple-images-learn-in-context-and-even-understand-videos)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/05/Screenshot-2024-05-04-at-4.57.30-PM.png)](https://www.marktechpost.com/2024/05/04/researchers-at-nvidia-ai-introduce-vila-a-vision-language-model-that-can-reason-among-multiple-images-learn-in-context-and-even-understand-videos)

</div>

The rapid evolution in AI demands models that can handle large-scale
data and deliver accurate, actionable insights. Researchers in this
field aim to create systems capable of continuous learning and
adaptation, ensuring they remain relevant in dynamic environments. A
significant challenge in developing AI models lies in overcoming the
issue of catastrophic forgetting, where models fail to retain previously
acquired knowledge when learning new tasks. This challenge becomes more
pressing as applications increasingly demand continuous learning
capabilities. For instance, models must update their understanding of
healthcare, financial analysis, and autonomous systems while retaining
prior knowledge to make informed decisions. The

</div>

<div class="card">

<div class="card-title">

[Hugging Face - Documentation](https://huggingface.co/docs)

</div>

<div class="card-image">

[![](https://huggingface.co/front/thumbnails/docs.png)](https://huggingface.co/docs)

</div>

We’re on a journey to advance and democratize artificial intelligence
through open source and open science.

</div>

<div class="card">

<div class="card-title">

[Understanding Key Terminologies in Large Language Model (LLM)
Universe](https://www.marktechpost.com/2024/04/25/understanding-key-terminologies-in-large-language-model-llm-universe)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/04/Screenshot-2024-04-24-at-8.42.34-PM.png)](https://www.marktechpost.com/2024/04/25/understanding-key-terminologies-in-large-language-model-llm-universe)

</div>

Are you curious about the intricate world of large language models
(LLMs) and the technical jargon that surrounds them? Understanding the
terminology, from the foundational aspects of training and fine-tuning
to the cutting-edge concepts of transformers and reinforcement learning,
is the first step towards demystifying the powerful algorithms that
drive modern AI language systems. In this article, we delve into 25
essential terms to enhance your technical vocabulary and provide
insights into the mechanisms that make LLMs so transformative. Heatmap
representing the relative importance of terms in the context of LLMs
Source: marktechpost.com 1. LLM (Large Language Model) Large Language

</div>

<div class="card">

<div class="card-title">

[Top 15 AI Libraries/Frameworks for Automatically Red-Teaming Your
Generativ](https://www.marktechpost.com/2024/04/23/top-15-ai-libraries-frameworks-for-automatically-red-teaming-your-generative-ai-application)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/04/Screenshot-2024-04-22-at-8.55.47-PM-1024x962.png)](https://www.marktechpost.com/2024/04/23/top-15-ai-libraries-frameworks-for-automatically-red-teaming-your-generative-ai-application)

</div>

Prompt Fuzzer: The Prompt Fuzzer is an interactive tool designed to
evaluate the security of GenAI application system prompts by simulating
various dynamic LLM-based attacks. It assesses security by analyzing the
results of these simulations, helping users fortify their system prompts
accordingly. This tool specifically customizes its tests to fit the
unique configuration and domain of the user's application. The Fuzzer
also features a Playground chat interface, allowing users to refine
their system prompts iteratively, enhancing their resilience against a
broad range of generative AI attacks. Users should be aware that using
the Prompt Fuzzer will consume tokens. Garak: Garak

</div>

<div class="card">

<div class="card-title">

[Meta says Llama 3 beats most other models, including Gemini - The
Verge](https://www.theverge.com/2024/4/18/24134103/llama-3-benchmark-testing-ai-gemma-gemini-mistral)

</div>

<div class="card-image">

[![](https://cdn.vox-cdn.com/thumbor/aFVf1nZ5PjZNbxd151IaoqXfmvA=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951355/STK043_VRG_Illo_N_Barclay_1_Meta.jpg)](https://www.theverge.com/2024/4/18/24134103/llama-3-benchmark-testing-ai-gemma-gemini-mistral)

</div>

The models have some pretty good general knowledge.

</div>

<div class="card">

<div class="card-title">

[anthropics/anthropic-cookbook: A collection of notebooks/recipes
showcasing](https://github.com/anthropics/anthropic-cookbook)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/745bc9c2a06a632586be86215858e9baa9db7dd47ef54f48c99a0cc906248e09/anthropics/anthropic-cookbook)](https://github.com/anthropics/anthropic-cookbook)

</div>

A collection of notebooks/recipes showcasing some fun and effective ways
of using Claude. - anthropics/anthropic-cookbook

</div>

<div class="card">

<div class="card-title">

[Deep Learning Architectures From CNN, RNN, GAN, and Transformers To
Encoder](https://www.marktechpost.com/2024/04/12/deep-learning-architectures-from-cnn-rnn-gan-and-transformers-to-encoder-decoder-architectures)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/04/Hn6UWRfcQGS1sXgZTUWw6A.png)](https://www.marktechpost.com/2024/04/12/deep-learning-architectures-from-cnn-rnn-gan-and-transformers-to-encoder-decoder-architectures)

</div>

Deep learning architectures have revolutionized the field of artificial
intelligence, offering innovative solutions for complex problems across
various domains, including computer vision, natural language processing,
speech recognition, and generative models. This article explores some of
the most influential deep learning architectures: Convolutional Neural
Networks (CNNs), Recurrent Neural Networks (RNNs), Generative
Adversarial Networks (GANs), Transformers, and Encoder-Decoder
architectures, highlighting their unique features, applications, and how
they compare against each other. Convolutional Neural Networks (CNNs)
CNNs are specialized deep neural networks for processing data with a
grid-like topology, such as images. A CNN automatically detects the
important features without any human supervision.

</div>

<div class="card">

<div class="card-title">

[Tips for LLM Pretraining and Evaluating Reward
Models](https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms?isFreemail=true&post_id=142924793&publication_id=1174659&r=oc5d&triedRedirect=true)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fabd9ec-29f1-4c1c-85fb-8781e7c6ce0b_1600x436.png)](https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms?isFreemail=true&post_id=142924793&publication_id=1174659&r=oc5d&triedRedirect=true)

</div>

Discussing AI Research Papers in March 2024

</div>

<div class="card">

<div class="card-title">

[Lessons after a half-billion GPT tokens - Ken Kantzer's
Blog](https://kenkantzer.com/lessons-after-a-half-billion-gpt-tokens)

</div>

My startup Truss (gettruss.io) released a few LLM-heavy features in the
last six months, and the narrative around LLMs that I read on Hacker
News is now starting to diverge from my reality, so I thought I’d share
some of the more “surprising” lessons after churning through just north
of 500 million tokens, by my \[…\]

</div>

<div class="card">

<div class="card-title">

[5 Ways To Use LLMs On Your
Laptop](https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/awan_5_ways_llms_laptop_3.png)](https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop)

</div>

Run large language models on your local PC for customized AI
capabilities with more control, privacy, and personalization.

</div>

<div class="card">

<div class="card-title">

[Words are flowing out like endless rain: Recapping a busy week of LLM
news](https://arstechnica.com/information-technology/2024/04/words-are-flowing-out-like-endless-rain-recapping-a-busy-week-of-llm-news)

</div>

<div class="card-image">

[![](https://cdn.arstechnica.net/wp-content/uploads/2024/04/flying_letters.jpg)](https://arstechnica.com/information-technology/2024/04/words-are-flowing-out-like-endless-rain-recapping-a-busy-week-of-llm-news)

</div>

Gemini 1.5 Pro launch, new version of GPT-4 Turbo, new Mistral model,
and more.

</div>

<div class="card">

<div class="card-title">

[Gemini: A Family of Highly Capable Multimodal
Models](https://dev.to/mikeyoung44/gemini-a-family-of-highly-capable-multimodal-models-20gi)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fcgt3bt85na64kv6bddac.png)](https://dev.to/mikeyoung44/gemini-a-family-of-highly-capable-multimodal-models-20gi)

</div>

</div>

<div class="card">

<div class="card-title">

[Peter Gostev’s
Post](https://www.linkedin.com/posts/peter-gostev_we-are-seeing-some-clear-categories-emerge-activity-7183501457684365314-iihT)

</div>

<div class="card-image">

[![](https://media.licdn.com/dms/image/v2/D4E22AQFm3iXaCM_yFw/feedshare-shrink_800/feedshare-shrink_800/0/1712680209849?e=2147483647&v=beta&t=K5qJnHxnDnN2glIvEp6YWthqeqb7L5O7dMkk0DkFowU)](https://www.linkedin.com/posts/peter-gostev_we-are-seeing-some-clear-categories-emerge-activity-7183501457684365314-iihT)

</div>

We are seeing some clear categories emerge in the world of LLMs - 1)
affordable (~\$1 per million tokens); 2) mid-range (\$8/m) and 3) top
end (\$25-50/m)… \| 32 comments on LinkedIn

</div>

<div class="card">

<div class="card-title">

[Detecting Hallucinations in Large Language Models with Text Similarity
Metr](https://dev.to/rutamstwt/detecting-hallucinations-in-large-language-models-with-text-similarity-metrics-4lj3)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fko9r8rgbfqg18kirq32y.jpeg)](https://dev.to/rutamstwt/detecting-hallucinations-in-large-language-models-with-text-similarity-metrics-4lj3)

</div>

In the world of LLMs, there is a phenomenon known as "hallucinations."
These hallucinations are...

</div>

<div class="card">

<div class="card-title">

[Top Open Source Large Language Models (LLMs) Available For Commercial
Use](https://www.marktechpost.com/2024/04/02/top-open-source-large-language-models-llms-available-for-commercial-use)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/04/m31VipoLSf6blOs_CSgwnA.png)](https://www.marktechpost.com/2024/04/02/top-open-source-large-language-models-llms-available-for-commercial-use)

</div>

The top open source Large Language Models available for commercial use
are as follows. Llama - 2 Meta released Llama 2, a set of pretrained and
refined LLMs, along with Llama 2-Chat, a version of Llama 2. These
models are scalable up to 70 billion parameters. It was discovered after
extensive testing on safety and helpfulness-focused benchmarks that
Llama 2-Chat models perform better than current open-source models in
most cases. Human evaluations have shown that they align well with
several closed-source models.  The researchers have even taken a few
steps to guarantee the security of these models. This includes
annotating

</div>

<div class="card">

<div class="card-title">

[LLaMA Now Goes Faster on CPUs](https://justine.lol/matmul)

</div>

<div class="card-image">

[![](https://justine.lol/matmul/llamafile.png)](https://justine.lol/matmul)

</div>

I wrote 84 new matmul kernels to improve llamafile CPU performance.

</div>

<div class="card">

<div class="card-title">

[Large language models use a surprisingly simple mechanism to retrieve
some](https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325)

</div>

<div class="card-image">

[![](https://news.mit.edu/sites/default/files/images/202403/MIT-Transformer-Relations-01.jpg)](https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325)

</div>

Researchers find large language models use a simple mechanism to
retrieve stored knowledge when they respond to a user prompt. These
mechanisms can be leveraged to see what the model knows about different
subjects and possibly to correct false information it has stored.

</div>

<div class="card">

<div class="card-title">

[Introducing DBRX: A New State-of-the-Art Open
LLM](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm)

</div>

<div class="card-image">

[![](https://www.databricks.com/sites/default/files/2024-03/dbrx-technical-blog-og_0.png)](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm)

</div>

</div>

<div class="card">

<div class="card-title">

[ChatGPT vs Perplexity AI: AI App
Comparison](https://www.marktechpost.com/2024/03/31/chatgpt-vs-perplexity-ai-ai-app-comparison)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/03/Screenshot-2024-03-30-at-11.07.39-PM-1024x865.png)](https://www.marktechpost.com/2024/03/31/chatgpt-vs-perplexity-ai-ai-app-comparison)

</div>

What is ChatGPT? ChatGPT, developed by OpenAI, is an AI platform
renowned for its conversational AI capabilities. Leveraging the power of
the Generative Pre-trained Transformer models, ChatGPT generates
human-like text responses across various topics, from casual
conversations to complex, technical discussions. Its ability to engage
users with coherent, contextually relevant dialogues stands out, making
it highly versatile for various applications, including content
creation, education, customer service, and more. Its integration with
tools like DALL-E for image generation from textual descriptions and its
continual updates for enhanced performance showcase its commitment to
providing an engaging and innovative user experience. ChatGPT Key

</div>

<div class="card">

<div class="card-title">

[Mamba Explained](https://thegradient.pub/mamba-explained)

</div>

<div class="card-image">

[![](https://images.unsplash.com/photo-1598348341635-33a3f4205d32?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHRyYW5zZm9ybWVyfGVufDB8fHx8MTcxMTM0NTEwM3ww&ixlib=rb-4.0.3&q=80&w=2000)](https://thegradient.pub/mamba-explained)

</div>

Is Attention all you need? Mamba, a novel AI model based on State Space
Models (SSMs), emerges as a formidable alternative to the widely used
Transformer models, addressing their inefficiency in processing long
sequences.

</div>

<div class="card">

<div class="card-title">

[How Nvidia Blackwell Systems Attack 1 Trillion Parameter AI
Models](https://www.nextplatform.com/2024/03/19/how-nvidia-blackwell-systems-attack-1-trillion-parameter-ai-models)

</div>

<div class="card-image">

[![](https://www.nextplatform.com/wp-content/uploads/2024/03/nvidia-blackwell-platform-logo-scaled.jpg)](https://www.nextplatform.com/2024/03/19/how-nvidia-blackwell-systems-attack-1-trillion-parameter-ai-models)

</div>

We like datacenter compute engines here at The Next Platform, but as the
name implies, what we really like are platforms – how compute, storage,

</div>

<div class="card">

<div class="card-title">

[How Chain-of-Thought Reasoning Helps Neural Networks
Compute](https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321)

</div>

<div class="card-image">

[![](https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/03/ChainOfThought-byNickSlater-Social.webp)](https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321)

</div>

Large language models do better at solving problems when they show their
work. Researchers are beginning to understand why.

</div>

<div class="card">

<div class="card-title">

[Why and How to Achieve Longer Context Windows for
LLMs](https://towardsdatascience.com/why-and-how-to-achieve-longer-context-windows-for-llms-5f76f8656ea9?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:517/1*YIUq11zLVHA2OKPovlZKTQ.png)](https://towardsdatascience.com/why-and-how-to-achieve-longer-context-windows-for-llms-5f76f8656ea9?source=rss----7f60cf5620c9---4)

</div>

Language models (LLMs) have revolutionized the field of natural language
processing (NLP) over the last few years, achieving…

</div>

<div class="card">

<div class="card-title">

[Generative AI Design Patterns: A Comprehensive Guide \| by Vincent Koc
\|
Feb](https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*2tBQkVvC-_sHACgSs0ouug.png)](https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0)

</div>

Reference architecture patterns and mental models for working with Large
Language Models (LLM’s)

</div>

<div class="card">

<div class="card-title">

[You can now train a 70b language model at
home](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html)

</div>

<div class="card-image">

[![](https://www.answer.ai/posts/fsdp-qlora.png)](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html)

</div>

We’re releasing an open source system, based on FSDP and QLoRA, that can
train a 70b model on two 24GB GPUs.

</div>

<div class="card">

<div class="card-title">

[Easily Train a Specialized LLM: PEFT, LoRA, QLoRA, LLaMA-Adapter, and
More](https://towardsdatascience.com/easily-train-a-specialized-llm-peft-lora-qlora-llama-adapter-and-more-aedb5be39244?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*roKdHgMhP-nL19AMYiDyNQ.jpeg)](https://towardsdatascience.com/easily-train-a-specialized-llm-peft-lora-qlora-llama-adapter-and-more-aedb5be39244?source=rss----7f60cf5620c9---4)

</div>

Training a specialized LLM over your own data is easier than you think…

</div>

<div class="card">

<div class="card-title">

[Google Bard is called Gemini now and expands to mobile, paid
versions](https://www.axios.com/2024/02/08/google-bard-gemini-renamed)

</div>

<div class="card-image">

[![](https://images.axios.com/vRNK61f1Y4Pp0NXH6s6kR5pK3_w=/0x0:2048x1152/1366x768/2024/02/08/1707350880991.png)](https://www.axios.com/2024/02/08/google-bard-gemini-renamed)

</div>

The search giant is unifying its AI-assistant efforts under one name and
trying to show it can match rivals.

</div>

<div class="card">

<div class="card-title">

[Anthropic’s
Post](https://www.linkedin.com/posts/anthropicresearch_today-were-announcing-the-claude-3-model-activity-7170419945292455936-BPaN)

</div>

<div class="card-image">

[![](https://media.licdn.com/dms/image/v2/D5622AQG0TfRR1wFd8Q/feedshare-shrink_800/feedshare-shrink_800/0/1709561333446?e=2147483647&v=beta&t=20fIMbI05iH1vidsBa_8OaYDngf3lGtL23IxdJ8Ks5M)](https://www.linkedin.com/posts/anthropicresearch_today-were-announcing-the-claude-3-model-activity-7170419945292455936-BPaN)

</div>

Today, we're announcing the Claude 3 model family, which sets new
industry benchmarks across a wide range of cognitive tasks. The family
includes three… \| 429 comments on LinkedIn

</div>

<div class="card">

<div class="card-title">

[OpenAI's ChatGPT may have its first true rival in Anthropic's new
chatbot](https://qz.com/anthropic-opus-claude-openai-chatgpt-ai-1851304996)

</div>

<div class="card-image">

[![](https://i.kinja-img.com/image/upload/c_fill,h_675,pg_1,q_80,w_1200/dd2dd81ccabe1897b6654be8accfe869.jpg)](https://qz.com/anthropic-opus-claude-openai-chatgpt-ai-1851304996)

</div>

The Amazon-backed AI startup said its "most intelligent model"
outperformed OpenAI's powerful GPT-4

</div>

<div class="card">

<div class="card-title">

[rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)

</div>

<div class="card-image">

[![](https://repository-images.githubusercontent.com/669879380/79da1d51-4ef9-4733-a61c-1d7851020d9a)](https://github.com/rasbt/LLMs-from-scratch)

</div>

Implementing a ChatGPT-like LLM in PyTorch from scratch, step by step -
rasbt/LLMs-from-scratch

</div>

<div class="card">

<div class="card-title">

[Meet RAGxplorer: An interactive AI Tool to Support the Building of
Retrieva](https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-25-at-3.55.05-PM.png)](https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space)

</div>

Understanding how well they comprehend and organize information is
crucial in advanced language models. A common challenge arises in
visualizing the intricate relationships between different document
parts, especially when using complex models like the Retriever-Answer
Generator (RAG). Existing tools can only sometimes provide a clear
picture of how chunks of information relate to each other and specific
queries. Several attempts have been made to address this issue, but they
often need to deliver the need to provide an intuitive and interactive
solution. These tools need help breaking down documents into manageable
pieces and visualizing their semantic landscape effectively. As a

</div>

<div class="card">

<div class="card-title">

[Meet Google Lumiere AI, Bard’s video maker
cousin](https://dataconomy.com/2024/01/25/how-to-use-google-lumiere)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2024/01/How-to-use-Google-Lumiere.jpg)](https://dataconomy.com/2024/01/25/how-to-use-google-lumiere)

</div>

Step into the future of video creation with Google Lumiere, the latest
breakthrough from Google Research that promises to redefine

</div>

<div class="card">

<div class="card-title">

[How To Build an LLM-Powered App To Chat with
PapersWithCode](https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*0AW3FGe41K7h3E0p)](https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4)

</div>

Keep up with the latest ML research

</div>

<div class="card">

<div class="card-title">

[The killer app of Gemini Pro 1.5 is
video](https://simonwillison.net/2024/Feb/21/gemini-pro-video)

</div>

<div class="card-image">

[![](https://static.simonwillison.net/static/2024/gemini-pro-card.jpg)](https://simonwillison.net/2024/Feb/21/gemini-pro-video)

</div>

Last week Google introduced Gemini Pro 1.5, an enormous upgrade to their
Gemini series of AI models. Gemini Pro 1.5 has a 1,000,000 token context
size. This is huge—previously that …

</div>

<div class="card">

<div class="card-title">

[Understanding Direct Preference
Optimization](https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1024/1*L5Fx8l3DZ5LxZVSwBzlEdg.png)](https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841?source=rss----7f60cf5620c9---4)

</div>

This blog post will look at the “Direct Preference Optimization: Your
Language Model is Secretly a Reward Model” paper and its findings.

</div>

<div class="card">

<div class="card-title">

[I Spent a Week With Gemini Pro 1.5—It’s
Fantastic](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic)

</div>

<div class="card-image">

[![](https://d24ovhgu8s7341.cloudfront.net/uploads/post/social_media_image/2987/unnamed__1_.png)](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic)

</div>

When it comes to context windows, size matters

</div>

<div class="card">

<div class="card-title">

[Title:The Era of 1-bit LLMs: All Large Language Models are in 1.58
Bits](https://arxiv.org/abs/2402.17764)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2402.17764)

</div>

Recent research, such as BitNet, is paving the way for a new era of
1-bit Large Language Models (LLMs). In this work, we introduce a 1-bit
LLM variant, namely BitNet b1.58, in which every single...

</div>

<div class="card">

<div class="card-title">

[Sora early access: Your guide to securing a
spot](https://dataconomy.com/2024/02/26/sora-early-access)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2024/02/Sora-early-access_02.jpg)](https://dataconomy.com/2024/02/26/sora-early-access)

</div>

Are you looking for the news everyday for Sora early access like us?
Well you are absolutely right because OpenAI's

</div>

<div class="card">

<div class="card-title">

[Au Large \| Mistral AI \| Frontier AI in your
hands](https://mistral.ai/news/mistral-large)

</div>

<div class="card-image">

[![](https://mistral.ai/images/icons/mistral-supersonic-boat.jpg)](https://mistral.ai/news/mistral-large)

</div>

Mistral Large is our flagship model, with top-tier reasoning capacities.
It is also available on Azure.

</div>

<div class="card">

<div class="card-title">

[Claude](https://claude.ai/chat/a77c0bb5-3e7c-4a91-9ced-5314df193759)

</div>

<div class="card-image">

[![](https://claude.ai/images/claude_ogimage.png)](https://claude.ai/chat/a77c0bb5-3e7c-4a91-9ced-5314df193759)

</div>

Talk with Claude, an AI assistant from Anthropic

</div>

<div class="card">

<div class="card-title">

[Beyond Self-Attention: How a Small Language Model Predicts the Next
Token](https://shyam.blog/posts/beyond-self-attention)

</div>

A deep dive into the internals of a small transformer model to learn how
it turns self-attention calculations into accurate predictions for the
next token.

</div>

<div class="card">

<div class="card-title">

[How do transformers work?+Design a Multi-class Sentiment Analysis for
Custo](https://open.substack.com/pub/nintyzeros/p/how-do-transformer-workdesign-a-multi)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b143728-e85e-4a5e-af07-98662aa67d5a_727x1024.png)](https://open.substack.com/pub/nintyzeros/p/how-do-transformer-workdesign-a-multi)

</div>

We will deep dive into understanding how transformer model work like
BERT(Non-mathematical Explanation of course!). system design to use the
transformer to build a Sentiment Analysis

</div>

<div class="card">

<div class="card-title">

[1708022141659 (JPEG Image, 1280 × 1600 pixels) — Scaled
(56%)](https://media.licdn.com/dms/image/D4D22AQElBF0kmo1tgA/feedshare-shrink_1280/0/1708022141659?e=1711584000&t=9UxcdrylfOu5hKIS-OZBr4aqeF-Gue26r84_GgTWV0g&v=beta)

</div>

</div>

<div class="card">

<div class="card-title">

[Groq Inference Tokenomics: Speed, But At What
Cost?](https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4aad86a5-7fda-444f-9179-7912e9196547_2156x1100.png)](https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but)

</div>

Faster than Nvidia? Dissecting the economics

</div>

<div class="card">

<div class="card-title">

[How Well Can LLMs Negotiate? Stanford Researchers Developed
‘NegotiationAre](https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-6.06.54-AM.png)](https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents)

</div>

In artificial intelligence, the capacity of Large Language Models (LLMs)
to negotiate mirrors a leap toward achieving human-like interactions in
digital negotiations. At the heart of this exploration is the
NEGOTIATION ARENA, a pioneering framework devised by researchers from
Stanford University and Bauplan. This innovative platform delves into
the negotiation prowess of LLMs, offering a dynamic environment where AI
can mimic, strategize, and engage in nuanced dialogues across a spectrum
of scenarios, from splitting resources to intricate trade and price
negotiations. The NEGOTIATION ARENA is a tool and a gateway to
understanding how AI can be shaped to think, react,

</div>

<div class="card">

<div class="card-title">

[Sora](https://openai.com/sora)

</div>

<div class="card-image">

[![](https://images.ctfassets.net/kftzwdyauwt9/8264d3d7-922c-4343-dde924eae75b/c9f68101050dc2a6caaac2f434c0da5e/paper-airplanes.jpg?w=1600&h=900&fit=fill)](https://openai.com/sora)

</div>

Sora is an AI model that can create realistic and imaginative scenes
from text instructions.

</div>

<div class="card">

<div class="card-title">

[Code LoRA from Scratch - a Lightning Studio by
sebastian](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)

</div>

<div class="card-image">

[![](https://lightning.ai/v1/thumbnail/cloudspace/01hm9hypqc6y1hrapb5prmtz0h?updated_at=1727723800)](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)

</div>

LoRA (Low-Rank Adaptation) is a popular technique to finetune LLMs more
efficiently. This Studio explains how LoRA works by coding it from
scratch, which is an excellent exercise for looking under …

</div>

<div class="card">

<div class="card-title">

[Bard is now Gemini and Gemini Advanced is
amazing](https://dataconomy.com/2024/02/08/bard-is-now-gemini-here-are-gemini-advanced-features)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2024/02/Bard-is-now-Gemini-Advanced_2.jpg)](https://dataconomy.com/2024/02/08/bard-is-now-gemini-here-are-gemini-advanced-features)

</div>

AI community is once again filled with excitement as Bard is now Gemini
and Gemini Advanced offering users an exceptional

</div>

<div class="card">

<div class="card-title">

[Ask HN: What have you built with
LLMs?](https://news.ycombinator.com/item?id=39263664)

</div>

</div>

<div class="card">

<div class="card-title">

[Title:BloombergGPT: A Large Language Model for
Finance](https://arxiv.org/abs/2303.17564)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2303.17564)

</div>

The use of NLP in the realm of financial technology is broad and
complex, with applications ranging from sentiment analysis and named
entity recognition to question answering. Large Language...

</div>

<div class="card">

<div class="card-title">

[Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large
Language](https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_9-scaled.jpg)](https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model)

</div>

Zephyr is a series of Large Language Models released by Hugging Face
trained using distilled supervised fine-tuning (dSFT) on larger models
with significantly improved task accuracy.

</div>

<div class="card">

<div class="card-title">

[Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables
with](https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=rss----d7683ed5043e---4)

</div>

<div class="card-image">

[![](https://cdn.sanity.io/images/7m9jw85w/production/2e20042f130ae9b86c063958cc2cc717f522a0b4-820x790.jpg)](https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=rss----d7683ed5043e---4)

</div>

LlamaIndex is a simple, flexible data framework for connecting custom
data sources to large language models (LLMs).

</div>

<div class="card">

<div class="card-title">

[Understanding and Coding Self-Attention, Multi-Head Attention,
Cross-Attent](https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention?isFreemail=true&post_id=140464659&publication_id=1174659&r=oc5d)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.png)](https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention?isFreemail=true&post_id=140464659&publication_id=1174659&r=oc5d)

</div>

This article will teach you about self-attention mechanisms used in
transformer architectures and large language models (LLMs) such as GPT-4
and Llama.

</div>

<div class="card">

<div class="card-title">

[Dashboard - SciSummary](https://scisummary.com/dashboard/signed-up)

</div>

<div class="card-image">

[![](https://scisummary.com/img/social.webp)](https://scisummary.com/dashboard/signed-up)

</div>

AI Driven tools for researchers and students. Use AI to summarize and
understand scientific articles and research papers.

</div>

<div class="card">

<div class="card-title">

[Meet Waymo’s MotionLM: The State-of-the-Art Multi-Agent Motion
Prediction
A](https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/10/ezgif-4-5e9741ba41.gif)](https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars)

</div>

Autoregressive language models have excelled at predicting the
subsequent subword in a sentence without the need for any predefined
grammar or parsing concepts. This method has been expanded to include
continuous data domains like audio and image production, where data is
represented as discrete tokens, much like language model vocabularies.
Due to their versatility, sequence models have attracted interest for
use in increasingly complicated and dynamic contexts, such as behavior.
Road users are compared to participants in a continuous conversation
when driving since they exchange actions and replies. The question is
whether similar sequence models may be used to forecast

</div>

<div class="card">

<div class="card-title">

[How much detail is too much? Midjourney v6 attempts to find
out](https://arstechnica.com/information-technology/2024/01/a-crazy-update-midjourney-v6-upgrade-heaps-on-ai-generated-detail)

</div>

<div class="card-image">

[![](https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_queen_of_the_universe.jpg)](https://arstechnica.com/information-technology/2024/01/a-crazy-update-midjourney-v6-upgrade-heaps-on-ai-generated-detail)

</div>

As Midjourney rolls out new features, it continues to make some artists
furious.

</div>

<div class="card">

<div class="card-title">

[10 Noteworthy AI Research Papers of
2023](https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0046298-1059-4538-bcd8-dfcfc863d7c5_1254x810.png)](https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023)

</div>

This year has felt distinctly different. I've been working in, on, and
with machine learning and AI for over a decade, yet I can't recall a
time when these fields were as popular and rapidly evolving as they have
been this year. To conclude an eventful 2023 in machine learning and AI
research, I'm excited to share 10 noteworthy papers I've read this year.
My personal focus has been more on large language models, so you'll find
a heavier emphasis on large language model (LLM) papers than computer
vision papers this year.

</div>

<div class="card">

<div class="card-title">

[7 Steps to Mastering Large Language Models
(LLMs)](https://www.kdnuggets.com/7-steps-to-mastering-large-language-models-llms)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/c_7_steps_mastering_large_language_models_llms_2.png)](https://www.kdnuggets.com/7-steps-to-mastering-large-language-models-llms)

</div>

Large Language Models (LLMs) have unlocked a new era in natural language
processing. So why not learn more about them? Go from learning what
large language models are to building and deploying LLM apps in 7 easy
steps with this guide.

</div>

<div class="card">

<div class="card-title">

[Meta AI Researchers Propose Advanced Long-Context LLMs: A Deep Dive
into
Up](https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-08-at-8.08.38-AM.png)](https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance)

</div>

The emergence of Large Language Models (LLMs) in natural language
processing represents a groundbreaking development. These models,
trained on vast amounts of data and leveraging immense computational
resources, promise to transform human interactions with the digital
world. As they evolve through scaling and rapid deployment, their
potential use cases become increasingly intricate and complex. They
extend their capabilities to tasks such as analyzing dense,
knowledge-rich documents, enhancing chatbot experiences to make them
more genuine and engaging, and assisting human users in iterative
creative processes like coding and design. One crucial feature that
empowers this evolution is the capacity to effectively

</div>

<div class="card">

<div class="card-title">

[This AI Paper from NVIDIA Explores the Power of Retrieval-Augmentation
vs.](https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-10-at-5.55.31-PM.png)](https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist)

</div>

In a comparative study, Researchers from Nvidia investigated the impact
of retrieval augmentation and context window size on the performance of
large language models (LLMs) in downstream tasks. The findings reveal
that retrieval augmentation consistently enhances LLM performance,
irrespective of context window size. Their research sheds light on the
effectiveness of retrieval mechanisms in optimizing LLMs for various
applications. Researchers delve into the domain of long-context language
models, investigating the efficacy of retrieval augmentation and context
window size in enhancing LLM performance across various downstream
tasks. It conducts a comparative analysis of different pretrained LLMs,
demonstrating that retrieval mechanisms significantly

</div>

<div class="card">

<div class="card-title">

[Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of
Experiments - Lightning
AI](https://lightning.ai/pages/community/lora-insights)

</div>

<div class="card-image">

[![](https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png)](https://lightning.ai/pages/community/lora-insights)

</div>

LoRA is one of the most widely used, parameter-efficient finetuning
techniques for training custom LLMs. From saving memory with QLoRA to
selecting the optimal LoRA settings, this article provides practical
insights for those interested in applying it.

</div>

<div class="card">

<div class="card-title">

[Getting Started with Large Language Models: Key Things to
Know](https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms)

</div>

<div class="card-image">

[![](https://cdn.prod.website-files.com/63bc83b29094ec80844b6dd5/6526dc79dea0f080d2d61d6f_Starting-with-large-language-models.webp)](https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms)

</div>

As a machine learning engineer who has witnessed the rise of Large
Language Models (LLMs), I find it daunting to comprehend how the
ecosystem surrounding LLMs is developing.

</div>

<div class="card">

<div class="card-title">

[Unlocking GPT-4 Summarization with Chain of Density
Prompting](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/chain-of-density-header-3.png)](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)

</div>

Unlock the power of GPT-4 summarization with Chain of Density (CoD), a
technique that attempts to balance information density for high-quality
summaries.

</div>

<div class="card">

<div class="card-title">

[The Ins and Outs of Retrieval-Augmented Generation
(RAG)](https://towardsdatascience.com/the-ins-and-outs-of-retrieval-augmented-generation-rag-56f470ccda4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*z44aRSEAwZ93fOqB)](https://towardsdatascience.com/the-ins-and-outs-of-retrieval-augmented-generation-rag-56f470ccda4)

</div>

Our weekly selection of must-read Editors’ Picks and original features

</div>

<div class="card">

<div class="card-title">

[Building RAG-based LLM Applications for Production (Part
1)](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)

</div>

<div class="card-image">

[![](https://images.ctfassets.net/xjan103pcp94/1vCYZeIqmd03ECO3UXcCSi/374c494a8be6000ccb7570afe40ff182/social-rag-based-llm.png)](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)

</div>

In this guide, we will learn how to develop and productionize a
retrieval augmented generation (RAG) based LLM application, with a focus
on scale and evaluation.

</div>

<div class="card">

<div class="card-title">

[RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM
Application?](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1127/1*Jq9bEbitg1Pv4oASwEQwJg.png)](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7)

</div>

The definitive guide for choosing the right method for your use case

</div>

<div class="card">

<div class="card-title">

[A High-Level Overview Of Large Language Model Concepts, Use Cases, And
Tool](https://smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools)

</div>

<div class="card-image">

[![](https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/overview-large-language-model-concepts-use-cases-tools.jpg)](https://smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools)

</div>

Discuss the concept of large language models (LLMs) and how they are
implemented with a set of data to develop an application. Joas compares
a collection of no-code and low-code apps designed to help you get a
feel for not only how the concept works but also to get a sense of what
types of models are available to train AI on different skill sets.

</div>

<div class="card">

<div class="card-title">

[Augmenting LLMs with
RAG](https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1000/0*2I08qvic82JOQIuA)](https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=rss----7f60cf5620c9---4)

</div>

An End to End Example Of Seeing How Well An LLM Model Can Answer Amazon
SageMaker Related Questions

</div>

<div class="card">

<div class="card-title">

[Parallel Processing in Prompt Engineering: The Skeleton-of-Thought
Techniqu](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/skeleton-of-thought-header.png)](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)

</div>

Explore how the Skeleton-of-Thought prompt engineering technique
enhances generative AI by reducing latency, offering structured output,
and optimizing projects.

</div>

<div class="card">

<div class="card-title">

[\[2302.07730\] Transformer models: an introduction and
catalog](https://arxiv.org/abs/2302.07730)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2302.07730)

</div>

In the past few years we have seen the meteoric appearance of dozens of
foundation models of the Transformer family, all of which have memorable
and sometimes funny, but not self-explanatory,...

</div>

<div class="card">

<div class="card-title">

[Hey, Computer, Make Me a
Font](https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font)

</div>

<div class="card-image">

[![](https://serce.me/images/make-me-a-font/bender.jpeg)](https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font)

</div>

This is a story of my journey learning to build generative ML models
from scratch and teaching a computer to create fonts in the process.

</div>

<div class="card">

<div class="card-title">

[SaaS Competitive Advantage Through Elegant LLM Feedback
Mechanisms](https://www.tomtunguz.com/easy-feedback-ml-bard)

</div>

Eliciting product feedback elegantly is a competitive advantage for
LLM-software. Over the weekend, I queried Google’s Bard, & noticed the
elegant feedback loop the product team has incorporated into their
product. I asked Bard to compare the 3rd-row leg room of the leading
7-passenger SUVs. At the bottom of the post is a little G button, which
double-checks the response using Google searches. I decided to click it.
This is what I would be doing in any case ; spot-checking some of the
results.

</div>

<div class="card">

<div class="card-title">

[ChatGPT, Bard, or Bing Chat? Differences Among 3 Generative-AI
Bots](https://www.nngroup.com/articles/ai-bot-comparison)

</div>

<div class="card-image">

[![](https://media.nngroup.com/media/articles/opengraph_images/AI-Bots_social-33.png)](https://www.nngroup.com/articles/ai-bot-comparison)

</div>

Participants rated Bing Chat as less helpful and trustworthy than
ChatGPT or Bard. These results can be attributed to Bing’s richer yet
imperfect UI and to its poorer information aggregation.

</div>

<div class="card">

<div class="card-title">

[Bard](https://bard.google.com/chat)

</div>

<div class="card-image">

[![](https://www.gstatic.com/lamda/images/gemini_thumbnail_c362e5eadc46ca9f617e2.png)](https://bard.google.com/chat)

</div>

Bard is now Gemini. Get help with writing, planning, learning, and more
from Google AI.

</div>

<div class="card">

<div class="card-title">

[The State of Large Language
Models](https://www.scientificamerican.com/podcast/episode/the-state-of-large-language-models)

</div>

<div class="card-image">

[![](https://static.scientificamerican.com/sciam/cache/file/48E0C0D2-E023-4F16-BE1A7D26DC05AF36_source.gif?w=600)](https://www.scientificamerican.com/podcast/episode/the-state-of-large-language-models)

</div>

We present the latest updates on ChatGPT, Bard and other competitors in
the artificial intelligence arms race.

</div>

<div class="card">

<div class="card-title">

[10 Ways to Improve the Performance of Retrieval Augmented Generation
System](https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*J16KiNF4M_XxPkALZFUJHw.jpeg)](https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c)

</div>

Tools to go from prototype to production

</div>

<div class="card">

<div class="card-title">

[How to Build an LLM from
Scratch](https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*kNzeztfZxg8IsXA4)](https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9?source=rss----7f60cf5620c9---4)

</div>

Data Curation, Transformers, Training at Scale, and Model Evaluation

</div>

<div class="card">

<div class="card-title">

[Large Language Model Prompt Engineering for Complex Summarization - ISE
Dev](https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering)

</div>

<div class="card-image">

[![](https://devblogs.microsoft.com/ise/wp-content/uploads/sites/55/2023/06/prompt-engineering-may23.png)](https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering)

</div>

Learn how to use GPT / LLMs to create complex summaries such as for
medical text

</div>

<div class="card">

<div class="card-title">

[Open LLM Leaderboard : a Hugging Face Space by
HuggingFaceH4](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

</div>

<div class="card-image">

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/spaces/open-llm-leaderboard/open_llm_leaderboard.png)](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

</div>

Track, rank and evaluate open LLMs and chatbots

</div>

<div class="card">

<div class="card-title">

[Llama from scratch](https://blog.briankitano.com/llama-from-scratch)

</div>

<div class="card-image">

[![](https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman-1683556668-0.png)](https://blog.briankitano.com/llama-from-scratch)

</div>

I want to provide some tips from my experience implementing a paper. I'm
going to cover my tips so far from implementing a dramatically
scaled-down versio...

</div>

<div class="card">

<div class="card-title">

[Cracking Open the OpenAI (Python)
API](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*QzoGN7Zhi3m21yU0)](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)

</div>

A complete beginner-friendly introduction with example code

</div>

<div class="card">

<div class="card-title">

[Cracking Open the Hugging Face Transformers
Library](https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*Rkoquyw55K6qbFWF)](https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)

</div>

A quick-start guide to using open-source LLMs

</div>

<div class="card">

<div class="card-title">

[Asking 60+ LLMs a set of 20
questions](https://benchmarks.llmonitor.com)

</div>

Human-readable benchmarks of 60+ open-source and proprietary LLMs.

</div>

<div class="card">

<div class="card-title">

[OpenAI Unveils DALL·E 3: A Revolutionary Leap in Text-to-Image
Generation](https://www.marktechpost.com/2023/09/20/openai-unveils-dall%C2%B7e-3-a-revolutionary-leap-in-text-to-image-generation)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-20-at-10.40.15-PM-1024x545.png)](https://www.marktechpost.com/2023/09/20/openai-unveils-dall%C2%B7e-3-a-revolutionary-leap-in-text-to-image-generation)

</div>

In a significant technological leap, OpenAI has announced the launch of
DALL·E 3, the latest iteration in their groundbreaking text-to-image
generation technology. With an unprecedented capacity to understand
nuanced and detailed descriptions, DALL·E 3 promises to revolutionize
the creative landscape by allowing users to translate their textual
ideas into astonishingly accurate images effortlessly. DALL·E 3 is
currently in research preview, offering a tantalizing glimpse into its
capabilities. However, the broader availability of this cutting-edge
technology is set for early October, when it will be accessible to
ChatGPT Plus and Enterprise customers through the API and Labs later in
the fall.

</div>

<div class="card">

<div class="card-title">

[Comparison: DALL-E 3 vs
Midjourney](https://dataconomy.com/2023/09/22/comparison-dall-e-3-vs-midjourney)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2023/09/Comparison-DALL-E-3-vs-Midjourney-1111.jpg)](https://dataconomy.com/2023/09/22/comparison-dall-e-3-vs-midjourney)

</div>

DALL-E 3, the latest version of OpenAI's ground-breaking generative AI
visual art platform, was just announced with groundbreaking features,
including

</div>

<div class="card">

<div class="card-title">

[What OpenAI Really
Wants](https://www.wired.com/story/what-openai-really-wants)

</div>

<div class="card-image">

[![](https://media.wired.com/photos/64ed0bc52da6c6d86e70e575/191:100/w_1280,c_limit/WI100123_FF_OpenAI_01.jpg)](https://www.wired.com/story/what-openai-really-wants)

</div>

The young company sent shock waves around the world when it released
ChatGPT. But that was just the start. The ultimate goal: Change
everything. Yes. Everything.

</div>

<div class="card">

<div class="card-title">

[A Beginner’s Guide to Building LLM-Powered Applications with
LangChain!](https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fso3pj9juipg7i3bvrwjb.png)](https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e)

</div>

If you're a developer or simply someone passionate about technology,
you've likely encountered AI...

</div>

<div class="card">

<div class="card-title">

[iryna-kondr/scikit-llm: Seamlessly integrate LLMs into
scikit-learn.](https://github.com/iryna-kondr/scikit-llm)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/350c1f2d6ab49a8c893e709f629e66749bf5265df96eb98a9d57ba89c89f2999/iryna-kondr/scikit-llm)](https://github.com/iryna-kondr/scikit-llm)

</div>

Seamlessly integrate LLMs into scikit-learn.

</div>

<div class="card">

<div class="card-title">

[Prompt Engineering — How to trick AI into solving your
problems](https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*ZcfH-qxXT4AYAqwr)](https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)

</div>

7 prompting tricks, Langchain, and Python example code

</div>

<div class="card">

<div class="card-title">

[A Beginner’s Guide to LLM
Fine-Tuning](https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*LVIFTTCmYWQw8nyiuKOA9g.jpeg)](https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672)

</div>

How to fine-tune Llama and other LLMs with one tool

</div>

<div class="card">

<div class="card-title">

[Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in
Extended-Con](https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg)](https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing)

</div>

A multifaceted challenge has arisen in the expansive realm of natural
language processing: the ability to adeptly comprehend and respond to
intricate and lengthy instructions. As communication nuances become more
complicated, the shortcomings of prevailing models in dealing with
extensive contextual intricacies have been laid bare. Within these
pages, an extraordinary solution crafted by the dedicated minds at
Together AI comes to light—a solution that holds the promise of
reshaping the very fabric of language processing. This innovation has
profound implications, especially in tasks requiring an acute grasp of
extended contextual nuances. Contemporary natural language processing
techniques rely heavily on

</div>

<div class="card">

<div class="card-title">

[A Practical Introduction to
LLMs](https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*Nl-5C1WBW4XdGkNI)](https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148)

</div>

3 levels of using LLMs in practice

</div>

<div class="card">

<div class="card-title">

[Meet Chroma: An AI-Native Open-Source Vector Database For LLMs: A
Faster
Wa](https://www.marktechpost.com/2023/08/19/meet-chroma-an-ai-native-open-source-vector-database-for-llms-a-faster-way-to-build-python-or-javascript-llm-apps-with-memory)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-19-at-3.55.16-AM-1024x534.png)](https://www.marktechpost.com/2023/08/19/meet-chroma-an-ai-native-open-source-vector-database-for-llms-a-faster-way-to-build-python-or-javascript-llm-apps-with-memory)

</div>

Word embedding vector databases have become increasingly popular due to
the proliferation of massive language models. Using the power of
sophisticated machine learning techniques, data is stored in a vector
database. It allows for very fast similarity search, essential for many
AI uses such as recommendation systems, picture recognition, and NLP.
The essence of complicated data is captured in a vector database by
representing each data point as a multidimensional vector. Quickly
retrieving related vectors is made possible by modern indexing
techniques like k-d trees and hashing. To transform big data analytics,
this architecture generates highly scalable, efficient solutions for

</div>

<div class="card">

<div class="card-title">

[How to Extract Text from Any PDF and Image for Large Language Model \|
by
Zo](https://towardsdatascience.com/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1000/0*hsHhE00e_S__ITtI)](https://towardsdatascience.com/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6)

</div>

Use these text extraction techniques to get quality data for your LLM
models

</div>

<div class="card">

<div class="card-title">

[Introducing OpenLLM: Open Source Library for
LLMs](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/arya_introducing_openllm_open_source_library_llms_1.png)](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)

</div>

A user-friendly platform for operating large language models (LLMs) in
production, with features such as fine-tuning, serving, deployment, and
monitoring of any LLMs.

</div>

<div class="card">

<div class="card-title">

[Abacus AI Introduces A New Open Long-Context Large Language Model LLM:
Meet](https://www.marktechpost.com/2023/08/03/abacus-ai-introduces-a-new-open-long-context-large-language-model-llm-meet-giraffe)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/08/F2cyQhvXAAAJk8y.jpeg)](https://www.marktechpost.com/2023/08/03/abacus-ai-introduces-a-new-open-long-context-large-language-model-llm-meet-giraffe)

</div>

Recent language models can take long contexts as input; more is needed
to know about how well they use longer contexts. Can LLMs be extended to
longer contexts? This is an unanswered question. Researchers at Abacus
AI conducted multiple experiments involving different schemes for
developing the context length ability of Llama, which is pre-trained on
context length 2048. They linear rescaled these models with IFT at
scales 4 and 16. Scaling the model to scale 16 can perform world tasks
up to 16k context length or even up to 20-24k context length.  Different
methods of extending context length are Linear

</div>

<div class="card">

<div class="card-title">

[How to use LLMs for PDF
parsing](https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api)

</div>

<div class="card-image">

[![](https://images.unsplash.com/photo-1682420636597-0786f3406a94?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDM5fHxjaGF0Z3B0fGVufDB8fHx8MTcxNDU0MjE1M3ww&ixlib=rb-4.0.3&q=80&w=2000)](https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api)

</div>

Using ChatGPT & OpenAI's GPT API, this code tutorial teaches how to chat
with PDFs, automate PDF tasks, and build PDF chatbots.

</div>

<div class="card">

<div class="card-title">

[How to Chat With Any File from PDFs to Images Using Large Language
Models
—](https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*jMAGouB3s_LA1YoslX5Z_A.png)](https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc?source=rss----7f60cf5620c9---4)

</div>

Complete guide to building an AI assistant that can answer questions
about any file

</div>

<div class="card">

<div class="card-title">

[How to Leverage Open-Source LLMs in Your
Project](https://www.turingpost.com/p/practicalllms)

</div>

<div class="card-image">

[![](https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/3d4e8599-c213-442c-b2c3-bf39b5306497/Frame_144.png?t=1693246361)](https://www.turingpost.com/p/practicalllms)

</div>

Practical Advice from Experts: Fine-Tuning, Deployment, and Best
Practices

</div>

<div class="card">

<div class="card-title">

[LangChain 101: Build Your Own GPT-Powered
Applications](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/c_langchain_101_build_gptpowered_applications_2.png)](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)

</div>

LangChain is a Python library that helps you build GPT-powered
applications in minutes. Get started with LangChain by building a simple
question-answering app.

</div>

<div class="card">

<div class="card-title">

[MPT-30B: Raising the bar for open-source foundation
models](https://www.mosaicml.com/blog/mpt-30b)

</div>

<div class="card-image">

[![](https://www.databricks.com/en-blog-assets/static/og-databricks-58419d0d868b05ddb057830066961ebe.png)](https://www.mosaicml.com/blog/mpt-30b)

</div>

Latest blogs from the team at Mosaic Research

</div>

<div class="card">

<div class="card-title">

[Midjourney pricing plans and free alternatives to
try](https://dataconomy.com/2023/07/12/midjourney-pricing-and-free-alternatives)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2023/07/Midjourney-pricing-plans-and-free-alternatives-to-try.jpg)](https://dataconomy.com/2023/07/12/midjourney-pricing-and-free-alternatives)

</div>

Navigating the maze of pricing plans for digital services can sometimes
be a daunting task. Today, we are unveiling Midjourney

</div>

<div class="card">

<div class="card-title">

[A Deep Dive Into LLaMA, Falcon, Llama 2 and Their Remarkable Fine-Tuned
Ver](https://www.turingpost.com/p/top3llmsope)

</div>

<div class="card-image">

[![](https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/f739d30a-90f3-4c02-9e23-f40e93f92c28/Frame_143.png?t=1693246280)](https://www.turingpost.com/p/top3llmsope)

</div>

Exploring the Development of the 3 Leading Open LLMs and Their Chatbot
Derivatives

</div>

<div class="card">

<div class="card-title">

[Chain of Thought Prompting for
LLMs](https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*g5Q-4lGt9UySnOK0JRQiPg.jpeg)](https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38?source=rss----7f60cf5620c9---4)

</div>

A practical and simple approach for “reasoning” with LLMs

</div>

<div class="card">

<div class="card-title">

[Is Anthropic's Claude 2 model ready to take down GPT-4? We put them to
the](https://dev.to/bitohq/claude-2-vs-claude-13-vs-gpt-4-ai-coding-comparison-k29)

</div>

<div class="card-image">

[![](https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F0an9xnkhqoa564q8gird.png)](https://dev.to/bitohq/claude-2-vs-claude-13-vs-gpt-4-ai-coding-comparison-k29)

</div>

Anthropic released Claude 2, a new iteration of its AI model, to take on
ChatGPT and Google Bard...

</div>

<div class="card">

<div class="card-title">

[Emerging Architectures for LLM
Applications](https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications)

</div>

<div class="card-image">

[![](https://d1lamhf6l6yk6d.cloudfront.net/uploads/2023/06/2657_-LLM-Architecture-Yoast-1200x630-1.webp)](https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications)

</div>

A reference architecture for the LLM app stack. It shows the most common
systems, tools, and design patterns used by AI startups and tech
companies.

</div>

<div class="card">

<div class="card-title">

[ELI5:
FlashAttention](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*i4tDdwgvGtXuTIyJpFUn8A.png)](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad)

</div>

Step by step explanation of how one of the most important MLSys
breakthroughs work — in gory detail.

</div>

<div class="card">

<div class="card-title">

[Build Industry-Specific LLMs Using Retrieval Augmented
Generation](https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*tJYmd5EGacd-7ld5PFgdHg.png)](https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68)

</div>

Organizations are in a race to adopt Large Language Models. Let’s dive
into how you can build industry-specific LLMs Through RAG

</div>

<div class="card">

<div class="card-title">

[Free Full Stack LLM
Bootcamp](https://www.kdnuggets.com/2023/06/free-full-stack-llm-bootcamp.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/c_free_full_stack_llm_bootcamp_2.png)](https://www.kdnuggets.com/2023/06/free-full-stack-llm-bootcamp.html)

</div>

Want to learn more about LLMs and build cool LLM-powered applications?
This free Full Stack LLM Bootcamp is all you need!

</div>

<div class="card">

<div class="card-title">

[Edge 300: Meet Falcon LLM: The Most Powerful Open Source LLM Released
to
Da](https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa405bc1-2701-410e-8b87-53c72a5c84af_1024x1024.png)](https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most)

</div>

The model quickly top the Open LLM Leaderboard that ranks the
performance of open source LLMs.

</div>

<div class="card">

<div class="card-title">

[The Secret Sauce behind 100K context window in LLMs: all tricks in one
plac](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:534/0*x80ZcJl_2zLbyvCE.jpg)](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c)

</div>

tldr; techniques to speed up training and inference of LLMs to use large
context window up to 100K input tokens during training and…

</div>

<div class="card">

<div class="card-title">

[All You Need to Know to Build Your First LLM
App](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*njagJOgiT-VTJjQ18bugcw.png)](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)

</div>

A step-by-step tutorial to document loaders, embeddings, vector stores
and prompt templates

</div>

<div class="card">

<div class="card-title">

[Observe.ai unveils 30-billion-parameter contact center LLM and a
generative](https://venturebeat.com/ai/observe-ai-unveils-30-billion-parameter-contact-center-llm-and-a-generative-ai-product-suite)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2023/06/ObserveAI-Banner-Image.jpeg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/observe-ai-unveils-30-billion-parameter-contact-center-llm-and-a-generative-ai-product-suite)

</div>

The Observe.AI contact center LLM showed a 35% increase in accuracy
compared to GPT-3.5 when automatically summarizing conversations.

</div>

<div class="card">

<div class="card-title">

[Training LLMs with AMD MI250 GPUs and
MosaicML](https://www.mosaicml.com/blog/amd-mi250)

</div>

<div class="card-image">

[![](https://www.databricks.com/sites/default/files/2023-12/training-llms-amd-mosaicml-img-og.png)](https://www.mosaicml.com/blog/amd-mi250)

</div>

With the release of PyTorch 2.0 and ROCm 5.4, we are excited to announce
that LLM training works out of the box on AMD MI250 accelerators with
zero code changes and at high performance!

</div>

<div class="card">

<div class="card-title">

[Optimizing Memory Usage for Training LLMs and Vision Transformers in
PyTorc](https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm)

</div>

<div class="card-image">

[![](https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/pytorch-memory-hero.png)](https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm)

</div>

This article provides a series of techniques that can lower memory
consumption in PyTorch (when training vision transformers and LLMs) by
approximately 20x without sacrificing modeling performance and
prediction accuracy.

</div>

<div class="card">

<div class="card-title">

[Deploying Falcon-7B Into
Production](https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1024/1*mJeCCGWnhNg3albw4UqCjg.png)](https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373?source=rss----7f60cf5620c9---4)

</div>

Running Falcon-7B in the cloud as a microservice

</div>

<div class="card">

<div class="card-title">

[Anthropic releases Claude 2, its second-gen AI
chatbot](https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot)

</div>

<div class="card-image">

[![](https://techcrunch.com/wp-content/uploads/2023/05/anthropic-header.jpg?resize=1200,675)](https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot)

</div>

Anthropic, the AI startup founded by ex-OpenAI execs, has released its
newest chatbot, Claude 2. It's ostensibly improved in several ways.

</div>

<div class="card">

<div class="card-title">

[Google Launches AI-Powered Notes App Called
NotebookLM](https://tech.slashdot.org/story/23/07/12/2334234/google-launches-ai-powered-notes-app-called-notebooklm)

</div>

<div class="card-image">

[![](https://a.fsdn.com/sd/topics/ai_64.png)](https://tech.slashdot.org/story/23/07/12/2334234/google-launches-ai-powered-notes-app-called-notebooklm)

</div>

Google is launching its AI-backed note-taking tool to "a small group of
users in the US," the company said in a blog post. Formerly referred to
as Project Tailwind at Google I/O earlier this year, the new app is now
known as NotebookLM (the LM stands for Language Model). The Verge
reports: The core...

</div>

<div class="card">

<div class="card-title">

[Meet LMQL: An Open Source Query Language for
LLMs](https://thesequence.substack.com/p/meet-lmql-an-open-source-query-language)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb64cfd32-2483-4d99-9c2b-d4cc34017c0f_1024x1024.png)](https://thesequence.substack.com/p/meet-lmql-an-open-source-query-language)

</div>

Developed by ETH Zürich, the language explores new paradigms for LLM
programming.

</div>

<div class="card">

<div class="card-title">

[Ecosystem Graphs for Foundation
Models](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table)

</div>

</div>

<div class="card">

<div class="card-title">

[Leandro von Werra’s
Post](https://www.linkedin.com/posts/lvwerra_it-crazy-how-far-the-ml-field-has-come-when-activity-7087699813009383425-Sr1y)

</div>

<div class="card-image">

[![](https://media.licdn.com/dms/image/v2/D4E22AQGGzP26Zn7lSg/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1689839317534?e=2147483647&v=beta&t=2-BIClj1Bq40beli2UNOE37ZSktTyTWlRXY4sFIxceg)](https://www.linkedin.com/posts/lvwerra_it-crazy-how-far-the-ml-field-has-come-when-activity-7087699813009383425-Sr1y)

</div>

It crazy how far the ML field has come when it comes to fine-tuning
LLMs. A year ago: it was challenging to fine-tune GPT-2 (1.5B) on a
single GPU without… \| 76 comments on LinkedIn

</div>

<div class="card">

<div class="card-title">

[LLaMA 2: How to access and use Meta’s versatile open-source chatbot
right
n](https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2023/07/nuneybits_vector_art_of_a_llama_programming_8c825672-172b-4e69-a6f1-b7c9e8bf5294.png?w=803?w=1200&strip=all)](https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now)

</div>

A comprehensive guide on how to use Meta's LLaMA 2, the new open-source
AI model challenging OpenAI's ChatGPT and Google's Bard.

</div>

<div class="card">

<div class="card-title">

[Beyond LLaMA: The Power of Open
LLMs](https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*c3XC-3-pgvtxakXTmKubUA.jpeg)](https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f)

</div>

How LLaMA is making open-source cool again

</div>

<div class="card">

<div class="card-title">

[Facebook parent Meta unveils LLaMA 2 open-source AI model for
commercial
us](https://venturebeat.com/ai/facebook-parent-meta-unveils-llama-2-open-source-ai-model-for-commercial-use)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_vector_art_cybernetic_llama_wearing_sunglasses_synthwav_d3f82260-2c47-4abd-9599-b91751711f5b.png?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/facebook-parent-meta-unveils-llama-2-open-source-ai-model-for-commercial-use)

</div>

Not only has LLaMA been trained on more data, with more parameters, the
model also performs better than its predecessor, according to Meta.

</div>

<div class="card">

<div class="card-title">

[MosaicML launches MPT-7B-8K, a 7B-parameter open-source LLM with 8k
context](https://venturebeat.com/ai/mosaicml-launches-mpt-7b-8k-a-7b-parameter-open-source-llm)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2023/07/Mosaic-ML.jpg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/mosaicml-launches-mpt-7b-8k-a-7b-parameter-open-source-llm)

</div>

MosaicML claims that the MPT-7B-8K LLM exhibits exceptional proficiency
in summarization and answering tasks compared to previous models.

</div>

<div class="card">

<div class="card-title">

[The \$1 billion gamble to ensure AI doesn’t destroy
humanity](https://www.thediff.co/r/a2af7311?m=5ba63d9b-6620-4051-8686-515cd8a8f374)

</div>

<div class="card-image">

[![](https://platform.vox.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/24788204/Vox_Anthropic_final.jpg?quality=90&strip=all&crop=0%2C3.4613147178592%2C100%2C93.077370564282&w=1200)](https://www.thediff.co/r/a2af7311?m=5ba63d9b-6620-4051-8686-515cd8a8f374)

</div>

The founders of Anthropic quit OpenAI to make a safe AI company. It’s
easier said than done.

</div>

<div class="card">

<div class="card-title">

[Unraveling the Power of Chain-of-Thought Prompting in Large Language
Models](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/cot-brain-model-chains.jpg)](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)

</div>

This article delves into the concept of Chain-of-Thought (CoT)
prompting, a technique that enhances the reasoning capabilities of large
language models (LLMs). It discusses the principles behind CoT
prompting, its application, and its impact on the performance of LLMs.

</div>

<div class="card">

<div class="card-title">

[GitHub - Mooler0410/LLMsPracticalGuide: A curated list of practical
guide r](https://github.com/Mooler0410/LLMsPracticalGuide)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/4a3206398769105f4d6992be690752d89bd655e13bafcaf464ecde09cbc72a56/Mooler0410/LLMsPracticalGuide)](https://github.com/Mooler0410/LLMsPracticalGuide)

</div>

A curated list of practical guide resources of LLMs (LLMs Tree,
Examples, Papers) - Mooler0410/LLMsPracticalGuide

</div>

<div class="card">

<div class="card-title">

[Falcon LLM: The New King of Open-Source
LLMs](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/arya_falcon_llm_new_king_llms_3.png)](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)

</div>

Falcon LLM, is the new large language model that has taken the crown
from LLaMA.

</div>

<div class="card">

<div class="card-title">

[Introduction to the Open LLM Falcon-40B: Performance, Training Data,
and
Ar](https://towardsdatascience.com/introduction-to-the-open-llm-falcon-40b-performance-training-data-and-architecture-98388fa40226?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*nlOvoxsWqgObj_Jj)](https://towardsdatascience.com/introduction-to-the-open-llm-falcon-40b-performance-training-data-and-architecture-98388fa40226?source=rss----7f60cf5620c9---4)

</div>

Get started using Falcon-7B, Falcon-40B, and their instruct versions

</div>

<div class="card">

<div class="card-title">

[Meet FinGPT: An Open-Source Financial Large Language Model
(LLMs)](https://www-marktechpost-com.cdn.ampproject.org/c/s/www.marktechpost.com/2023/06/16/meet-fingpt-an-open-source-financial-large-language-model-llms?amp=)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/06/Screenshot-2023-06-15-at-10.50.11-PM.png)](https://www-marktechpost-com.cdn.ampproject.org/c/s/www.marktechpost.com/2023/06/16/meet-fingpt-an-open-source-financial-large-language-model-llms?amp=)

</div>

Large language models have increased due to the ongoing development and
advancement of artificial intelligence, which has profoundly impacted
the state of natural language processing in various fields. The
potential use of these models in the financial sector has sparked
intense attention in light of this radical upheaval. However,
constructing an effective and efficient open-source economic language
model depends on gathering high-quality, pertinent, and current data.
The use of language models in the financial sector exposes many
barriers. These vary from challenges in getting data, maintaining
various data forms and kinds, and coping with inconsistent data quality
to the crucial

</div>

<div class="card">

<div class="card-title">

[LMM Garden \| Discover, search, and compare LLMs](https://llm.garden)

</div>

<div class="card-image">

[![](https://llm.garden/wp-content/uploads/2023/05/Social-share_LLM-Garden-1024x535.png)](https://llm.garden)

</div>

Welcome to the LMM garden! A searchable list of open-source and
off-the-shelf LLMs available to ML practitioners. Know of a new LLM? Add
it

</div>

<div class="card">

<div class="card-title">

[iryna-kondr/scikit-llm](https://github.com/iryna-kondr/scikit-llm/issues)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/350c1f2d6ab49a8c893e709f629e66749bf5265df96eb98a9d57ba89c89f2999/iryna-kondr/scikit-llm)](https://github.com/iryna-kondr/scikit-llm/issues)

</div>

Seamlessly integrate LLMs into scikit-learn.

</div>

<div class="card">

<div class="card-title">

[The Case for Running AI on CPUs Isn’t Dead
Yet](https://spectrum.ieee.org/ai-cpu)

</div>

<div class="card-image">

[![](https://spectrum.ieee.org/media-library/an-intel-xeon-processor-on-a-black-backdrop-the-processor-is-shown-from-both-above-and-below-displaying-the-thousands-of-conta.jpg?id=33743986&width=1200&height=600&coordinates=0%2C698%2C0%2C698)](https://spectrum.ieee.org/ai-cpu)

</div>

GPUs may dominate, but CPUs could be perfect for smaller AI models

</div>

<div class="card">

<div class="card-title">

[The Art of Prompt Design: Prompt Boundaries and Token
Healing](https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/resize:fit:1200/1*PPLOArQM0wXZ5V55VbTNYA.png)](https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38)

</div>

Learn how standard greedy tokenization introduces a subtle and powerful
bias that can have all kinds of unintended consequences.

</div>

<div class="card">

<div class="card-title">

[Sonali Pattnaik on LinkedIn: \#generativeai \#ai \| 45
comments](https://www.linkedin.com/posts/sonali-pattnaik_generativeai-ai-activity-7063160223967973376-3K0P)

</div>

<div class="card-image">

[![](https://static.licdn.com/aero-v1/sc/h/c45fy346jw096z9pbphyyhdz7)](https://www.linkedin.com/posts/sonali-pattnaik_generativeai-ai-activity-7063160223967973376-3K0P)

</div>

AI companies are using LangChain to supercharge their LLM apps. Here is
a comprehensive guide of resources to build your LangChain + LLM
journey.  🔗 What is… \| 45 comments on LinkedIn

</div>

<div class="card">

<div class="card-title">

[The Non-Silence of the
LLMs](https://informationisbeautiful.net/2023/the-non-silence-of-the-llms)

</div>

<div class="card-image">

[![](https://infobeautiful4.s3.amazonaws.com/2023/05/IIB-LLM-decorative-blog-blog-1400x400-1-960x274.png)](https://informationisbeautiful.net/2023/the-non-silence-of-the-llms)

</div>

AI is getting very chatty! Here’s a visualisation charting the rise of
Large Language Models like GPT4, LaMDA, LLaMa, PaLM and their bots...

</div>

<div class="card">

<div class="card-title">

[Super Bard: The AI That Can Do It All and
Better](https://www.kdnuggets.com/2023/05/super-bard-ai-better.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/awan_super_bard_ai_better_1.png)](https://www.kdnuggets.com/2023/05/super-bard-ai-better.html)

</div>

A new AI Bard powered by PaLM V2 that can write, translate, and code
better than ChatGPT.

</div>

<div class="card">

<div class="card-title">

[Edge 291: Reinforcement Learning with Human
Feedback](https://thesequence.substack.com/p/edge-291-reinforcement-learning-with)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1aaa4cc-10d6-4ada-bba0-f1f2f0793427_1024x1024.png)](https://thesequence.substack.com/p/edge-291-reinforcement-learning-with)

</div>

1\) Reinforcement Learning with Human Feedback(RLHF) 2) The RLHF paper,
3) The transformer reinforcement learning framework.

</div>

<div class="card">

<div class="card-title">

[Google dives into the ‘supercomputer’ game by knitting together
purpose-bui](https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2022/12/VB_dictionary-page_romain-vignes-ywqa9IZB-dU-unsplash.jpg?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training)

</div>

Google's new machines combine Nvidia H100 GPUs with Google’s high-speed
interconnections for AI tasks like training very large language models.

</div>

<div class="card">

<div class="card-title">

[Distilling Step-by-Step! Outperforming Larger Language Models
with...](https://arxiv.org/abs/2305.02301)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2305.02301)

</div>

Deploying large language models (LLMs) is challenging because they are
memory inefficient and compute-intensive for practical applications. In
reaction, researchers train smaller task-specific...

</div>

<div class="card">

<div class="card-title">

[SparseGPT: Massive Language Models Can Be Accurately Pruned in
One-Shot](https://arxiv.org/abs/2301.00774)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2301.00774)

</div>

We show for the first time that large-scale generative pretrained
transformer (GPT) family models can be pruned to at least 50% sparsity
in one-shot, without any retraining, at minimal loss of...

</div>

<div class="card">

<div class="card-title">

[openlm-research/open_llama: OpenLLaMA, a permissively licensed open
source reproduction of Meta AI’s LLaMA 7B trained on the RedPajama
dataset](https://github.com/openlm-research/open_llama)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/e7ffbff063d324707d142c5ab7f43a0491b51bf163bb2b7cb51ae1ca0f4eda81/openlm-research/open_llama)](https://github.com/openlm-research/open_llama)

</div>

OpenLLaMA, a permissively licensed open source reproduction of Meta AI’s
LLaMA 7B trained on the RedPajama dataset - openlm-research/open_llama

</div>

<div class="card">

<div class="card-title">

[guidance-ai/guidance: A guidance language for controlling large
language models.](https://github.com/microsoft/guidance)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/40caa4be0603b938000317605dfdb2293da8c409e5cc9f3168bcd98f0b97c888/guidance-ai/guidance)](https://github.com/microsoft/guidance)

</div>

A guidance language for controlling large language models. -
guidance-ai/guidance

</div>

<div class="card">

<div class="card-title">

[Blog \|
Anyscale](https://www.anyscale.com/blog/how-to-fine-tune-and-serve-llms-simply-quickly-and-cost-effectively-using)

</div>

Anyscale is the leading AI application platform. With Anyscale,
developers can build, run and scale AI applications instantly.

</div>

<div class="card">

<div class="card-title">

[Parameter-Efficient LLM Finetuning With Low-Rank Adaptation
(LoRA)](https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html)

</div>

<div class="card-image">

[![](https://sebastianraschka.com/images/blog/2023/llm-finetuning-llama-adapter/hero.jpg)](https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html)

</div>

In the rapidly evolving field of AI, using large language models in an
efficient and effective manner is becoming more and more important. In
this article, y...

</div>

<div class="card">

<div class="card-title">

[Edge 286: Vicuna, the LLaMA-Based Model that Matches ChatGPT
Performance](https://thesequence.substack.com/p/edge-286-vicuna-the-llama-based-model)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37f4993d-660a-44f2-af55-b40a5b870e8c_1024x1024.png)](https://thesequence.substack.com/p/edge-286-vicuna-the-llama-based-model)

</div>

Created by researchers from UC Berkeley, CMU, Stanford, and UC San
Diego, Vicuna is part of the new wave of models that use Meta's LLaMA as
its foundation.

</div>

<div class="card">

<div class="card-title">

[Grounding Large Language Models in a Cognitive Foundation: How to Build
Som](https://thegradient.pub/grounding-large-language-models-in-a-cognitive-foundation)

</div>

<div class="card-image">

[![](https://thegradient.pub/content/images/2023/04/header-5.svg)](https://thegradient.pub/grounding-large-language-models-in-a-cognitive-foundation)

</div>

Many intelligent robots have come and gone, failing to become a
commercial success. We’ve lost Aibo, Romo, Jibo, Baxter—even Alexa is
reducing staff. Perhaps they failed to reach their potential because you
can’t have a meaningful conversation with them. We are now at an
inflection point: AI

</div>

<div class="card">

<div class="card-title">

[Data Machina
\#198](https://datamachina.substack.com/p/data-machina-198)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F212c16cd-1315-43b1-9dda-6e09235ce41d_1006x1006.png)](https://datamachina.substack.com/p/data-machina-198)

</div>

Your own LLM. MiniGPT-4. WebGPT on WebGPU. Transformers from scratch.
ChatGTP Plugins demo live. Whisper JAX. LLaVA. MetaAI DINO SoTA Computer
Vision. Autonomous agents in LangChain. RedPajama.

</div>

<div class="card">

<div class="card-title">

[Finetuning Large Language
Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa534808e-9284-47eb-9b4d-3e3aedc0b5da_1180x842.png)](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)

</div>

An introduction to the core ideas and approaches

</div>

<div class="card">

<div class="card-title">

[The LLama Effect: How an Accidental Leak Sparked a Series of Impressive
Ope](https://thesequence.substack.com/p/the-llama-effect-how-an-accidental)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef03b36c-e5da-49d6-af96-e1ad9a078c0d_1024x1024.png)](https://thesequence.substack.com/p/the-llama-effect-how-an-accidental)

</div>

Sundays, The Sequence Scope brings a summary of the most important
research papers, technology releases and VC funding deals in the
artificial intelligence space.

</div>

<div class="card">

<div class="card-title">

[Stanford CRFM](https://crfm.stanford.edu/2023/03/13/alpaca.html)

</div>

</div>

<div class="card">

<div class="card-title">

[Meta has built a massive new language AI—and it’s giving it away for
free](https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency)

</div>

<div class="card-image">

[![](https://wp.technologyreview.com/wp-content/uploads/2022/05/tiles2-1.jpeg?resize=1200,600)](https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency)

</div>

Facebook’s parent company is inviting researchers to pore over and pick
apart the flaws in its version of GPT-3

</div>

<div class="card">

<div class="card-title">

[Eight Things to Know about Large Language
Models](https://arxiv.org/abs/2304.00612)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2304.00612)

</div>

The widespread public deployment of large language models (LLMs) in
recent months has prompted a wave of new attention and engagement from
advocates, policymakers, and scholars from many fields....

</div>

<div class="card">

<div class="card-title">

[Baby AGI: The Birth of a Fully Autonomous
AI](https://www.kdnuggets.com/2023/04/baby-agi-birth-fully-autonomous-ai.html)

</div>

<div class="card-image">

[![](https://www.kdnuggets.com/wp-content/uploads/arya_baby_agi_birth_fully_autonomous_ai_3.png)](https://www.kdnuggets.com/2023/04/baby-agi-birth-fully-autonomous-ai.html)

</div>

Introducing the new fully autonomous task manager that can create, track
and prioritize your company's projects using artificial intelligence.

</div>

<div class="card">

<div class="card-title">

[Hacker
News](https://magazine.sebastianraschka.com/p/understanding-large-language-models)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9a0766d-2e52-4af0-96c5-3e07a30d6ecb_1868x1130.png)](https://magazine.sebastianraschka.com/p/understanding-large-language-models)

</div>

A Cross-Section of the Most Relevant Literature To Get Up to Speed

</div>

<div class="card">

<div class="card-title">

[📝 Guest Post: How to Enhance the Usefulness of Large Language
Models\*](https://thesequence.substack.com/p/guest-post-how-to-enhance-the-usefulness)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F644b606d-622a-4a15-acb7-02b97ad843a9_3200x1454.png)](https://thesequence.substack.com/p/guest-post-how-to-enhance-the-usefulness)

</div>

In this guest post, Filip Haltmayer, a Software Engineer at Zilliz,
explains how LangChain and Milvus can enhance the usefulness of Large
Language Models (LLMs) by allowing for the storage and retrieval of
relevant documents. By integrating Milvus, a vector database, with
LangChain, LLMs can process more tokens and improve their conversational
abilities.

</div>

<div class="card">

<div class="card-title">

[Prompt
Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering)

</div>

Prompt Engineering, also known as In-Context Prompting, refers to
methods for how to communicate with LLM to steer its behavior for
desired outcomes without updating the model weights. It is an empirical
science and the effect of prompt engineering methods can vary a lot
among models, thus requiring heavy experimentation and heuristics. This
post only focuses on prompt engineering for autoregressive language
models, so nothing with Cloze tests, image generation or multimodality
models.

</div>

<div class="card">

<div class="card-title">

[A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)

</div>

<div class="card-image">

[![](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png)](https://arxiv.org/abs/2303.18223)

</div>

Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to
develop capable AI algorithms for comprehending and...

</div>

<div class="card">

<div class="card-title">

[New Ebook: A Beginner’s Guide to Large Language
Models](https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook)

</div>

<div class="card-image">

[![](https://www.nvidia.com/content/dam/en-zz/Solutions/lp/large-language-models-ebook/nvidia-llm-ebook-og.jpg)](https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook)

</div>

Explore what LLMs are, how they work, and gain insights into real-world
examples, use cases, and best practices.

</div>

<div class="card">

<div class="card-title">

[Maximizing the Potential of LLMs: A Guide to Prompt
Engineering](https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms)

</div>

<div class="card-image">

[![](https://ruxu.devassets/images/openai.png)](https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms)

</div>

</div>

<div class="card">

<div class="card-title">

[The Magic of LLMs — Prompt
Engineering](https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=rss----7f60cf5620c9---4)

</div>

<div class="card-image">

[![](https://miro.medium.com/v2/da:true/resize:fit:1200/0*ri0kB_t9WfNZtpLe)](https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=rss----7f60cf5620c9---4)

</div>

Garbage in, garbage out has never been more true.

</div>

<div class="card">

<div class="card-title">

[📝 Guest Post: Caching LLM Queries for Improved Performance and Cost
Savings\*](https://thesequence.substack.com/p/guest-post-caching-llm-queries-for)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1763eb47-236b-4dfd-851c-2a388c7a5671_3200x1454.png)](https://thesequence.substack.com/p/guest-post-caching-llm-queries-for)

</div>

If you're looking for a way to improve the performance of your large
language model (LLM) application while reducing costs, consider
utilizing a semantic cache to store LLM responses.

</div>

<div class="card">

<div class="card-title">

[OpenAI Platform](https://platform.openai.com/overview)

</div>

<div class="card-image">

[![](https://cdn.openai.com/API/images/opengraph.png)](https://platform.openai.com/overview)

</div>

Explore developer resources, tutorials, API docs, and dynamic examples
to get the most out of OpenAI's platform.

</div>

</div>
