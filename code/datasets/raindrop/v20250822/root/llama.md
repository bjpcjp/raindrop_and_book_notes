<div class="nav">

⟵ [Up](index.html)  \|  [Index](index.html)

</div>

# llama

<div class="cards">

<div class="card">

<div class="card-title">

[ngafar/llama-scan: Transcribe PDFs with local
LLMs](https://github.com/ngafar/llama-scan)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/f7016f297dce503eb4904222bbdfb962ceb0e1e800f42fb30795657063161bba/ngafar/llama-scan)](https://github.com/ngafar/llama-scan)

</div>

Transcribe PDFs with local LLMs

</div>

<div class="card">

<div class="card-title">

[Meta Introduces KernelLLM: An 8B LLM that Translates PyTorch Modules
into Efficient Triton GPU
Kernels](https://www.marktechpost.com/2025/05/20/meta-introduces-kernelllm-an-8b-llm-that-translates-pytorch-modules-into-efficient-triton-gpu-kernels/)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2025/05/llm_performance_comparison-scaled.png)](https://www.marktechpost.com/2025/05/20/meta-introduces-kernelllm-an-8b-llm-that-translates-pytorch-modules-into-efficient-triton-gpu-kernels/)

</div>

</div>

<div class="card">

<div class="card-title">

[The Llama 4 herd: The beginning of a new era of natively multimodal AI
innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)

</div>

<div class="card-image">

[![](https://scontent-ber1-1.xx.fbcdn.net/v/t39.2365-6/488639590_2182781778834283_7341615399691839509_n.png?_nc_cat=107&ccb=1-7&_nc_sid=e280be&_nc_ohc=9buYuGUTUwMQ7kNvwGtzUMi&_nc_oc=AdkN3SnJ11eSLEUJlk4ya4OUL7KaIj2j0TnxIsboqdpW3969c7_L8tK24zlT4Og1jfg&_nc_zt=14&_nc_ht=scontent-ber1-1.xx&_nc_gid=O7pjMcOm63OU1lqMXrq3Zg&oh=00_AYEQyK79iiih-1eagCAdYCNZR346qSKGGzOYg-Mlp3NBdQ&oe=680BDB60)](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)

</div>

We’re introducing Llama 4 Scout and Llama 4 Maverick, the first
open-weight natively multimodal models with unprecedented context
support and our first built using a mixture-of-experts (MoE)
architecture.

</div>

<div class="card">

<div class="card-title">

[llama.cpp guide - Running LLMs locally, on any hardware, from
scratch](https://steelph0enix.github.io/posts/llama-cpp-guide/)

</div>

<div class="card-image">

[![](https://steelph0enix.github.io/og-image.png)](https://steelph0enix.github.io/posts/llama-cpp-guide/)

</div>

Psst, kid, want some cheap and small LLMs?

</div>

<div class="card">

<div class="card-title">

[LlamaIndex : LlamaIndex](https://docs.llamaindex.ai/en/stable)

</div>

</div>

<div class="card">

<div class="card-title">

[Ten Wild Examples of Llama 3.1 Use
Cases](https://www.marktechpost.com/2024/08/04/ten-wild-examples-of-llama-3-1-use-cases)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/08/Screenshot-2024-08-04-at-1.40.31-AM.png)](https://www.marktechpost.com/2024/08/04/ten-wild-examples-of-llama-3-1-use-cases)

</div>

Meta's recent release of Llama 3.1 has stirred excitement in the AI
community, offering an array of remarkable applications. This
groundbreaking model, particularly the 405B variant, stands out for its
superior performance and open-source accessibility, outpacing even
top-tier closed models. Here are ten wild examples showcasing the
versatile use cases of Llama 3.1, from enhancing personal gadgets to
innovative AI deployments. Efficient Task Automation: Llama 3.1 405B can
be harnessed to teach the smaller 8B model how to execute tasks
perfectly, reducing costs and latency. This setup allows users to train
the 8B model to handle various operations, providing a

</div>

<div class="card">

<div class="card-title">

[Meta unleashes its most powerful AI model, Llama 3.1, with 405B
parameters](https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters)

</div>

<div class="card-image">

[![](https://venturebeat.com/wp-content/uploads/2024/04/nuneybits_Vector_art_of_a_llama_in_a_blazing_fast_racecar_7f670485-6ad6-482b-ae36-c52aa0cf61a6-transformed-1.webp?w=1024?w=1200&strip=all)](https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters)

</div>

Llama 3.1 is the latest version of Meta's large language models, with a
new model weight, 405 billion parameters, the biggest model it's
trained.

</div>

<div class="card">

<div class="card-title">

[Customize Generative AI Models for Enterprise Applications with Llama
3.1](https://developer.nvidia.com/blog/customize-generative-ai-models-for-enterprise-applications-with-llama-3-1)

</div>

<div class="card-image">

[![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/04/dev-llama3-blog-1920x1080-1.png)](https://developer.nvidia.com/blog/customize-generative-ai-models-for-enterprise-applications-with-llama-3-1)

</div>

The newly unveiled Llama 3.1 collection of 8B, 70B, and 405B large
language models (LLMs) is narrowing the gap between proprietary and
open-source models. Their open nature is attracting more…

</div>

<div class="card">

<div class="card-title">

[Llama 3.1 Released: Meta’s New Open-Source AI Model that You can
Fine-Tune,](https://www.marktechpost.com/2024/07/23/llama-3-1-released-metas-new-open-source-ai-model-that-you-can-fine-tune-distill-and-deploy-anywhere-and-available-in-8b-70b-and-405b)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2024/07/Screenshot-2024-07-23-at-5.29.09-PM.png)](https://www.marktechpost.com/2024/07/23/llama-3-1-released-metas-new-open-source-ai-model-that-you-can-fine-tune-distill-and-deploy-anywhere-and-available-in-8b-70b-and-405b)

</div>

Meta announced the release of Llama 3.1, the most capable model in the
LLama Series. This latest iteration of the Llama series, particularly
the 405B model, represents a substantial advancement in open-source AI
capabilities, positioning Meta at the forefront of AI innovation.  Meta
has long advocated for open-source AI, a stance underscored by Mark
Zuckerberg’s assertion that open-source benefits developers, Meta, and
society. Llama 3.1 embodies this philosophy by offering state-of-the-art
capabilities in an openly accessible model. The release aims to
democratize AI, making cutting-edge technology available to various
users and applications. The Llama 3.1 405B model stands out for

</div>

<div class="card">

<div class="card-title">

[Meta Llama 3.1 405b is outperforming private models with open
access](https://dataconomy.com/2024/07/24/meta-llama-3-1-405b-comparison-features)

</div>

<div class="card-image">

[![](https://dataconomy.com/wp-content/uploads/2024/07/meta-llama-3.1-405b_3.jpg)](https://dataconomy.com/2024/07/24/meta-llama-3-1-405b-comparison-features)

</div>

Meta llama 3.1 405b kicks off a fresh chapter for open-source language
models. This breakthrough brings unmatched skills to AI

</div>

<div class="card">

<div class="card-title">

[naklecha/llama3-from-scratch](https://github.com/naklecha/llama3-from-scratch)

</div>

<div class="card-image">

[![](https://opengraph.githubassets.com/8d2e244aeba16103152d524e2782f1a003e33ae090eae093973ff64f742be56b/naklecha/llama3-from-scratch)](https://github.com/naklecha/llama3-from-scratch)

</div>

llama3 implementation one matrix multiplication at a time -
naklecha/llama3-from-scratch

</div>

<div class="card">

<div class="card-title">

[Meta says Llama 3 beats most other models, including Gemini - The
Verge](https://www.theverge.com/2024/4/18/24134103/llama-3-benchmark-testing-ai-gemma-gemini-mistral)

</div>

<div class="card-image">

[![](https://cdn.vox-cdn.com/thumbor/aFVf1nZ5PjZNbxd151IaoqXfmvA=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951355/STK043_VRG_Illo_N_Barclay_1_Meta.jpg)](https://www.theverge.com/2024/4/18/24134103/llama-3-benchmark-testing-ai-gemma-gemini-mistral)

</div>

The models have some pretty good general knowledge.

</div>

<div class="card">

<div class="card-title">

[LLaMA Now Goes Faster on CPUs](https://justine.lol/matmul)

</div>

<div class="card-image">

[![](https://justine.lol/matmul/llamafile.png)](https://justine.lol/matmul)

</div>

I wrote 84 new matmul kernels to improve llamafile CPU performance.

</div>

<div class="card">

<div class="card-title">

[Llama from scratch](https://blog.briankitano.com/llama-from-scratch)

</div>

<div class="card-image">

[![](https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman-1683556668-0.png)](https://blog.briankitano.com/llama-from-scratch)

</div>

I want to provide some tips from my experience implementing a paper. I'm
going to cover my tips so far from implementing a dramatically
scaled-down versio...

</div>

<div class="card">

<div class="card-title">

[Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in
Extended-Con](https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing)

</div>

<div class="card-image">

[![](https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg)](https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing)

</div>

A multifaceted challenge has arisen in the expansive realm of natural
language processing: the ability to adeptly comprehend and respond to
intricate and lengthy instructions. As communication nuances become more
complicated, the shortcomings of prevailing models in dealing with
extensive contextual intricacies have been laid bare. Within these
pages, an extraordinary solution crafted by the dedicated minds at
Together AI comes to light—a solution that holds the promise of
reshaping the very fabric of language processing. This innovation has
profound implications, especially in tasks requiring an acute grasp of
extended contextual nuances. Contemporary natural language processing
techniques rely heavily on

</div>

<div class="card">

<div class="card-title">

[The LLama Effect: How an Accidental Leak Sparked a Series of Impressive
Ope](https://thesequence.substack.com/p/the-llama-effect-how-an-accidental)

</div>

<div class="card-image">

[![](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef03b36c-e5da-49d6-af96-e1ad9a078c0d_1024x1024.png)](https://thesequence.substack.com/p/the-llama-effect-how-an-accidental)

</div>

Sundays, The Sequence Scope brings a summary of the most important
research papers, technology releases and VC funding deals in the
artificial intelligence space.

</div>

<div class="card">

<div class="card-title">

[Dalai](https://cocktailpeanut.github.io/dalai#/)

</div>

<div class="card-image">

[![](https://cocktailpeanut.github.io/dalai/preview.png)](https://cocktailpeanut.github.io/dalai#/)

</div>

Dead simple way to run LLaMA on your computer

</div>

</div>
