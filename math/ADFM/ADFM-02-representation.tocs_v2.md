- Representation  
  - Degrees of Belief and Probability  
    Conditional plausibility comparisons establish an ordering system that leads to representing belief with a real-valued function P. Under assumptions of universal comparability and transitivity, this function maps to probability values between 0 and 1. Fundamental axioms of probability then formalize how these plausibilities quantify uncertainty. For more, see [Probability Theory: The Logic of Science](https://bayes.wustl.edu/etj/prob/book.pdf).  
  - Probability Distributions  
    Probability distributions assign likelihoods to variable outcomes, with discrete distributions represented by probability mass functions and continuous ones by density functions. Discrete probabilities sum to 1, while continuous densities integrate to 1. Parameterizations such as the uniform and Gaussian distributions illustrate typical forms. An introductory resource is [Introduction to Probability](http://web.mit.edu/dimitrib/www/prob/prob10.pdf).  
    - Discrete Probability Distributions  
      Discrete probability distributions map a finite set of variable states to probabilities summing to one, with parameters reduced by normalization constraints. Notational conventions utilize lowercase letters for variable assignments. Examples include distributions over die rolls with probabilities θ1:6. Julia and MATLAB programming conventions for indexing are mentioned.  
    - Continuous Probability Distributions  
      Continuous distributions assign probability density functions where the probability of any specific value is infinitesimally small, requiring integration over intervals to compute probabilities. Cumulative distribution functions and quantile functions complement density functions. Uniform and Gaussian distributions exemplify continuous models. Refer to [Bertsekas and Tsitsiklis, Introduction to Probability](https://athenasc.com/probbook.html) for foundational theory.  
  - Joint Distributions  
    Joint distributions describe probabilities over multiple variables, with discrete joints represented by tables that grow exponentially in size. Independence assumptions reduce complexity via product factorizations, while decision trees and factor functions provide alternative compact representations. Continuous joint distributions include multivariate uniforms, mixtures, discretizations, and Gaussian models with covariance parameterizations. See [Probabilistic Graphical Models](https://mitpress.mit.edu/books/probabilistic-graphical-models) for deeper insights.  
    - Discrete Joint Distributions  
      Joint discrete probabilities cover all variable assignments with probabilities summing to one. The exponential growth of parameters (2^n - 1 for n binary variables) motivates exploiting independence assumptions, which factorize distributions into products reducing parameter count. Factor data structures and decision tree representations optimize storage when repeated values exist.  
    - Continuous Joint Distributions  
      These extend discrete concepts to continuous variables using multivariate distributions. Uniform distributions over boxes and their mixtures allow flexible modeling. Piecewise-constant discretization and decision trees map continuous distributions efficiently. Multivariate Gaussian distributions are parameterized by mean vectors and covariance matrices, with independence expressed via diagonal covariance.  
  - Conditional Distributions  
    Conditional distributions describe probabilities of variables given evidence, defined by the ratio of joint probabilities. Key properties include normalization and the law of total probability applied conditionally. Bayes’ theorem relates conditional probabilities by swapping conditioning variables. Representations vary by discrete and continuous variables, including conditional probability tables, Gaussian models, and sigmoid/logit functions modeling soft thresholds. Deterministic variables are also discussed.  
    - Discrete Conditional Models  
      Conditional discrete distributions use tables indexed by conditioned variable values, where probabilities sum to one over the conditioned variable given fixed evidence. Tables grow exponentially with conditioning variables, and decision trees optimize representation when many values repeat.  
    - Conditional Gaussian Models  
      These model continuous variables conditioned on discrete variables as mixtures of Gaussian distributions, parameterized separately by each discrete case. The total parameters scale with the number of discrete states.  
    - Linear Gaussian Models  
      Linear Gaussian models relate continuous variables linearly before applying Gaussian noise, modeling P(X|Y) with a Gaussian whose mean is a linear function of Y. Parameters include linear coefficients, bias, and variance.  
    - Conditional Linear Gaussian Models  
      These combine discrete and continuous conditioning, representing P(X|Y,Z) with Gaussian distributions whose means depend linearly on continuous parents and where discrete parent states index separate parameter sets.  
    - Sigmoid Models  
      Sigmoid or logit models define soft probabilistic thresholds for binary outcomes conditioned on continuous variables, controlling threshold location and spread with parameters, producing characteristic "S"-shaped curves.  
    - Deterministic Variables  
      Deterministic variables have probability 1 assigned to specific values determined by evidence functions; sparse factor representations efficiently encode these without wasteful zero probabilities.  
  - Bayesian Networks  
    Bayesian networks encode joint distributions using directed acyclic graphs and factorized conditional distributions at each node given parents. The chain rule constructs joint probabilities as products of conditionals, greatly reducing required parameters through structural assumptions. Example includes a satellite-monitoring problem modeling rare failures and system outcomes. Implementations use variable, factor, and graph structures. See [Probabilistic Graphical Models](https://mitpress.mit.edu/books/probabilistic-graphical-models).  
  - Conditional Independence  
    Conditional independence generalizes independence by asserting that two variables are independent given a third. This concept is encoded graphically in Bayesian networks via d-separation, specifying three canonical path patterns that block influence. The Markov blanket of a node consists of its parents, children, and children's other parents, forming the minimal conditioning set rendering the node independent of others. Correctness depends on validity of independence assumptions. For algorithmic details, see [Probabilistic Reasoning in Intelligent Systems](https://mitpress.mit.edu/books/probabilistic-reasoning-intelligent-systems).  
- Summary  
  The chapter motivates representing uncertainty through probability theory grounded in axioms linking plausibility and probability distributions. It reviews discrete and continuous distributions, joint and conditional distributions, and how mixtures increase modeling flexibility. Bayesian networks enable efficient joint distribution representation by exploiting conditional independence, which is rigorously defined by d-separation in graph structures. These foundational concepts enable scalable probabilistic modeling for complex systems.  
- Exercises  
  The exercises apply theoretical concepts to practical problems including deriving cumulative distributions of exponential variables, identifying mixture components, constructing decision trees for joint distributions, computing parameter counts for mixture models and Bayesian networks, examining d-separation and Markov blankets, and understanding the implications of network structure on independence. Each exercise reinforces foundational probability modeling and graph-based inference principles.
