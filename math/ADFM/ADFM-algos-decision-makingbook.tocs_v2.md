- Preface  
  The preface introduces the book's focus on algorithms for optimal decision making under uncertainty, emphasizing mathematical foundations and computational methods. It targets advanced undergraduates, graduate students, and professionals in various disciplines, requiring prior knowledge in calculus, linear algebra, and probability. The authors highlight the use of the Julia programming language for algorithm implementation and encourage sharing and translation of code, with resources available on the book’s webpage. For further background, see the [Algorithms for Decision Making webpage](http://mitpress.mit.edu/algorithms-for-decision-making).  

- Acknowledgments  
  This section credits students, teaching assistants, and numerous contributors who shaped the course underlying the textbook, and acknowledges editorial and stylistic influences such as Edward Tufte’s work. It also notes software and tools utilized in the book’s production, stressing collaborative and open-source foundations. For information on scholarly acknowledgments and their scope, see the [Research Acknowledgments Guide](https://www.aje.com/arc/acknowledging-contributions/).  

- 1 Introduction  
  Introduces decision making under uncertainty, defining agents that act based on observations with incomplete, noisy data. It identifies four key uncertainties—outcome, model, state, and interaction—and stresses their importance for robust automated decision-making. Applications include aircraft collision avoidance, autonomous driving, and medical screening, illustrating the breadth of the domain. For comprehensive AI context, see [Artificial Intelligence: A Modern Approach](https://aima.cs.berkeley.edu/).  
  - 1.1 Decision Making  
    Defines agents as physical or software entities interacting through an observe-act cycle, affected by uncertain observations and requiring intelligent action selection. It outlines the four main types of uncertainty agents must manage to make optimal decisions respectfully acknowledging these challenges as central to AI. The section is foundational for understanding agent-environment interaction. For foundational study, consult [Russell & Norvig’s AI text](https://aima.cs.berkeley.edu/).  
  - 1.2 Applications  
    Presents concrete examples of decision making under uncertainty, including aircraft collision avoidance, automated driving, breast cancer screening, financial portfolio allocation, and distributed wildfire surveillance. Each application is characterized by relevant sources of uncertainty and stakes, ranging from safety-critical aerospace scenarios to personalized medical recommendations. The examples exhibit practical demands that shape algorithm design. Related real-world case studies are available via [Stanford’s Decision Making Lab](https://sail.stanford.edu/).  
  - 1.3 Methods  
    Surveys methods for agent design: explicit programming, supervised learning, optimization, planning, and reinforcement learning. Emphasizes distinctions such as knowledge of models and adaptation from experience, highlighting strengths and limitations of each. Planning and reinforcement learning receive special focus due to their ability to handle uncertainty directly or through interaction. For algorithm overviews, see [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html).  
  - 1.4 History  
    Traces the evolution of decision-making theory from early automatons and logic rules, through economics and psychology, to engineering and modern computing. Key contributions include utility theory, trial-and-error learning, neural networks, symbolic AI, and operations research methods. Emphasizes interdisciplinary origins and convergence that underpin current algorithms. For historical perspectives, refer to [Nilsson’s Quest for Artificial Intelligence](https://ai.stanford.edu/~nilsson/QAI/qai.pdf).  
  - 1.5 Societal Impact  
    Discusses positive contributions of decision-making algorithms in sustainability, medicine, urban planning, and transportation, alongside challenges such as data biases, fairness, and adversarial vulnerabilities. Highlights the need for responsibility and ethical frameworks to avoid unintended consequences of algorithmic decisions. For detailed discussions, see the survey [Artificial Intelligence for Social Good](https://arxiv.org/abs/2001.01818).  
  - 1.6 Overview  
    Outlines the book’s five parts: probabilistic reasoning, sequential problems, model uncertainty, state uncertainty, and multiagent systems. Each part develops essential theory and algorithms, progressively addressing uncertainty in decision making from foundational representations to complex interactions among multiple agents. The overview provides structure for the comprehensive treatment of decision-making challenges. Explore this foundational approach through [Probabilistic Graphical Models](http://www.probabilistic-graphical-models.com/).  

- I Probabilistic Reasoning  
  Introduces fundamental probabilistic representations necessary for rational decision making under uncertainty, emphasizing probability distributions and graphical models for managing complex joint distributions. Covers inference, parameter learning, and utility theory foundations culminating in decision networks that integrate objectives with uncertainty. Sets foundational material for single-step decision problems with practical examples. The material aligns closely with [Probability Theory: The Logic of Science](https://bayes.wustl.edu/Manual/).  
  - 2 Representation  
    Develops formal foundations for representing uncertainty as degrees of belief encoded by probability distributions. Introduces axioms linking plausibility orders to probability values, ensuring consistency and enabling mathematical treatment. Discusses discrete and continuous distributions, including foundational examples such as uniform and Gaussian distributions, emphasizing parameter constraints and realistic modeling limitations. Offers computational representations essential for subsequent reasoning. For detailed axioms and formulations, consult [Fishburn’s Axioms of Probability](https://projecteuclid.org/euclid.ss/1177012602).  
  - 2.1 Degrees of Belief and Probability  
    Defines plausibility relations (more likely, as likely, less likely) and assumptions of universal comparability and transitivity, establishing representation as a real-valued function satisfying probability axioms. The approach justifies probabilities as consistent measures of uncertainty within rational decision making. For a formal treatment, see [Bayesian Probability Axioms](https://projecteuclid.org/euclid.bjps/1232125864).  
  - 2.2 Probability Distributions  
    Details discrete and continuous probability distribution representations. Discrete distributions assign mass functions summing to one over finite outcomes; continuous distributions use density functions integrating to one. The section introduces cumulative and quantile functions for continuous distributions and highlights mixture models, including Gaussian mixtures, for representing multimodal densities. Features key distributions such as uniform, Gaussian, truncated Gaussian, and mixtures, providing concrete parameterizations. Further study available at [Introduction to Probability](https://www.athenasc.com/probbook.html).  
  - 2.3 Joint Distributions  
    Covers the representation of probability distributions over multiple variables, termed joint distributions. For discrete variables, joints are multidimensional tables requiring exponential parameters but can be efficiently represented via independence assumptions, reducing parameters from 2^n-1 to n. Discusses the factorization of joint distributions using factors, enabling compact representation and computation. Presents decision trees to exploit repeated values for storage savings, formalizing factor data structures for practical use. For computational approaches, review [Probabilistic Graphical Models: Principles and Techniques](https://mitpress.mit.edu/books/probabilistic-graphical-models).
