- Inference
  - Inference in Bayesian Networks
    - The section defines inference as determining the distribution over query variables given observed evidence, using the posterior distribution terminology. It illustrates exact inference computations via conditional probability, marginalization, and the chain rule on a Bayesian network example. Factors and their operations—product, marginalization, and conditioning—are introduced as tools to implement exact inference. Computation complexity given factor products is a practical consideration. For further reading, see [Koller & Friedman, Probabilistic Graphical Models](https://mitpress.mit.edu/books/probabilistic-graphical-models).
  - Inference in Naive Bayes Models
    - This section focuses on naive Bayes networks where features conditionally independent given a class variable simplify inference. It specifies the joint distribution as prior times the product of class-conditional feature likelihoods and defines classification as posterior probability over classes given observed features. The section notes the proportionality used to avoid computing normalization constants explicitly and mentions decision-making considerations beyond max posterior class selection. Relevant resource: [Murphy, Machine Learning: A Probabilistic Perspective](https://mitpress.mit.edu/books/machine-learning-0).
  - Sum-Product Variable Elimination
    - Sum-product variable elimination improves inference efficiency by sequentially marginalizing hidden variables and interleaving factor products per an elimination ordering. The method reduces intermediate factor sizes compared to naive computation by early marginalization and reusing intermediate results, achieving linear scaling with network size in favorable cases. The section highlights the NP-hardness of choosing optimal variable order and references heuristics to minimize intermediate factors. More details can be found at [Darwiche, Modeling and Reasoning with Bayesian Networks](https://www.cambridge.org/core/books/modeling-and-reasoning-with-bayesian-networks/).
  - Belief Propagation
    - Belief propagation exploits message passing via the sum-product algorithm to compute marginal distributions efficiently on tree-structured Bayesian networks. For networks with cycles, junction tree transformations or loopy belief propagation enable exact or approximate inference respectively, albeit without guarantees of convergence. The method operates linearly on trees and generalizes to factor graphs. See [Kschischang et al., Factor Graphs and the Sum-Product Algorithm](https://ieeexplore.ieee.org/document/910572) for a tutorial.
  - Computational Complexity
    - Inference in Bayesian networks is NP-hard, demonstrated by reduction from 3SAT. A corresponding network structure encodes clause satisfaction via conditional probability distributions. This establishes the impracticality of general-purpose exact inference algorithms, motivating research into approximate inference methods. An in-depth complexity analysis is provided by [Cooper, The Computational Complexity of Probabilistic Inference using Bayesian Belief Networks](https://www.sciencedirect.com/science/article/abs/pii/000437029090022K).
  - Direct Sampling
    - Direct sampling draws independent samples from the joint distribution of a Bayesian network using its topological ordering. These samples estimate query probabilities by counting consistency with evidence but can be very inefficient if evidence is rare due to discarded inconsistent samples. Sampling relies on conditional probabilities and topological sorting to ensure parents are sampled first. For additional context, consult [Motwani & Raghavan, Randomized Algorithms](https://www.cambridge.org/core/books/randomized-algorithms/).
  - Likelihood Weighted Sampling
    - Likelihood weighted sampling improves efficiency by generating samples consistent with observed evidence, assigning weights according to the likelihood of evidence variables under the sampled parents. This approach reduces wasted computation compared to direct sampling but can still suffer inefficiency in cases of rare events, such as the chemical detection example. The method combines sampling with weighted importance to approximate posterior distributions effectively. See [Fung & Chang, Weighing and integrating evidence for stochastic simulation in Bayesian networks](https://www.sciencedirect.com/science/article/abs/pii/S0004370299000444) for further reading.
  - Gibbs Sampling
    - Gibbs sampling is a Markov chain Monte Carlo method generating correlated samples consistent with evidence by sequentially sampling each unobserved variable conditioned on the current values of all other variables in the network’s Markov blanket. This method converges to the true posterior distribution asymptotically and can be more efficient than direct or likelihood weighted sampling, especially for complex distributions. Burn-in and thinning techniques address sample correlation and convergence issues. For comprehensive coverage, see [Barber, Bayesian Reasoning and Machine Learning](http://www.cs.ucl.ac.uk/staff/D.Barber/textbook/).
  - Inference in Gaussian Models
    - Exact inference in multivariate Gaussian models leverages closed-form expressions for marginal and conditional distributions. Given joint mean and covariance matrices partitioned into query and evidence variables, the conditional distribution’s mean and covariance are computed via matrix operations involving inverses and products. This allows analytic solutions for Bayesian inference when the joint is Gaussian. The Distributions.jl package supports this in practice. For more, consult [Bishop, Pattern Recognition and Machine Learning](https://www.springer.com/gp/book/9780387310732).
