- **22 Online Belief State Planning**
  - **22.1 Lookahead with Rollouts**
    - Lookahead with rollouts samples next states randomly to estimate action value in partially observed problems.
    - Uses a generative model for transitions, rewards, and observations supporting high-dimensional spaces.
    - Builds on methods introduced in fully observable settings, adapted for belief states.
    - Refer to S. Ross et al.'s survey on online POMDP planning algorithms for deeper insight.
  - **22.2 Forward Search**
    - Forward search extends one-step lookahead to arbitrary depths using recursive Bellman backups over beliefs.
    - Computational complexity grows exponentially with depth as O(|A|^d |O|^d ), limiting practical depth.
    - Uses approximate value functions (e.g., QMDP) as leaf node utilities to guide search.
    - Observation and action branching can be pruned by domain knowledge or heuristics.
  - **22.3 Branch and Bound**
    - Branch and bound applies upper and lower bound pruning to reduce forward search complexity.
    - Can use bounds from fast informed bound for upper bounds and point-based value iteration for lower bounds.
    - Requires valid bounds to guarantee equivalence to full forward search results.
    - Demonstrated on problems like the crying baby with depth-based pruning.
  - **22.4 Sparse Sampling**
    - Sparse sampling avoids summing over all observations by sampling a fixed number m of observations per action.
    - Reduces complexity to O(|A|^d m^d ) in forward search approximations.
    - Enables handling large observation spaces by statistical sampling.
  - **22.5 Monte Carlo Tree Search**
    - Extends MDP Monte Carlo Tree Search (MCTS) to POMDPs by associating values and counts with action-observation histories rather than states.
    - Uses history trees alternating between action and observation nodes, storing Q(h, a) and N(h, a).
    - Balances exploration and exploitation using a UCB-like formula with exploration parameter c.
    - The root history updates as new observations arrive, allowing incremental search refinement.
    - Convergence and variations are detailed in [Silver and Veness, 2010](https://papers.nips.cc/paper/2010/file/2ff97f64c14e9aa3a1ac730422eb5a0e-Paper.pdf).
  - **22.6 Determinized Sparse Tree Search**
    - Reduces sampling and tree size by determinizing observations via a scenario-based particle belief using a determinizing matrix Φ.
    - Transitions and observations become deterministic along scenarios, decreasing tree size to O(|A|^d m) where m is number of scenarios.
    - Implements particles with fixed scenarios and depth indices to deterministically traverse belief branches.
    - Combines particle representation with forward search to reduce approximation complexity.
    - Further details in [Ye et al., 2017](https://www.jair.org/index.php/jair/article/view/11197).
  - **22.7 Gap Heuristic Search**
    - Uses the gap between upper and lower bounds on value U^+(b) − U^−(b) to guide exploration in online search.
    - Selects actions and belief branches that maximize this gap to improve value estimation efficiency.
    - Employs best-action best-state upper bound and rollout-based lower bound heuristics.
    - Allows early stopping when gap falls below a threshold, balancing computation and accuracy.
  - **22.8 Summary**
    - Summarizes key online planning approaches in POMDPs including lookahead, forward search, branch and bound, sparse sampling, MCTS, determinized sparse trees, and gap heuristic search.
    - Emphasizes tradeoffs between computational complexity and practical depth/horizon.
    - Notes that better bounds and rollout policies improve pruning and convergence.
    - Online methods exploit limited reachable belief space for tractability.
  - **22.9 Exercises**
    - Provides exercises to practice forward search computations with approximate value functions.
    - Illustrates sparse sampling action value calculations from sampled trajectories.
    - Shows determinized sparse tree search particle updates using transition and observation probabilities.
    - Reinforces theoretical concepts with concrete numeric examples.
