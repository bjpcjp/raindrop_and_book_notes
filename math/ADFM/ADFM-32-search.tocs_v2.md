- **E Search Algorithms**
  - **E.1 Search Problems**
    - Search problems focus on finding action sequences to maximize rewards over deterministic state transitions.
    - They frame as Markov decision processes but with deterministic transitions.
    - Examples include sliding tile puzzles, the Rubik's Cube, Sokoban, and shortest path problems.
    - State and action spaces can be finite or infinite, with absorbing states yielding no future reward.
    - For further reading, see [Markov Decision Processes](https://en.wikipedia.org/wiki/Markov_decision_process).
  - **E.2 Search Graphs**
    - Search problems with finite states/actions can be represented as graphs with states as nodes and transitions as edges.
    - Edges are labeled with actions and expected rewards.
    - Search algorithms explore such graphs by generating a search tree from an initial state.
    - Example provided from a 3Ã—3 sliding tile puzzle.
    - More on graph search at [Graph Search Algorithms](https://en.wikipedia.org/wiki/Graph_traversal).
  - **E.3 Forward Search**
    - Performs depth-limited search from an initial state, recursively exploring all possible action sequences up to depth d.
    - Uses an approximate value function U(s) to estimate terminal node values.
    - Results in a complete search tree with complexity O(|A|^d).
    - Depth-first nature can be inefficient due to redundant state visits.
    - See [Depth-First Search](https://en.wikipedia.org/wiki/Depth-first_search) for more.
  - **E.4 Branch and Bound**
    - Employs upper (Qhi) and lower (Ulo) bounds to prune suboptimal branches during search.
    - Actions are explored in order of descending upper bound values.
    - Can avoid exploring large portions of the search tree if bounds are effective.
    - Worst-case complexity equals forward search; efficiency depends heavily on tightness of heuristics.
    - Branch and bound compared with forward search in hex world example.
    - Refer to [Branch and Bound Method](https://en.wikipedia.org/wiki/Branch_and_bound).
  - **E.5 Dynamic Programming**
    - Avoids redundant evaluation by caching results of subproblems in a transposition table.
    - Applicable when problems exhibit optimal substructure, enabling reuse of computed optimal paths.
    - Shares the recursive structure of forward search but benefits from memoization.
    - Demonstrated improvements over pure forward search by reducing exponential state visits.
    - For more, see [Dynamic Programming](https://en.wikipedia.org/wiki/Dynamic_programming).
  - **E.6 Heuristic Search**
    - Improves branch and bound by ordering actions using a heuristic upper bound Uhi(s).
    - Maintains a cache of visited states to avoid redundant computations like dynamic programming.
    - Requires admissible (not overestimating) and consistent heuristics to guarantee optimality.
    - Orders actions by immediate reward plus heuristic, pruning branches that cannot improve current best.
    - Compared favorably against branch and bound in hex world example.
    - More details at [Heuristic Search](https://en.wikipedia.org/wiki/Heuristic_search_algorithm).
