1. **Q:** How are instruction set architectures classified based on internal storage, and what are the primary advantages and disadvantages of load-store versus register-memory architectures?
   **A:** Instruction set architectures are classified by internal storage types: stack, accumulator, and general-purpose registers (GPR). GPR architectures are further divided into load-store (register-register) and register-memory types. Load-store architectures allow memory access only through explicit load and store instructions, resulting in simple fixed-length encoding, a uniform pipeline-friendly execution time, and a straightforward code generation model but at the cost of higher instruction count and lower code density. Register-memory architectures allow one memory operand in ALU instructions, enabling data access without separate loads and improving code density but produce variable instruction lengths, less pipeline uniformity, and operands that are not fully equivalent since source operands can be overwritten.
   **External example:** ARM architecture uses a load-store model for performance benefits as detailed in ARM Cortex-A series documentation: https://developer.arm.com/documentation/ddi0500/latest

2. **Q:** What are the key addressing modes that a modern instruction set architecture should support, and how do their usage patterns influence instruction set design decisions?
   **A:** A modern instruction set architecture should support at least displacement (16 bits or more), immediate (8 to 16 bits), and register indirect addressing modes, as these account for 75% to 99% of operand addressing in measured benchmarks. Displacement addressing allows flexible access to local variables and structured data, with a wide distribution of offsets indicating support for multiple field sizes is beneficial. Immediate values tend to be small, mostly positive constants, making short immediate fields effective for most cases. The predominance of these modes guides architects toward minimal, orthogonal addressing modes that simplify hardware and compiler design.
   **External example:** Intel IA-32 architecture extensively uses displacement and immediate addressing as documented: Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 2: https://software.intel.com/sites/default/files/managed/39/c5/253666-sdm-vol-2abcd.pdf

3. **Q:** How does the number of operands and memory operands in an ALU instruction affect the instruction set classification, and what typical architectures correspond to these classes?
   **A:** ALU instructions differ in the number of operands (two or three) and how many operands may be memory references (zero to three). This leads to classifications: load-store (0 memory operands, usually three operands, like MIPS, ARM), register-memory (1 memory operand, two operands, like 80x86, IBM 360), and memory-memory (2 or 3 memory operands, used in VAX). Load-store architectures simplify hardware and decoding at the cost of more instructions; register-memory provides more compact code but complicates hardware; memory-memory offers compactness but greater variability and is mostly obsolete.
   **External example:** Comparison of RISC (load-store) and CISC (register-memory) architectures in Tanenbaum’s Modern Operating Systems: https://www.pearson.com/us/higher-education/program/Tanenbaum-Modern-Operating-Systems-4th-Edition/PGM244242.html

4. **Q:** Describe the impact of instruction encoding formats (variable length, fixed length, hybrid) on code size and processor implementation complexity, giving examples of architectures that adopt each format.
   **A:** Variable-length encoding, as in 80x86 and VAX, allows efficient code size by omitting unused instruction fields but increases decoder complexity and variable instruction timing. Fixed-length encoding, used by RISC architectures like MIPS, ARM, and PowerPC, simplifies decoding and pipeline implementation with uniform instruction size but can increase code size. Hybrid encoding, such as IBM 360 and Thumb (ARM), combines benefits by using multiple instruction lengths to reduce code size while maintaining reasonable decoder complexity.
   **External example:** ARM’s Thumb instruction set provides 16-bit instructions for code density with fixed-length format: ARM Architecture Reference Manual: https://developer.arm.com/documentation/ddi0406/latest

5. **Q:** How do compiler optimizations, particularly register allocation, influence instruction set design, and what architectural features support efficient compiler-generated code?
   **A:** Compilers perform complex optimizations like register allocation (often graph coloring) that require sufficient general-purpose registers (at least 16) for effective register use, improving performance by minimizing memory access. Architectures with orthogonal addressing modes applicable to all instructions simplify compiler code generation. Features that bind constants known at compile time, and provide primitives rather than high-level constructs in hardware, aid compiler efficiency. Limited or special-purpose registers increase compiler complexity and reduce generated code quality.
   **External example:** LLVM compiler infrastructure leverages abundant registers and orthogonal instruction sets such as in x86-64 to optimize code: https://llvm.org/docs/CodeGenerator.html

6. **Q:** What are the main types of control flow instructions, how are branch targets typically specified, and why is this important for instruction set design?
   **A:** Control flow includes conditional branches, jumps (unconditional branches), procedure calls, and returns. Branch targets are mostly specified using PC-relative addressing with signed offsets (usually 8–16 bits), enabling position-independent code and compact instruction encoding. Procedure returns and indirect jumps utilize register indirect addressing since the target is dynamic. The size of branch offsets affects instruction length and encoding efficiency; most branches target instructions within a few hundred instructions.
   **External example:** MIPS architecture’s use of PC-relative addressing for branches is detailed in: MIPS RISC Architecture: http://highered.mheducation.com/sites/dl/free/0072829055/571791/chap4.pdf

7. **Q:** Summarize the design priorities and architectural choices embodied in the MIPS instruction set architecture derived from traditional principles.
   **A:** MIPS is a 64-bit load-store architecture with 32 general-purpose and 32 floating-point registers, fixed 32-bit instruction length, simple addressing with displacement and immediate modes, support for 8, 16, 32, and 64-bit integers plus IEEE 754 floating-point, and simple ALU, branch, jump, and floating-point operations. It emphasizes pipelining efficiency, orthogonality, sufficient registers for compiler allocation, and minimalism, reflecting recommendations for desktop/server applications.
   **External example:** MIPS RISC Instruction Set Reference provides formal details reflecting these principles: https://inst.eecs.berkeley.edu/~cs61c/sp06/extra/mips-ref.pdf

8. **Q:** Explain the benefits and challenges of adding multimedia SIMD instructions to general-purpose instruction sets based on the material provided.
   **A:** SIMD multimedia instructions aim to accelerate operations on multiple data elements simultaneously, mimicking vector architectures. However, they often provide short fixed-width vectors, have limited registers, use data types mismatched with high-level languages, and lack flexible memory addressing modes like strided or gather/scatter, making compiler vectorization hard. Consequently, SIMD is often used in hand-coded libraries rather than compiler-generated code, reducing its widespread utility.
   **External example:** Intel’s SSE instructions provide SIMD acceleration but require manual optimization as described here: Intel® 64 and IA-32 Architectures Software Developer’s Manual: https://software.intel.com/sites/default/files/managed/39/c5/253666-sdm-vol-2abcd.pdf
