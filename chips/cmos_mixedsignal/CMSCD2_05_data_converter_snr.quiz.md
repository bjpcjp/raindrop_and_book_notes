1. **Q:** Explain Bennett’s criteria for quantization noise analysis in ADCs and describe why each assumption is critical for modeling quantization noise as white noise.
   **A:** Bennett's criteria comprise three assumptions: (1) the input signal varies within the ADC's reference range (no saturation), as exceeding it causes spurs in the output spectrum; (2) the input amplitude is much larger than 1 LSB, ensuring the output doesn't become squarewave-like, which would introduce spectral spikes; (3) the input is busy (no two consecutive ADC outputs are identical), so the quantization noise appears random and uniformly distributed. These assumptions are critical because they guarantee the quantization noise behaves like white noise rather than spurs or tones, validating the uniform probability density function used for noise power calculation.
   **External example:** IEEE Standard 1241 details the assumptions for uniform quantization noise in ADCs: https://ieeexplore.ieee.org/document/1331257

2. **Q:** How does the root-mean-square (RMS) quantization noise voltage relate to the ADC LSB voltage and number of bits, and why doesn't increasing the sampling frequency reduce the total RMS quantization noise power?
   **A:** RMS quantization noise voltage is V_LSB divided by the square root of 12, where V_LSB = (V_REF+ - V_REF-)/2^N. The total RMS quantization noise power is independent of sampling frequency because higher sampling frequency spreads the quantization noise power over a wider bandwidth, reducing noise spectral density but keeping the total noise power constant. Bandlimiting reduces noise power by filtering out higher-frequency noise components, but merely increasing sampling without filtering does not reduce total noise power.
   **External example:** Texas Instruments quantization noise explanation concurs with this: https://www.ti.com/lit/an/slaa448a/slaa448a.pdf

3. **Q:** Describe the impact of clock jitter on ADC signal-to-noise ratio (SNR), including how input sinewave frequency and jitter magnitude determine bits lost, and how oversampling can relax clock stability requirements.
   **A:** Clock jitter causes sampling time uncertainty, which translates to voltage uncertainty proportional to input slew rate (frequency × amplitude). The bits lost due to jitter increase with input sinewave frequency and jitter magnitude, as N_Loss ≈ 3.32 × log2(2π × f_in × V_jitter). Oversampling increases sampling frequency beyond twice the input bandwidth, allowing the same jitter magnitude but with relaxed clock stability (parts per million) because the clock period is shorter, decreasing relative jitter effect. Thus, oversampling reduces the effective resolution loss from jitter for a given clock.
   **External example:** National Instruments explains ADC aperture jitter and oversampling benefits: https://www.ni.com/en-us/innovations/white-papers/06/understanding-adc-aperture-jitter.html

4. **Q:** Explain how digital averaging filters improve the effective resolution of an ADC and state the assumptions under which averaging is valid, including any constraints on input signal and data converter linearity.
   **A:** Digital averaging reduces quantization noise power by averaging K uncorrelated samples, improving the effective resolution by N_Inc = (10 × log10 K) / 6.02 bits, i.e., every doubling in samples adds 0.5 bits. Averaging is valid if Bennett’s criteria hold—input must be busy, with amplitude variations exceeding 1 LSB, and the signal bandwidth must be sufficiently limited (≤ fs/2K) to avoid canceling desired signals. The ADC and DAC must be linear to the final output resolution; nonlinearities, missing codes, or nonmonotonic behavior limit the benefit of averaging.
   **External example:** Analog Devices covers resolution improvement via noise averaging in Sigma-Delta ADCs: https://www.analog.com/en/analog-dialogue/articles/digitizing-analog-signals-oversampling-and-noise-shaping.html

5. **Q:** Differentiate between Signal-to-Noise Ratio (SNR) and Signal-to-Noise plus Distortion Ratio (SNDR) in data converter performance measurement and describe how each is calculated from output spectra.
   **A:** SNR measures the ratio of signal power to quantization noise power alone, excluding distortion components; calculated by zeroing out the fundamental input tone and all distortion/spur tones in the output spectrum. SNDR includes both noise and distortion (harmonics, nonlinearities), calculated by zeroing only the fundamental and its aliases, summing the remaining power. Hence, SNR ≈ SNDR at low input amplitudes (minimal distortion), but at higher amplitudes, distortion increases, causing SNDR to degrade more than SNR.
   **External example:** IEEE Standard 1241 defines distinctions between SNR and SNDR: https://ieeexplore.ieee.org/document/1331257

6. **Q:** Using the additive quantization noise model, compare the signal transfer function (STF) and noise transfer function (NTF) characteristics of predictive and noise-shaping modulators and their implications on system design complexity.
   **A:** Predictive modulators use a high-gain feedback filter B(f) to approximate the input signal, resulting in STF and NTF both approximately 1/B(f), implying quantization noise is shaped identically to the signal and requires a precise analog reconstruction filter matching B(f), increasing design complexity and sensitivity to component mismatch. Noise-shaping modulators utilize a high-gain forward path A(f), making STF ≈ 1 (signal passes unchanged) and NTF ≈ 1/(1 + A(f)B(f)) ≈ 0 in-band, pushing quantization noise out of the signal band. This relaxes analog component precision, reduces reliance on reconstruction filtering, and simplifies design.
   **External example:** Analog Devices overview of delta-sigma modulators: https://www.analog.com/en/analog-dialogue/articles/delta-sigma-modulators-adc.html

7. **Q:** Why does adding a noise dither to an ADC input improve quantization noise characteristics for DC or slow-varying signals, and what are the practical considerations in implementing such dither?
   **A:** Noise dither randomizes the quantization error for DC or low-frequency inputs that violate Bennett’s criteria (lack of input busyness), thereby making quantization noise more uniform and white. This mitigates spurious tones and allows averaging filters to effectively reduce noise. Practical considerations include limiting dither spectral content below fs/2K to enable filtering, ensuring the dither signal has zero mean (symmetrical PDF) to avoid DC offset, and designing dither circuits (e.g., asynchronous inverter chains) that produce uncorrelated, band-limited noise with proper amplitude (∼0.5 LSB RMS).
   **External example:** Texas Instruments explanation on dither in ADCs: https://www.ti.com/lit/an/slyt281/slyt281.pdf

8. **Q:** What are the limitations of increasing data converter resolution by averaging multiple lower-resolution converter outputs, and how do converter linearity and input signal characteristics influence these limitations?
   **A:** Increasing resolution via averaging is limited by the linearity of the individual ADCs/DACs; errors like integral and differential nonlinearity (INL, DNL) must be within half an LSB of the desired total resolution after averaging. Missing codes or nonmonotonic behavior negate averaging benefits. Input signals must be busy and bandlimited to avoid averaging away desired signals. Essentially, the final output accuracy depends on the ADC linearity exceeding the target resolution, else resolution gains from averaging are lost.
   **External example:** Analog Devices discussion on ADC linearity effects on averaging: https://www.analog.com/en/analog-dialogue/articles/data-converter-linearity-performance.html
