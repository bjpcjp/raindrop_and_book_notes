- **Activation Output** — The computed response or firing level generated by a neuron based on its inputs.  
- **Actor-Critic Architecture** — A reinforcement learning framework separating policy selection (actor) and value estimation (critic).  
- **Attractors** — Stable states in neural networks that represent memory patterns or categorical decisions.  
- **Basal Ganglia** — Brain structures involved in action selection, motor control, and reinforcement learning.  
- **Bidirectional Excitatory Dynamics** — Neural processes where excitatory signals propagate in two directions to stabilize activity patterns.  
- **BCM Model** — A self-organizing learning algorithm based on synaptic plasticity with adaptable thresholds over long timescales.  
- **Cerebellum** — Brain region responsible for motor coordination and error-driven learning.  
- **Contrastive Attractor Learning (XCAL)** — A biologically inspired synaptic plasticity model combining error-driven and self-organizing learning.  
- **Distributed Representations** — Neural coding scheme where information is represented across many neurons rather than localized.  
- **Dopamine (DA)** — Neurotransmitter critical for reinforcement learning and temporal difference signaling.  
- **Energy Function** — A mathematical description used to analyze stability and dynamics in neural networks.  
- **Error-Driven Learning** — Learning driven by the difference between expected and actual outcomes.  
- **Feedforward and Feedback Inhibition** — Mechanisms by which inhibitory neurons regulate neural activity through input (feedforward) or internal network feedback.  
- **Hemispatial Neglect** — A neurological condition where a person ignores one side of space, often due to right hemisphere damage.  
- **Hebbian Learning** — A synaptic learning rule where simultaneous activation of connected neurons strengthens their connection.  
- **Localist Representations** — Neural coding where individual neurons represent specific concepts or features.  
- **Motor Control** — Processes and brain structures involved in planning, initiating, and executing movements.  
- **Net Input** — The total weighted sum of inputs a neuron receives before activation calculation.  
- **Neocortex** — The layered brain structure involved in higher cognitive functions and sensory processing.  
- **Neurons as Detectors** — Conceptualization of neurons functioning as units that detect specific patterns of input.  
- **Pattern Completion** — The ability of neural networks, especially in the hippocampus, to retrieve entire stored patterns from partial cues.  
- **Pattern Separation** — Neural process that reduces overlap between similar input patterns, crucial for memory storage.  
- **PBWM Model** — Prefrontal cortex basal ganglia working memory computational model supporting dynamic memory updating.  
- **Phasic Dopamine** — Brief bursts of dopamine signaling used to signal prediction errors in reinforcement learning.  
- **Plasticity** — The ability of synapses to change their strength based on activity and experience.  
- **Posner Spatial Cueing Task** — Behavioral paradigm used to study spatial attention mechanisms.  
- **Reinforcement Learning** — Learning driven by rewards or feedback signals guiding future behavior.  
- **Sodium-Gated Potassium Channels (kNa Adapt)** — Ion channels involved in adaptation mechanisms regulating neuronal excitability.  
- **Self-Organizing Learning** — Unsupervised learning processes that organize neural responses based on input statistics.  
- **Spike Timing Dependent Plasticity (STDP)** — A form of synaptic plasticity dependent on the precise timing of pre- and postsynaptic spikes.  
- **Temporal Difference (TD) Learning** — Reinforcement learning method based on predicting future rewards and updating estimates accordingly.
